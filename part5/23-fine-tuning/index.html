<!DOCTYPE html><html lang="en"> <head><meta charset="UTF-8"><meta name="viewport" content="width=device-width, initial-scale=1.0"><title>Chapter 23: Fine-Tuning | Engineering Intelligence</title><meta name="description" content="A book for engineers who want to understand Machine Learning and AI from first principles"><!-- Canonical URL --><link rel="canonical" href="https://olivernguyen.io/eng-ai/part5/23-fine-tuning/"><!-- Open Graph / Facebook --><meta property="og:type" content="website"><meta property="og:url" content="https://olivernguyen.io/eng-ai/part5/23-fine-tuning/"><meta property="og:title" content="Chapter 23: Fine-Tuning | Engineering Intelligence"><meta property="og:description" content="A book for engineers who want to understand Machine Learning and AI from first principles"><meta property="og:image" content="https://olivernguyen.io/eng-ai/og-image.png"><meta property="og:site_name" content="Engineering Intelligence"><!-- Twitter --><meta name="twitter:card" content="summary_large_image"><meta name="twitter:url" content="https://olivernguyen.io/eng-ai/part5/23-fine-tuning/"><meta name="twitter:title" content="Chapter 23: Fine-Tuning | Engineering Intelligence"><meta name="twitter:description" content="A book for engineers who want to understand Machine Learning and AI from first principles"><meta name="twitter:image" content="https://olivernguyen.io/eng-ai/og-image.png"><!-- Additional Meta --><meta name="author" content="Oliver Nguyen"><meta name="theme-color" content="#2563eb"><!-- Favicon (SVG preferred, PNG fallback) --><link rel="icon" type="image/svg+xml" href="/eng-ai/favicon.svg"><link rel="icon" type="image/png" sizes="32x32" href="/eng-ai/favicon-32x32.png"><link rel="icon" type="image/png" sizes="16x16" href="/eng-ai/favicon-16x16.png"><link rel="apple-touch-icon" sizes="180x180" href="/eng-ai/apple-touch-icon.png"><!-- KaTeX CSS for math rendering --><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css"><!-- Site styles --><link rel="stylesheet" href="/eng-ai/styles/global.css"><link rel="stylesheet" href="/eng-ai/styles/typography.css"><link rel="stylesheet" href="/eng-ai/styles/themes.css"><link rel="stylesheet" href="/eng-ai/styles/print.css"><style>.breadcrumbs[data-astro-cid-ilhxcym7]{margin-bottom:2rem}.breadcrumbs[data-astro-cid-ilhxcym7] ol[data-astro-cid-ilhxcym7]{display:flex;flex-wrap:wrap;gap:.5rem;list-style:none;padding:0;font-size:.9rem}.breadcrumbs[data-astro-cid-ilhxcym7] li[data-astro-cid-ilhxcym7]{display:flex;align-items:center;gap:.5rem}.breadcrumbs[data-astro-cid-ilhxcym7] li[data-astro-cid-ilhxcym7]:not(:last-child):after{content:"‚Ä∫";color:var(--text-muted)}.breadcrumbs[data-astro-cid-ilhxcym7] a[data-astro-cid-ilhxcym7]{color:var(--accent);text-decoration:none}.breadcrumbs[data-astro-cid-ilhxcym7] a[data-astro-cid-ilhxcym7]:hover{text-decoration:underline}.breadcrumbs[data-astro-cid-ilhxcym7] li[data-astro-cid-ilhxcym7][aria-current=page]{color:var(--text-muted)}.toc[data-astro-cid-xvrfupwn]{position:sticky;top:2rem;padding:1rem}.toc[data-astro-cid-xvrfupwn] h4[data-astro-cid-xvrfupwn]{font-size:.9rem;font-weight:600;text-transform:uppercase;letter-spacing:.05em;color:var(--text-muted);margin-bottom:.75rem}.toc[data-astro-cid-xvrfupwn] ul[data-astro-cid-xvrfupwn]{list-style:none;padding:0}.toc[data-astro-cid-xvrfupwn] li[data-astro-cid-xvrfupwn]{margin:.5rem 0}.toc[data-astro-cid-xvrfupwn] a[data-astro-cid-xvrfupwn]{font-size:.85rem;color:var(--text-muted);text-decoration:none;transition:color .2s}.toc[data-astro-cid-xvrfupwn] a[data-astro-cid-xvrfupwn]:hover{color:var(--accent)}.toc-level-2[data-astro-cid-xvrfupwn]{padding-left:0}.toc-level-3[data-astro-cid-xvrfupwn]{padding-left:1rem;font-size:.8rem}.chapter-navigation[data-astro-cid-pux6a34n]{display:flex;justify-content:space-between;gap:2rem;margin:4rem 0 2rem;padding-top:2rem;border-top:1px solid var(--border)}.nav-prev[data-astro-cid-pux6a34n],.nav-next[data-astro-cid-pux6a34n]{display:flex;flex-direction:column;gap:.5rem;padding:1rem;border:1px solid var(--border);border-radius:8px;text-decoration:none;transition:border-color .2s,background .2s;flex:1;max-width:45%}.nav-prev[data-astro-cid-pux6a34n]:hover,.nav-next[data-astro-cid-pux6a34n]:hover{border-color:var(--accent);background:var(--hover-bg)}.nav-prev[data-astro-cid-pux6a34n].placeholder{visibility:hidden}.nav-next[data-astro-cid-pux6a34n]{align-items:flex-end;text-align:right}.nav-label[data-astro-cid-pux6a34n]{font-size:.85rem;font-weight:600;text-transform:uppercase;letter-spacing:.05em;color:var(--accent)}.nav-title[data-astro-cid-pux6a34n]{font-size:1rem;color:var(--text)}
</style>
<link rel="stylesheet" href="/eng-ai/_astro/_chapter_.BUailOsj.css"><script type="module" src="/eng-ai/_astro/hoisted.0uyw1jl9.js"></script></head> <body>  <div class="book-layout"> <button id="mobile-menu-toggle" class="hamburger-button" aria-label="Toggle navigation menu" aria-expanded="false" data-astro-cid-odmlyywb> <span class="hamburger-line" data-astro-cid-odmlyywb></span> <span class="hamburger-line" data-astro-cid-odmlyywb></span> <span class="hamburger-line" data-astro-cid-odmlyywb></span> </button>  <div class="sidebar-overlay" id="sidebar-overlay" data-astro-cid-ssfzsv2f></div> <aside class="sidebar" id="sidebar" data-astro-cid-ssfzsv2f> <!-- Sidebar Controls --> <div class="sidebar-controls" data-astro-cid-ssfzsv2f> <button id="sidebar-close" class="sidebar-close-button" aria-label="Close menu" data-astro-cid-ssfzsv2f> <svg width="20" height="20" viewBox="0 0 20 20" fill="none" data-astro-cid-ssfzsv2f> <line x1="4" y1="4" x2="16" y2="16" stroke="currentColor" stroke-width="2" stroke-linecap="round" data-astro-cid-ssfzsv2f></line> <line x1="16" y1="4" x2="4" y2="16" stroke="currentColor" stroke-width="2" stroke-linecap="round" data-astro-cid-ssfzsv2f></line> </svg> </button> <button id="theme-toggle" class="theme-toggle-button" aria-label="Toggle dark mode" data-astro-cid-ssfzsv2f> <svg class="sun-icon" width="20" height="20" viewBox="0 0 20 20" data-astro-cid-ssfzsv2f> <circle cx="10" cy="10" r="4" fill="currentColor" data-astro-cid-ssfzsv2f></circle> <line x1="10" y1="1" x2="10" y2="3" stroke="currentColor" stroke-width="2" stroke-linecap="round" data-astro-cid-ssfzsv2f></line> <line x1="10" y1="17" x2="10" y2="19" stroke="currentColor" stroke-width="2" stroke-linecap="round" data-astro-cid-ssfzsv2f></line> <line x1="1" y1="10" x2="3" y2="10" stroke="currentColor" stroke-width="2" stroke-linecap="round" data-astro-cid-ssfzsv2f></line> <line x1="17" y1="10" x2="19" y2="10" stroke="currentColor" stroke-width="2" stroke-linecap="round" data-astro-cid-ssfzsv2f></line> <line x1="3.5" y1="3.5" x2="5" y2="5" stroke="currentColor" stroke-width="2" stroke-linecap="round" data-astro-cid-ssfzsv2f></line> <line x1="15" y1="15" x2="16.5" y2="16.5" stroke="currentColor" stroke-width="2" stroke-linecap="round" data-astro-cid-ssfzsv2f></line> <line x1="16.5" y1="3.5" x2="15" y2="5" stroke="currentColor" stroke-width="2" stroke-linecap="round" data-astro-cid-ssfzsv2f></line> <line x1="5" y1="15" x2="3.5" y2="16.5" stroke="currentColor" stroke-width="2" stroke-linecap="round" data-astro-cid-ssfzsv2f></line> </svg> <svg class="moon-icon" width="20" height="20" viewBox="0 0 20 20" data-astro-cid-ssfzsv2f> <path d="M10 2a8 8 0 108 8 6 6 0 01-8-8z" fill="currentColor" data-astro-cid-ssfzsv2f></path> </svg> </button> </div> <div class="sidebar-header" data-astro-cid-ssfzsv2f> <a href="/eng-ai/" data-astro-cid-ssfzsv2f> <h2 data-astro-cid-ssfzsv2f>Engineering Intelligence</h2> </a> </div> <nav class="sidebar-nav" data-astro-cid-ssfzsv2f> <section class="intro-section" data-astro-cid-ssfzsv2f> <ul data-astro-cid-ssfzsv2f> <li class="" data-astro-cid-ssfzsv2f> <a href="/eng-ai/introduction" <span class="intro-icon" data-astro-cid-ssfzsv2f>üìñ
              Introduction
</a> </li> </ul> </section> <section class="part-section" data-astro-cid-ssfzsv2f> <h3 class="" data-astro-cid-ssfzsv2f> <a href="/eng-ai/part1" data-astro-cid-ssfzsv2f>
Part I: Foundations </a> </h3> <ul data-astro-cid-ssfzsv2f> <li class="" data-astro-cid-ssfzsv2f> <a href="/eng-ai/part1/01-why-intelligence-is-not-magic" data-astro-cid-ssfzsv2f> <span class="chapter-num" data-astro-cid-ssfzsv2f>1.</span> Why Intelligence Is Not Magic </a> </li><li class="" data-astro-cid-ssfzsv2f> <a href="/eng-ai/part1/02-data-is-the-new-physics" data-astro-cid-ssfzsv2f> <span class="chapter-num" data-astro-cid-ssfzsv2f>2.</span> Data Is the New Physics </a> </li><li class="" data-astro-cid-ssfzsv2f> <a href="/eng-ai/part1/03-models-are-compression-machines" data-astro-cid-ssfzsv2f> <span class="chapter-num" data-astro-cid-ssfzsv2f>3.</span> Models Are Compression Machines </a> </li><li class="" data-astro-cid-ssfzsv2f> <a href="/eng-ai/part1/04-bias-variance-tradeoff" data-astro-cid-ssfzsv2f> <span class="chapter-num" data-astro-cid-ssfzsv2f>4.</span> The Bias-Variance Tradeoff </a> </li><li class="" data-astro-cid-ssfzsv2f> <a href="/eng-ai/part1/05-features-how-machines-see-the-world" data-astro-cid-ssfzsv2f> <span class="chapter-num" data-astro-cid-ssfzsv2f>5.</span> Features: How Machines See the World </a> </li> </ul> </section><section class="part-section" data-astro-cid-ssfzsv2f> <h3 class="" data-astro-cid-ssfzsv2f> <a href="/eng-ai/part2" data-astro-cid-ssfzsv2f>
Part II: Classical ML </a> </h3> <ul data-astro-cid-ssfzsv2f> <li class="" data-astro-cid-ssfzsv2f> <a href="/eng-ai/part2/06-linear-models" data-astro-cid-ssfzsv2f> <span class="chapter-num" data-astro-cid-ssfzsv2f>6.</span> Linear Models </a> </li><li class="" data-astro-cid-ssfzsv2f> <a href="/eng-ai/part2/07-logistic-regression" data-astro-cid-ssfzsv2f> <span class="chapter-num" data-astro-cid-ssfzsv2f>7.</span> Logistic Regression </a> </li><li class="" data-astro-cid-ssfzsv2f> <a href="/eng-ai/part2/08-decision-trees" data-astro-cid-ssfzsv2f> <span class="chapter-num" data-astro-cid-ssfzsv2f>8.</span> Decision Trees </a> </li><li class="" data-astro-cid-ssfzsv2f> <a href="/eng-ai/part2/09-ensembles" data-astro-cid-ssfzsv2f> <span class="chapter-num" data-astro-cid-ssfzsv2f>9.</span> Ensembles </a> </li><li class="" data-astro-cid-ssfzsv2f> <a href="/eng-ai/part2/10-loss-functions" data-astro-cid-ssfzsv2f> <span class="chapter-num" data-astro-cid-ssfzsv2f>10.</span> Loss Functions and Optimization </a> </li> </ul> </section><section class="part-section" data-astro-cid-ssfzsv2f> <h3 class="" data-astro-cid-ssfzsv2f> <a href="/eng-ai/part3" data-astro-cid-ssfzsv2f>
Part III: Neural Networks </a> </h3> <ul data-astro-cid-ssfzsv2f> <li class="" data-astro-cid-ssfzsv2f> <a href="/eng-ai/part3/11-neurons-as-math" data-astro-cid-ssfzsv2f> <span class="chapter-num" data-astro-cid-ssfzsv2f>11.</span> Neurons as Math </a> </li><li class="" data-astro-cid-ssfzsv2f> <a href="/eng-ai/part3/12-forward-pass" data-astro-cid-ssfzsv2f> <span class="chapter-num" data-astro-cid-ssfzsv2f>12.</span> The Forward Pass </a> </li><li class="" data-astro-cid-ssfzsv2f> <a href="/eng-ai/part3/13-backpropagation" data-astro-cid-ssfzsv2f> <span class="chapter-num" data-astro-cid-ssfzsv2f>13.</span> Backpropagation </a> </li><li class="" data-astro-cid-ssfzsv2f> <a href="/eng-ai/part3/14-optimization-deep-learning" data-astro-cid-ssfzsv2f> <span class="chapter-num" data-astro-cid-ssfzsv2f>14.</span> Optimization in Deep Learning </a> </li><li class="" data-astro-cid-ssfzsv2f> <a href="/eng-ai/part3/15-representation-learning" data-astro-cid-ssfzsv2f> <span class="chapter-num" data-astro-cid-ssfzsv2f>15.</span> Representation Learning </a> </li> </ul> </section><section class="part-section" data-astro-cid-ssfzsv2f> <h3 class="" data-astro-cid-ssfzsv2f> <a href="/eng-ai/part4" data-astro-cid-ssfzsv2f>
Part IV: Deep Architectures </a> </h3> <ul data-astro-cid-ssfzsv2f> <li class="" data-astro-cid-ssfzsv2f> <a href="/eng-ai/part4/16-convolutional-neural-networks" data-astro-cid-ssfzsv2f> <span class="chapter-num" data-astro-cid-ssfzsv2f>16.</span> Convolutional Neural Networks </a> </li><li class="" data-astro-cid-ssfzsv2f> <a href="/eng-ai/part4/17-recurrent-neural-networks" data-astro-cid-ssfzsv2f> <span class="chapter-num" data-astro-cid-ssfzsv2f>17.</span> Recurrent Neural Networks </a> </li><li class="" data-astro-cid-ssfzsv2f> <a href="/eng-ai/part4/18-embeddings" data-astro-cid-ssfzsv2f> <span class="chapter-num" data-astro-cid-ssfzsv2f>18.</span> Embeddings </a> </li><li class="" data-astro-cid-ssfzsv2f> <a href="/eng-ai/part4/19-attention" data-astro-cid-ssfzsv2f> <span class="chapter-num" data-astro-cid-ssfzsv2f>19.</span> Attention </a> </li><li class="" data-astro-cid-ssfzsv2f> <a href="/eng-ai/part4/20-transformers" data-astro-cid-ssfzsv2f> <span class="chapter-num" data-astro-cid-ssfzsv2f>20.</span> Transformers </a> </li> </ul> </section><section class="part-section" data-astro-cid-ssfzsv2f> <h3 class="" data-astro-cid-ssfzsv2f> <a href="/eng-ai/part5" data-astro-cid-ssfzsv2f>
Part V: Language Models </a> </h3> <ul data-astro-cid-ssfzsv2f> <li class="" data-astro-cid-ssfzsv2f> <a href="/eng-ai/part5/21-next-token-prediction" data-astro-cid-ssfzsv2f> <span class="chapter-num" data-astro-cid-ssfzsv2f>21.</span> Next-Token Prediction </a> </li><li class="" data-astro-cid-ssfzsv2f> <a href="/eng-ai/part5/22-pretraining" data-astro-cid-ssfzsv2f> <span class="chapter-num" data-astro-cid-ssfzsv2f>22.</span> Pretraining </a> </li><li class="active" data-astro-cid-ssfzsv2f> <a href="/eng-ai/part5/23-fine-tuning" data-astro-cid-ssfzsv2f> <span class="chapter-num" data-astro-cid-ssfzsv2f>23.</span> Fine-Tuning </a> </li><li class="" data-astro-cid-ssfzsv2f> <a href="/eng-ai/part5/24-rlhf" data-astro-cid-ssfzsv2f> <span class="chapter-num" data-astro-cid-ssfzsv2f>24.</span> RLHF </a> </li><li class="" data-astro-cid-ssfzsv2f> <a href="/eng-ai/part5/25-emergent-abilities-and-scaling" data-astro-cid-ssfzsv2f> <span class="chapter-num" data-astro-cid-ssfzsv2f>25.</span> Emergent Abilities and Scaling </a> </li> </ul> </section><section class="part-section" data-astro-cid-ssfzsv2f> <h3 class="" data-astro-cid-ssfzsv2f> <a href="/eng-ai/part6" data-astro-cid-ssfzsv2f>
Part VI: Modern AI Systems </a> </h3> <ul data-astro-cid-ssfzsv2f> <li class="" data-astro-cid-ssfzsv2f> <a href="/eng-ai/part6/26-prompting-as-programming" data-astro-cid-ssfzsv2f> <span class="chapter-num" data-astro-cid-ssfzsv2f>26.</span> Prompting as Programming </a> </li><li class="" data-astro-cid-ssfzsv2f> <a href="/eng-ai/part6/27-retrieval-augmented-generation" data-astro-cid-ssfzsv2f> <span class="chapter-num" data-astro-cid-ssfzsv2f>27.</span> Retrieval-Augmented Generation </a> </li><li class="" data-astro-cid-ssfzsv2f> <a href="/eng-ai/part6/28-tools-and-function-calling" data-astro-cid-ssfzsv2f> <span class="chapter-num" data-astro-cid-ssfzsv2f>28.</span> Tools and Function Calling </a> </li><li class="" data-astro-cid-ssfzsv2f> <a href="/eng-ai/part6/29-agents" data-astro-cid-ssfzsv2f> <span class="chapter-num" data-astro-cid-ssfzsv2f>29.</span> Agents - Models That Decide What to Do </a> </li><li class="" data-astro-cid-ssfzsv2f> <a href="/eng-ai/part6/30-memory-and-planning" data-astro-cid-ssfzsv2f> <span class="chapter-num" data-astro-cid-ssfzsv2f>30.</span> Memory, Planning, and Long-Term Behavior </a> </li> </ul> </section><section class="part-section" data-astro-cid-ssfzsv2f> <h3 class="" data-astro-cid-ssfzsv2f> <a href="/eng-ai/part7" data-astro-cid-ssfzsv2f>
Part VII: Engineering Reality </a> </h3> <ul data-astro-cid-ssfzsv2f> <li class="" data-astro-cid-ssfzsv2f> <a href="/eng-ai/part7/31-data-pipelines" data-astro-cid-ssfzsv2f> <span class="chapter-num" data-astro-cid-ssfzsv2f>31.</span> Data Pipelines - Where Models Are Born and Die </a> </li><li class="" data-astro-cid-ssfzsv2f> <a href="/eng-ai/part7/32-training-vs-inference" data-astro-cid-ssfzsv2f> <span class="chapter-num" data-astro-cid-ssfzsv2f>32.</span> Training vs Inference - Two Different Worlds </a> </li><li class="" data-astro-cid-ssfzsv2f> <a href="/eng-ai/part7/33-evaluation" data-astro-cid-ssfzsv2f> <span class="chapter-num" data-astro-cid-ssfzsv2f>33.</span> Evaluation - Why Accuracy Is Not Enough </a> </li><li class="" data-astro-cid-ssfzsv2f> <a href="/eng-ai/part7/34-hallucinations-bias-brittleness" data-astro-cid-ssfzsv2f> <span class="chapter-num" data-astro-cid-ssfzsv2f>34.</span> Hallucinations, Bias, and Brittleness </a> </li><li class="" data-astro-cid-ssfzsv2f> <a href="/eng-ai/part7/35-safety-alignment-control" data-astro-cid-ssfzsv2f> <span class="chapter-num" data-astro-cid-ssfzsv2f>35.</span> Safety, Alignment, and Control </a> </li> </ul> </section><section class="part-section" data-astro-cid-ssfzsv2f> <h3 class="" data-astro-cid-ssfzsv2f> <a href="/eng-ai/part8" data-astro-cid-ssfzsv2f>
Part VIII: The Frontier </a> </h3> <ul data-astro-cid-ssfzsv2f> <li class="" data-astro-cid-ssfzsv2f> <a href="/eng-ai/part8/36-scaling-laws" data-astro-cid-ssfzsv2f> <span class="chapter-num" data-astro-cid-ssfzsv2f>36.</span> Scaling Laws - Why Bigger Keeps Winning </a> </li><li class="" data-astro-cid-ssfzsv2f> <a href="/eng-ai/part8/37-multimodal-models" data-astro-cid-ssfzsv2f> <span class="chapter-num" data-astro-cid-ssfzsv2f>37.</span> Multimodal Models </a> </li><li class="" data-astro-cid-ssfzsv2f> <a href="/eng-ai/part8/38-self-improving-systems" data-astro-cid-ssfzsv2f> <span class="chapter-num" data-astro-cid-ssfzsv2f>38.</span> Self-Improving Systems </a> </li><li class="" data-astro-cid-ssfzsv2f> <a href="/eng-ai/part8/39-artificial-general-intelligence" data-astro-cid-ssfzsv2f> <span class="chapter-num" data-astro-cid-ssfzsv2f>39.</span> Artificial General Intelligence </a> </li><li class="" data-astro-cid-ssfzsv2f> <a href="/eng-ai/part8/40-the-engineers-role" data-astro-cid-ssfzsv2f> <span class="chapter-num" data-astro-cid-ssfzsv2f>40.</span> The Engineer&#39;s Role </a> </li> </ul> </section> </nav> </aside>   <main class="chapter-content"> <nav class="breadcrumbs" aria-label="Breadcrumb" data-astro-cid-ilhxcym7> <ol data-astro-cid-ilhxcym7> <li data-astro-cid-ilhxcym7><a href="/eng-ai/" data-astro-cid-ilhxcym7>Home</a></li> <li data-astro-cid-ilhxcym7><a href="/eng-ai/part5" data-astro-cid-ilhxcym7>Part V: Language Models</a></li> <li aria-current="page" data-astro-cid-ilhxcym7>Fine-Tuning</li> </ol> </nav>  <article class="chapter"> <h1 id="chapter-23-fine-tuning">Chapter 23: Fine-Tuning</h1>
<h2 id="turning-a-brain-into-a-tool-ch23">Turning a Brain into a Tool</h2>
<h2 id="why-pretrained-models-are-wild-ch23">Why Pretrained Models Are Wild</h2>
<p>A freshly pretrained language model is not an assistant. It‚Äôs a prediction engine trained to complete any text, regardless of usefulness or appropriateness. Give it ‚ÄúUser: What is the capital of France?‚Äù and it might continue with:</p>
<pre class="astro-code astro-code-themes github-light github-dark" style="background-color:#fff;--shiki-dark-bg:#24292e;color:#24292e;--shiki-dark:#e1e4e8; overflow-x: auto; white-space: pre-wrap; word-wrap: break-word;" tabindex="0" data-language="plaintext"><code><span class="line"><span>User: What is the capital of France?</span></span>
<span class="line"><span>User: How do I cook pasta?</span></span>
<span class="line"><span>User: Why is the sky blue?</span></span>
<span class="line"><span>...</span></span>
<span class="line"><span></span></span></code></pre>
<p>The model treats the input as the beginning of a forum thread or FAQ document and generates more questions. Or it might complete:</p>
<pre class="astro-code astro-code-themes github-light github-dark" style="background-color:#fff;--shiki-dark-bg:#24292e;color:#24292e;--shiki-dark:#e1e4e8; overflow-x: auto; white-space: pre-wrap; word-wrap: break-word;" tabindex="0" data-language="plaintext"><code><span class="line"><span>User: What is the capital of France? I think it's London but I'm not sure.</span></span>
<span class="line"><span></span></span></code></pre>
<p>The model predicts plausible text based on training data patterns‚Äîquestions often follow questions, uncertainty often follows questions. But this isn‚Äôt helpful behavior. The user wants an answer, not more questions or speculation.</p>
<p>This is the distinction between <strong>raw prediction</strong> and <strong>instruction following</strong>. Pretrained models predict likely continuations. They don‚Äôt distinguish between helpful responses, irrelevant completions, or harmful outputs. They simply model the statistical distribution of text‚Äîall text, including bad forum posts, wrong answers, and toxic rants.</p>
<p>Raw models are ‚Äúwild‚Äù in the sense that their outputs are unconstrained. They might:</p>
<ul>
<li>Complete the user‚Äôs query with another query</li>
<li>Generate factually incorrect information (because wrong answers appear in training data)</li>
<li>Produce toxic or harmful content (because such content exists on the internet)</li>
<li>Refuse to answer simple questions (if ‚ÄúI don‚Äôt know‚Äù is a statistically plausible continuation)</li>
</ul>
<p>This isn‚Äôt a bug‚Äîit‚Äôs the natural behavior of a next-token predictor trained on diverse internet text. The model predicts what comes next, not what would be helpful. Making models useful requires additional training: <strong>fine-tuning</strong>.</p>
<h2 id="supervised-fine-tuning-teaching-specific-behaviors-ch23">Supervised Fine-Tuning: Teaching Specific Behaviors</h2>
<p>Fine-tuning specializes a pretrained model for specific tasks by training on curated examples. Unlike pretraining (self-supervised on raw text), fine-tuning is <strong>supervised</strong>: each example includes an input and a desired output, explicitly demonstrating the behavior we want.</p>
<p>For instruction following, the training data consists of (prompt, response) pairs:</p>
<pre class="astro-code astro-code-themes github-light github-dark" style="background-color:#fff;--shiki-dark-bg:#24292e;color:#24292e;--shiki-dark:#e1e4e8; overflow-x: auto; white-space: pre-wrap; word-wrap: break-word;" tabindex="0" data-language="plaintext"><code><span class="line"><span>Input:  "User: What is the capital of France?\nAssistant:"</span></span>
<span class="line"><span>Output: "The capital of France is Paris."</span></span>
<span class="line"><span></span></span></code></pre>
<p>The model continues to optimize next-token prediction, but now the training data shows helpful responses. By training on thousands or tens of thousands of such examples, the model learns the pattern: when text matches ‚ÄúUser: ‚Ä¶ Assistant:‚Äù, generate helpful, relevant answers, not arbitrary completions.</p>
<p><strong>Supervised fine-tuning (SFT)</strong> applies gradient descent with a lower learning rate than pretraining. The model‚Äôs parameters have already learned language structure from pretraining (Chapter 22)‚Äîwe don‚Äôt want to erase that knowledge. We want to adjust the model to specialize in a particular format (instruction following, dialogue, task completion).</p>
<p>The loss function remains cross-entropy:</p>
<span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msub><mi mathvariant="script">L</mi><mtext>SFT</mtext></msub><mo>=</mo><mo>‚àí</mo><munderover><mo>‚àë</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>N</mi></munderover><mi>log</mi><mo>‚Å°</mo><mi>P</mi><mo stretchy="false">(</mo><msub><mi>y</mi><mi>i</mi></msub><mi mathvariant="normal">‚à£</mi><mi>x</mi><mo separator="true">,</mo><msub><mi>y</mi><mn>1</mn></msub><mo separator="true">,</mo><mo>‚Ä¶</mo><mo separator="true">,</mo><msub><mi>y</mi><mrow><mi>i</mi><mo>‚àí</mo><mn>1</mn></mrow></msub><mo separator="true">;</mo><mi>Œ∏</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\mathcal{L}_{\text{SFT}} = -\sum_{i=1}^{N} \log P(y_i | x, y_1, \ldots, y_{i-1}; \theta)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathcal">L</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord text mtight"><span class="mord mtight">SFT</span></span></span></span></span></span><span class="vlist-s">‚Äã</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:3.106em;vertical-align:-1.2777em;"></span><span class="mord">‚àí</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.8283em;"><span style="top:-1.8723em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.05em;"><span class="pstrut" style="height:3.05em;"></span><span><span class="mop op-symbol large-op">‚àë</span></span></span><span style="top:-4.3em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em;">N</span></span></span></span></span><span class="vlist-s">‚Äã</span></span><span class="vlist-r"><span class="vlist" style="height:1.2777em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mop">lo<span style="margin-right:0.01389em;">g</span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">‚Äã</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord">‚à£</span><span class="mord mathnormal">x</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">‚Äã</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="minner">‚Ä¶</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mbin mtight">‚àí</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">‚Äã</span></span><span class="vlist-r"><span class="vlist" style="height:0.2083em;"><span></span></span></span></span></span></span><span class="mpunct">;</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">Œ∏</span><span class="mclose">)</span></span></span></span></span>
<p>Where <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>x</mi></mrow><annotation encoding="application/x-tex">x</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal">x</span></span></span></span> is the input (user query), <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>y</mi></mrow><annotation encoding="application/x-tex">y</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.1944em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span></span></span></span> is the desired output (assistant response), and <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>Œ∏</mi></mrow><annotation encoding="application/x-tex">\theta</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">Œ∏</span></span></span></span> are the model parameters. The model learns to assign high probability to correct responses given the input format.</p>
<p>The key difference from pretraining: the data is curated. Instead of random internet text, fine-tuning uses high-quality examples written or selected by humans. This shifts the model‚Äôs predictions from ‚Äúwhat text is statistically likely on the internet?‚Äù to ‚Äúwhat text is helpful/correct/appropriate for this task?‚Äù</p>
<p><strong>Dataset construction</strong> is critical. Fine-tuning on 10,000 carefully written examples outperforms fine-tuning on 100,000 noisy examples. Quality trumps quantity because the model is learning specific behavioral patterns, not broad language coverage (which it already learned during pretraining).</p>
<p>Examples of fine-tuning datasets:</p>
<ul>
<li><strong>Question answering</strong>: Questions paired with accurate answers</li>
<li><strong>Dialogue</strong>: Conversational turns with helpful, engaging responses</li>
<li><strong>Instruction following</strong>: Instructions paired with correct completions</li>
<li><strong>Task-specific</strong>: Summarization input/output, translation pairs, code explanations</li>
</ul>
<p>Modern instruction-tuned models (InstructGPT, ChatGPT, Claude) are fine-tuned on diverse instruction datasets covering many tasks. This multi-task fine-tuning improves robustness: the model learns general instruction-following behavior, not just specific tasks.</p>
<p><img  src="/eng-ai/_astro/23-diagram.CSxomhHr_1zyLxU.svg" alt="Supervised Fine-Tuning: Teaching Specific Behaviors diagram" width="600" height="320" loading="lazy" decoding="async"></p>
<p>The diagram shows the transformation: pretrained models complete text arbitrarily, fine-tuned models follow instructions helpfully. Fine-tuning doesn‚Äôt add knowledge (that comes from pretraining)‚Äîit shapes behavior.</p>
<h2 id="instruction-following-learning-to-obey-ch23">Instruction Following: Learning to Obey</h2>
<p>The format of fine-tuning data determines learned behavior. To make models follow instructions, the data uses explicit instruction patterns:</p>
<pre class="astro-code astro-code-themes github-light github-dark" style="background-color:#fff;--shiki-dark-bg:#24292e;color:#24292e;--shiki-dark:#e1e4e8; overflow-x: auto; white-space: pre-wrap; word-wrap: break-word;" tabindex="0" data-language="plaintext"><code><span class="line"><span>User: {instruction or question}</span></span>
<span class="line"><span>Assistant: {helpful response}</span></span>
<span class="line"><span></span></span></code></pre>
<p>or:</p>
<pre class="astro-code astro-code-themes github-light github-dark" style="background-color:#fff;--shiki-dark-bg:#24292e;color:#24292e;--shiki-dark:#e1e4e8; overflow-x: auto; white-space: pre-wrap; word-wrap: break-word;" tabindex="0" data-language="plaintext"><code><span class="line"><span>Instruction: {task description}</span></span>
<span class="line"><span>Output: {correct result}</span></span>
<span class="line"><span></span></span></code></pre>
<p>By training on thousands of examples with this format, the model learns the pattern: text following ‚ÄúUser:‚Äù or ‚ÄúInstruction:‚Äù is a query, text following ‚ÄúAssistant:‚Äù or ‚ÄúOutput:‚Äù is the expected response. The model adjusts its predictions to favor helpful, relevant responses in this context.</p>
<p>This is <strong>pattern matching, not understanding</strong>. The model doesn‚Äôt ‚Äúunderstand‚Äù it should be helpful‚Äîit learns that statistically, after ‚ÄúUser: [question]‚Äù, text matching ‚ÄúAssistant: [answer]‚Äù has high probability in fine-tuning data. The model‚Äôs prediction distribution shifts from generic text completion to task-specific completion.</p>
<p><strong>Multi-task instruction fine-tuning</strong> trains on diverse tasks simultaneously:</p>
<ul>
<li>Question answering: factual queries with accurate answers</li>
<li>Summarization: long text with concise summaries</li>
<li>Translation: source language text with target language output</li>
<li>Code generation: descriptions with code implementations</li>
<li>Creative writing: prompts with stories or essays</li>
</ul>
<p>Training on diverse tasks teaches the model a general capability: extract intent from the instruction, generate an appropriate response. This is more robust than single-task fine-tuning because the model learns to adapt to different instruction types rather than memorizing specific task formats.</p>
<p><strong>Example progression</strong> from raw to fine-tuned model:</p>
<p>Raw pretrained model:</p>
<pre class="astro-code astro-code-themes github-light github-dark" style="background-color:#fff;--shiki-dark-bg:#24292e;color:#24292e;--shiki-dark:#e1e4e8; overflow-x: auto; white-space: pre-wrap; word-wrap: break-word;" tabindex="0" data-language="plaintext"><code><span class="line"><span>Input:  "Translate to French: Hello, how are you?"</span></span>
<span class="line"><span>Output: "Translate to Spanish: Hola, ¬øc√≥mo est√°s?"</span></span>
<span class="line"><span></span></span></code></pre>
<p>‚Üí The model completes with another translation instruction (statistically likely in multilingual corpora)</p>
<p>After fine-tuning on translation examples:</p>
<pre class="astro-code astro-code-themes github-light github-dark" style="background-color:#fff;--shiki-dark-bg:#24292e;color:#24292e;--shiki-dark:#e1e4e8; overflow-x: auto; white-space: pre-wrap; word-wrap: break-word;" tabindex="0" data-language="plaintext"><code><span class="line"><span>Input:  "Translate to French: Hello, how are you?"</span></span>
<span class="line"><span>Output: "Bonjour, comment allez-vous?"</span></span>
<span class="line"><span></span></span></code></pre>
<p>‚Üí The model recognizes the instruction format and generates the requested translation</p>
<p>The model learns: when the input matches ‚Äú[Task]: [Input]‚Äù, generate [Output for that task], not arbitrary continuations. This behavioral shift comes from training data, not architectural changes. The same Transformer that did raw prediction now does instruction following because the optimization objective was applied to different data.</p>
<h2 id="catastrophic-forgetting-why-tuning-must-be-careful-ch23">Catastrophic Forgetting: Why Tuning Must Be Careful</h2>
<p>Fine-tuning overwrites the model‚Äôs pretrained knowledge if not done carefully. This phenomenon is <strong>catastrophic forgetting</strong>: when training on new data causes a neural network to ‚Äúforget‚Äù previously learned information.</p>
<p>During pretraining, the model‚Äôs parameters encode broad language knowledge‚Äîgrammar, facts, reasoning patterns. During fine-tuning, gradient updates adjust these parameters to specialize on task data. If the learning rate is too high or training runs too long, the model‚Äôs parameters drift far from their pretrained values, erasing general knowledge in favor of task-specific patterns.</p>
<p>Symptoms of catastrophic forgetting:</p>
<ul>
<li>The model becomes excellent at the fine-tuning task but poor at everything else</li>
<li>It loses factual knowledge not represented in the fine-tuning data</li>
<li>It produces lower-quality outputs on out-of-domain queries</li>
</ul>
<p>The risk scales with fine-tuning data size relative to pretraining. Fine-tuning on 10,000 examples (tiny compared to trillions of pretraining tokens) is unlikely to cause forgetting if learning rates are low. Fine-tuning on millions of examples with high learning rates can significantly shift the model‚Äôs distribution, degrading general capabilities.</p>
<p><strong>Mitigation strategies</strong>:</p>
<ol>
<li>
<p><strong>Low learning rate</strong>: Use learning rates 10‚Äì100√ó smaller than pretraining (e.g., 1e-5 instead of 1e-3). Small steps adjust behavior without erasing knowledge.</p>
</li>
<li>
<p><strong>Few epochs</strong>: Train for 1-3 passes over fine-tuning data instead of dozens. Minimize total parameter drift.</p>
</li>
<li>
<p><strong>Early stopping</strong>: Monitor validation loss and stop when task performance saturates, before overfitting to fine-tuning data.</p>
</li>
<li>
<p><strong>Multi-task fine-tuning</strong>: Train on diverse tasks simultaneously so the model doesn‚Äôt overspecialize on a single distribution.</p>
</li>
<li>
<p><strong>Regularization</strong>: Add penalties that keep parameters close to pretrained values (L2 penalty on parameter changes, KL divergence between fine-tuned and pretrained distributions).</p>
</li>
</ol>
<p>The key insight: fine-tuning is adjustment, not retraining. The heavy lifting (learning language structure from scratch) happened during pretraining. Fine-tuning nudges parameters to specialize without forgetting general capabilities.</p>
<h2 id="parameter-efficient-fine-tuning-peft-ch23">Parameter-Efficient Fine-Tuning (PEFT)</h2>
<p>Full fine-tuning updates all model parameters‚Äîbillions of weights. This is computationally expensive and risks catastrophic forgetting. <strong>Parameter-efficient fine-tuning (PEFT)</strong> updates only a small subset of parameters, freezing most of the pretrained model.</p>
<p><strong>LoRA (Low-Rank Adaptation)</strong>:</p>
<p>Instead of updating weight matrix <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="bold">W</mi><mo>‚àà</mo><msup><mi mathvariant="double-struck">R</mi><mrow><mi>d</mi><mo>√ó</mo><mi>d</mi></mrow></msup></mrow><annotation encoding="application/x-tex">\mathbf{W} \in \mathbb{R}^{d \times d}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7252em;vertical-align:-0.0391em;"></span><span class="mord mathbf" style="margin-right:0.01597em;">W</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">‚àà</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.8491em;"></span><span class="mord"><span class="mord mathbb">R</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8491em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">d</span><span class="mbin mtight">√ó</span><span class="mord mathnormal mtight">d</span></span></span></span></span></span></span></span></span></span></span></span> directly, LoRA adds a low-rank update:</p>
<span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msub><mi mathvariant="bold">W</mi><mtext>tuned</mtext></msub><mo>=</mo><msub><mi mathvariant="bold">W</mi><mtext>pretrained</mtext></msub><mo>+</mo><mrow><mi mathvariant="bold">B</mi><mi mathvariant="bold">A</mi></mrow></mrow><annotation encoding="application/x-tex">\mathbf{W}_{\text{tuned}} = \mathbf{W}_{\text{pretrained}} + \mathbf{BA}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8361em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathbf" style="margin-right:0.01597em;">W</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:-0.016em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord text mtight"><span class="mord mtight">tuned</span></span></span></span></span></span><span class="vlist-s">‚Äã</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.9722em;vertical-align:-0.2861em;"></span><span class="mord"><span class="mord mathbf" style="margin-right:0.01597em;">W</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:-0.016em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord text mtight"><span class="mord mtight">pretrained</span></span></span></span></span></span><span class="vlist-s">‚Äã</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.6861em;"></span><span class="mord"><span class="mord mathbf">BA</span></span></span></span></span></span>
<p>Where <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="bold">B</mi><mo>‚àà</mo><msup><mi mathvariant="double-struck">R</mi><mrow><mi>d</mi><mo>√ó</mo><mi>r</mi></mrow></msup></mrow><annotation encoding="application/x-tex">\mathbf{B} \in \mathbb{R}^{d \times r}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7252em;vertical-align:-0.0391em;"></span><span class="mord mathbf">B</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">‚àà</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.8491em;"></span><span class="mord"><span class="mord mathbb">R</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8491em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">d</span><span class="mbin mtight">√ó</span><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span></span></span></span></span></span></span></span></span></span></span></span> and <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="bold">A</mi><mo>‚àà</mo><msup><mi mathvariant="double-struck">R</mi><mrow><mi>r</mi><mo>√ó</mo><mi>d</mi></mrow></msup></mrow><annotation encoding="application/x-tex">\mathbf{A} \in \mathbb{R}^{r \times d}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7252em;vertical-align:-0.0391em;"></span><span class="mord mathbf">A</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">‚àà</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.8491em;"></span><span class="mord"><span class="mord mathbb">R</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8491em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span><span class="mbin mtight">√ó</span><span class="mord mathnormal mtight">d</span></span></span></span></span></span></span></span></span></span></span></span> with <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>r</mi><mo>‚â™</mo><mi>d</mi></mrow><annotation encoding="application/x-tex">r \ll d</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5782em;vertical-align:-0.0391em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">‚â™</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.6944em;"></span><span class="mord mathnormal">d</span></span></span></span> (e.g., <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>r</mi><mo>=</mo><mn>8</mn></mrow><annotation encoding="application/x-tex">r = 8</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">8</span></span></span></span>, <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>d</mi><mo>=</mo><mn>4096</mn></mrow><annotation encoding="application/x-tex">d = 4096</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em;"></span><span class="mord mathnormal">d</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">4096</span></span></span></span>). The pretrained weights <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="bold">W</mi></mrow><annotation encoding="application/x-tex">\mathbf{W}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6861em;"></span><span class="mord mathbf" style="margin-right:0.01597em;">W</span></span></span></span> are frozen; only <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="bold">A</mi></mrow><annotation encoding="application/x-tex">\mathbf{A}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6861em;"></span><span class="mord mathbf">A</span></span></span></span> and <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="bold">B</mi></mrow><annotation encoding="application/x-tex">\mathbf{B}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6861em;"></span><span class="mord mathbf">B</span></span></span></span> are trained. This reduces trainable parameters from billions to millions while maintaining comparable performance to full fine-tuning.</p>
<p><strong>Adapters</strong>:</p>
<p>Insert small trainable layers (adapters) between frozen Transformer layers. Adapters have far fewer parameters than full layers (e.g., 100K parameters vs. 100M). During fine-tuning, only adapter parameters are updated. This modularizes specialization: different adapter sets can be swapped for different tasks without retraining the entire model.</p>
<p>PEFT methods reduce fine-tuning cost (less compute, less memory), prevent catastrophic forgetting (most parameters remain unchanged), and enable multi-task deployment (store multiple small adapter sets instead of multiple full models).</p>
<h2 id="engineering-takeaway-ch23">Engineering Takeaway</h2>
<p>Fine-tuning transforms raw language models into useful tools by teaching them task-specific behaviors. Understanding fine-tuning techniques, trade-offs, and alternatives is essential for deploying models effectively.</p>
<p><strong>Fine-tuning specializes general models for specific domains</strong></p>
<p>Pretrained models are generalists‚Äîdecent at many tasks, excellent at none. Fine-tuning on domain-specific data (medical records, legal documents, code repositories) makes models experts in that domain. A model fine-tuned on medical literature will predict medical terminology accurately, understand clinical context, and generate domain-appropriate responses. This specialization comes from training on domain data, not architectural changes. For production systems in specialized fields, fine-tuning on proprietary or domain-specific data significantly improves performance over generic pretrained models.</p>
<p><strong>Low learning rates and few epochs prevent catastrophic forgetting</strong></p>
<p>Use learning rates 10‚Äì100√ó smaller than pretraining. Fine-tune for 1-3 epochs (passes over data), not dozens. Monitor validation loss and stop early when task performance plateaus. These strategies adjust behavior without erasing general knowledge. In practice, fine-tuning often uses learning rates around 1e-5 to 1e-6, compared to pretraining rates of 1e-3 to 1e-4. Training for too long or with too high a rate degrades the model‚Äôs general capabilities‚Äîa fine-tuned model should retain its broad knowledge while gaining task-specific expertise.</p>
<p><strong>Data quality matters more than quantity for fine-tuning</strong></p>
<p>10,000 carefully curated examples outperform 100,000 noisy examples. Fine-tuning data teaches behavior patterns‚Äîlow-quality examples (wrong answers, poorly formatted, off-topic) teach bad behaviors. Pretrained models already have language coverage; fine-tuning needs precise examples demonstrating desired behavior. Invest in data quality: human-written responses, expert annotations, thorough filtering. For instruction following, quality means clear instructions paired with correct, helpful, appropriately formatted responses. Noisy fine-tuning data degrades model behavior even if the volume is large.</p>
<p><strong>LoRA and adapters enable efficient fine-tuning of massive models</strong></p>
<p>Updating all 175B parameters of GPT-3 requires massive GPU memory and compute. LoRA adds low-rank matrices (millions of parameters) instead of updating billions, reducing memory by 10‚Äì100√ó. Adapters insert small trainable layers, achieving similar savings. These methods make fine-tuning practical on commodity hardware (single or few GPUs instead of clusters). For production deployment, PEFT enables rapid task-specific specialization without the cost of full fine-tuning. Many applications now use LoRA as the default fine-tuning approach, training low-rank updates on task data while keeping base model weights frozen.</p>
<p><strong>Prompt engineering emerges as an alternative to fine-tuning</strong></p>
<p>Not all applications require fine-tuning. For tasks with clear patterns that can be described in prompts, prompt engineering (Part VI) achieves good performance without any training. Compare costs: fine-tuning requires labeled data, compute for training, and careful hyperparameter tuning. Prompting requires only designing effective prompts. The trade-off: fine-tuning produces task-optimized models (higher performance ceiling), prompting is faster and cheaper (lower effort, immediate deployment). For many applications‚Äîespecially with powerful pretrained models like GPT-4‚Äîprompting suffices. Fine-tuning is worthwhile when marginal performance improvements justify the cost or when tasks require learning from proprietary data not seen during pretraining.</p>
<p><strong>Multi-task fine-tuning improves robustness</strong></p>
<p>Training on diverse tasks simultaneously produces more robust models than single-task fine-tuning. A model fine-tuned only on question answering may struggle with summarization. A model fine-tuned on question answering, summarization, translation, and dialogue learns general instruction-following behavior. Multi-task fine-tuning prevents overfitting to a narrow distribution and improves zero-shot performance on unseen tasks. This is the approach used by instruction-tuned models (InstructGPT, FLAN): train on hundreds of tasks to learn adaptable instruction following. For production systems, multi-task fine-tuning is preferable to single-task when the deployment scenario involves diverse user requests.</p>
<p><strong>Why foundation models + fine-tuning is the dominant paradigm</strong></p>
<p>Training large models from scratch is prohibitively expensive for most organizations. Pretraining costs millions of dollars and requires massive datasets. Fine-tuning pretrained models costs orders of magnitude less‚Äîthousands of dollars, thousands of examples, days instead of months. The paradigm: large labs (OpenAI, Anthropic, Google, Meta) pretrain foundation models and release them (openly or via API). Users fine-tune on task-specific data to specialize for their applications. This division of labor makes large language models accessible: the fixed cost of pretraining is absorbed by providers, the variable cost of fine-tuning is manageable for practitioners. Understanding how to fine-tune effectively‚Äîdata curation, hyperparameters, PEFT methods‚Äîis now an essential skill for deploying AI systems.</p>
<p>The lesson: Fine-tuning is the bridge between general-purpose language models and task-specific tools. Pretrained models provide broad capabilities; fine-tuning narrows focus to desired behaviors. The process is delicate‚Äîadjust parameters enough to learn the task, but not so much that general knowledge is lost. Modern techniques (low learning rates, PEFT, multi-task training) make fine-tuning reliable and efficient. Whether through full fine-tuning, LoRA, or prompting, specializing pretrained models is now the standard approach for building production AI systems.</p>
<hr>
<h2 id="references-and-further-reading-ch23">References and Further Reading</h2>
<p><strong>Training language models to follow instructions with human feedback</strong> ‚Äì Long Ouyang, Jeff Wu, Xu Jiang, et al. (2022)
<a href="https://arxiv.org/abs/2203.02155">https://arxiv.org/abs/2203.02155</a></p>
<p>The InstructGPT paper introduced the approach behind ChatGPT. Ouyang et al. fine-tuned GPT-3 on human-written instructions and responses, then applied reinforcement learning from human feedback (Chapter 24) to align with human preferences. They showed that fine-tuning on ~13,000 high-quality instruction examples dramatically improved helpfulness, truthfulness, and safety compared to raw GPT-3. The paper demonstrates that fine-tuning data quality matters more than quantity and establishes the instruction-following paradigm now used in all major language model assistants. Reading this clarifies how ChatGPT differs from GPT-3: supervised fine-tuning on instruction data transforms a raw predictor into a helpful assistant.</p>
<p><strong>LoRA: Low-Rank Adaptation of Large Language Models</strong> ‚Äì Edward Hu, Yelong Shen, Phillip Wallis, et al. (2021)
<a href="https://arxiv.org/abs/2106.09685">https://arxiv.org/abs/2106.09685</a></p>
<p>Hu et al. introduced LoRA, the most widely used parameter-efficient fine-tuning method. LoRA freezes pretrained weights and adds trainable low-rank matrices, reducing trainable parameters by 10,000√ó (from billions to millions) while maintaining performance comparable to full fine-tuning. The paper shows LoRA works across tasks (question answering, summarization, translation) and models (GPT, T5, BERT). This breakthrough made fine-tuning massive models practical on accessible hardware‚Äîfine-tuning GPT-3-scale models now requires a single GPU instead of a cluster. LoRA is now the default method for task-specific model adaptation in production systems. Understanding LoRA is essential for practitioners deploying large models with limited compute.</p>
<p><strong>Finetuned Language Models Are Zero-Shot Learners</strong> ‚Äì Jason Wei, Maarten Bosma, Vincent Zhao, et al. (2021)
<a href="https://arxiv.org/abs/2109.01652">https://arxiv.org/abs/2109.01652</a></p>
<p>The FLAN paper showed that fine-tuning on diverse tasks simultaneously improves zero-shot performance on unseen tasks. Wei et al. fine-tuned models on over 60 NLP tasks with instructions and demonstrated improved generalization to new tasks without further training. Multi-task instruction fine-tuning teaches models adaptable instruction-following behavior rather than memorizing specific task formats. This established the recipe for modern instruction-tuned models: train on hundreds of diverse tasks to learn general helpfulness. The paper explains why InstructGPT, GPT-4, and other assistants perform well on novel tasks‚Äîthey learned instruction-following as a general capability through diverse fine-tuning. Reading this clarifies how to construct fine-tuning datasets that maximize generalization.</p> </article> <nav class="chapter-navigation" data-astro-cid-pux6a34n> <a href="/eng-ai/part5/22-pretraining" class="nav-prev " data-astro-cid-pux6a34n> <span class="nav-label" data-astro-cid-pux6a34n>‚Üê Previous</span> <span class="nav-title" data-astro-cid-pux6a34n>Pretraining</span> </a> <a href="/eng-ai/part5/24-rlhf" class="nav-next" data-astro-cid-pux6a34n> <span class="nav-label" data-astro-cid-pux6a34n>Next ‚Üí</span> <span class="nav-title" data-astro-cid-pux6a34n>RLHF</span> </a> </nav>  </main> <aside class="chapter-toc"> <nav class="toc" data-astro-cid-xvrfupwn><h4 data-astro-cid-xvrfupwn>On This Page</h4><ul data-astro-cid-xvrfupwn><li class="toc-level-2" data-astro-cid-xvrfupwn><a href="#turning-a-brain-into-a-tool-ch23" data-astro-cid-xvrfupwn>Turning a Brain into a Tool</a></li><li class="toc-level-2" data-astro-cid-xvrfupwn><a href="#why-pretrained-models-are-wild-ch23" data-astro-cid-xvrfupwn>Why Pretrained Models Are Wild</a></li><li class="toc-level-2" data-astro-cid-xvrfupwn><a href="#supervised-fine-tuning-teaching-specific-behaviors-ch23" data-astro-cid-xvrfupwn>Supervised Fine-Tuning: Teaching Specific Behaviors</a></li><li class="toc-level-2" data-astro-cid-xvrfupwn><a href="#instruction-following-learning-to-obey-ch23" data-astro-cid-xvrfupwn>Instruction Following: Learning to Obey</a></li><li class="toc-level-2" data-astro-cid-xvrfupwn><a href="#catastrophic-forgetting-why-tuning-must-be-careful-ch23" data-astro-cid-xvrfupwn>Catastrophic Forgetting: Why Tuning Must Be Careful</a></li><li class="toc-level-2" data-astro-cid-xvrfupwn><a href="#parameter-efficient-fine-tuning-peft-ch23" data-astro-cid-xvrfupwn>Parameter-Efficient Fine-Tuning (PEFT)</a></li><li class="toc-level-2" data-astro-cid-xvrfupwn><a href="#engineering-takeaway-ch23" data-astro-cid-xvrfupwn>Engineering Takeaway</a></li><li class="toc-level-2" data-astro-cid-xvrfupwn><a href="#references-and-further-reading-ch23" data-astro-cid-xvrfupwn>References and Further Reading</a></li></ul></nav> </aside> </div>   </body> </html>