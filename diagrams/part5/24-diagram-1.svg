<?xml version="1.0" encoding="UTF-8"?>
<svg viewBox="0 0 600 350" xmlns="http://www.w3.org/2000/svg">
  <!-- Title -->
  <text x="200" y="25" font-size="14" font-family="monospace" font-weight="bold">RLHF Pipeline</text>

  <!-- Step 1: SFT Model generates responses -->
  <rect x="40" y="60" width="140" height="50" fill="lightblue" stroke="black" stroke-width="2" rx="5"/>
  <text x="50" y="80" font-size="10" font-family="monospace" font-weight="bold">Step 1: Generate</text>
  <text x="50" y="95" font-size="9" font-family="monospace">SFT model produces</text>
  <text x="50" y="107" font-size="9" font-family="monospace">multiple responses</text>

  <!-- Arrow -->
  <line x1="190" y1="85" x2="230" y2="85" stroke="black" stroke-width="2" marker-end="url(#arrow)"/>

  <!-- Step 2: Humans rank -->
  <rect x="230" y="60" width="140" height="50" fill="lightyellow" stroke="black" stroke-width="2" rx="5"/>
  <text x="240" y="80" font-size="10" font-family="monospace" font-weight="bold">Step 2: Rank</text>
  <text x="240" y="95" font-size="9" font-family="monospace">Humans rank outputs</text>
  <text x="240" y="107" font-size="9" font-family="monospace">(A better than B?)</text>

  <!-- Arrow -->
  <line x1="380" y1="85" x2="420" y2="85" stroke="black" stroke-width="2" marker-end="url(#arrow)"/>

  <!-- Step 3: Train reward model -->
  <rect x="420" y="60" width="140" height="50" fill="lightgreen" stroke="black" stroke-width="2" rx="5"/>
  <text x="430" y="80" font-size="10" font-family="monospace" font-weight="bold">Step 3: Reward Model</text>
  <text x="430" y="95" font-size="9" font-family="monospace">Train r(x,y) to</text>
  <text x="430" y="107" font-size="9" font-family="monospace">predict preferences</text>

  <!-- Arrow down -->
  <line x1="110" y1="120" x2="110" y2="160" stroke="black" stroke-width="2" marker-end="url(#arrow)"/>
  <line x1="490" y1="120" x2="490" y2="160" stroke="black" stroke-width="2" marker-end="url(#arrow)"/>

  <!-- Step 4: PPO optimization -->
  <rect x="180" y="170" width="240" height="70" fill="lightcoral" stroke="black" stroke-width="2" rx="5"/>
  <text x="220" y="193" font-size="10" font-family="monospace" font-weight="bold">Step 4: Policy Optimization (PPO)</text>
  <text x="190" y="213" font-size="9" font-family="monospace">Train model to maximize reward</text>
  <text x="190" y="228" font-size="9" font-family="monospace">while staying close to SFT model</text>

  <!-- Feedback loop arrow -->
  <path d="M 420,200 L 450,200 L 450,155 L 110,155 L 110,170" fill="none" stroke="gray" stroke-width="2" stroke-dasharray="4,4" marker-end="url(#arrow-gray)"/>
  <text x="460" y="180" font-size="8" font-family="monospace" fill="gray">Generate</text>
  <text x="460" y="192" font-size="8" font-family="monospace" fill="gray">new</text>
  <text x="460" y="204" font-size="8" font-family="monospace" fill="gray">samples</text>

  <!-- Output -->
  <line x1="300" y1="250" x2="300" y2="280" stroke="black" stroke-width="2" marker-end="url(#arrow)"/>
  <rect x="200" y="290" width="200" height="40" fill="lavender" stroke="black" stroke-width="2" rx="5"/>
  <text x="220" y="313" font-size="10" font-family="monospace" font-weight="bold">Aligned Language Model</text>

  <!-- Annotation -->
  <text x="90" y="335" font-size="9" font-family="monospace" fill="gray">RLHF optimizes for human preferences, not just training data match</text>

  <!-- Arrow markers -->
  <defs>
    <marker id="arrow" markerWidth="10" markerHeight="10" refX="9" refY="3" orient="auto">
      <polygon points="0 0, 10 3, 0 6" fill="black"/>
    </marker>
    <marker id="arrow-gray" markerWidth="10" markerHeight="10" refX="9" refY="3" orient="auto">
      <polygon points="0 0, 10 3, 0 6" fill="gray"/>
    </marker>
  </defs>
</svg>
