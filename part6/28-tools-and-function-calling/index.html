<!DOCTYPE html><html lang="en"> <head><meta charset="UTF-8"><meta name="viewport" content="width=device-width, initial-scale=1.0"><title>Chapter 28: Tools and Function Calling | Engineering Intelligence</title><meta name="description" content="A book for engineers who want to understand Machine Learning and AI from first principles"><!-- Canonical URL --><link rel="canonical" href="https://olivernguyen.io/eng-ai/part6/28-tools-and-function-calling/"><!-- Open Graph / Facebook --><meta property="og:type" content="website"><meta property="og:url" content="https://olivernguyen.io/eng-ai/part6/28-tools-and-function-calling/"><meta property="og:title" content="Chapter 28: Tools and Function Calling | Engineering Intelligence"><meta property="og:description" content="A book for engineers who want to understand Machine Learning and AI from first principles"><meta property="og:image" content="https://olivernguyen.io/eng-ai/og-image.png"><meta property="og:site_name" content="Engineering Intelligence"><!-- Twitter --><meta name="twitter:card" content="summary_large_image"><meta name="twitter:url" content="https://olivernguyen.io/eng-ai/part6/28-tools-and-function-calling/"><meta name="twitter:title" content="Chapter 28: Tools and Function Calling | Engineering Intelligence"><meta name="twitter:description" content="A book for engineers who want to understand Machine Learning and AI from first principles"><meta name="twitter:image" content="https://olivernguyen.io/eng-ai/og-image.png"><!-- Additional Meta --><meta name="author" content="Oliver Nguyen"><meta name="theme-color" content="#2563eb"><!-- Favicon (SVG preferred, PNG fallback) --><link rel="icon" type="image/svg+xml" href="/eng-ai/favicon.svg"><link rel="icon" type="image/png" sizes="32x32" href="/eng-ai/favicon-32x32.png"><link rel="icon" type="image/png" sizes="16x16" href="/eng-ai/favicon-16x16.png"><link rel="apple-touch-icon" sizes="180x180" href="/eng-ai/apple-touch-icon.png"><!-- KaTeX CSS for math rendering --><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css"><!-- Site styles --><link rel="stylesheet" href="/eng-ai/styles/global.css"><link rel="stylesheet" href="/eng-ai/styles/typography.css"><link rel="stylesheet" href="/eng-ai/styles/themes.css"><link rel="stylesheet" href="/eng-ai/styles/print.css"><style>.breadcrumbs[data-astro-cid-ilhxcym7]{margin-bottom:2rem}.breadcrumbs[data-astro-cid-ilhxcym7] ol[data-astro-cid-ilhxcym7]{display:flex;flex-wrap:wrap;gap:.5rem;list-style:none;padding:0;font-size:.9rem}.breadcrumbs[data-astro-cid-ilhxcym7] li[data-astro-cid-ilhxcym7]{display:flex;align-items:center;gap:.5rem}.breadcrumbs[data-astro-cid-ilhxcym7] li[data-astro-cid-ilhxcym7]:not(:last-child):after{content:"‚Ä∫";color:var(--text-muted)}.breadcrumbs[data-astro-cid-ilhxcym7] a[data-astro-cid-ilhxcym7]{color:var(--accent);text-decoration:none}.breadcrumbs[data-astro-cid-ilhxcym7] a[data-astro-cid-ilhxcym7]:hover{text-decoration:underline}.breadcrumbs[data-astro-cid-ilhxcym7] li[data-astro-cid-ilhxcym7][aria-current=page]{color:var(--text-muted)}.toc[data-astro-cid-xvrfupwn]{position:sticky;top:2rem;padding:1rem}.toc[data-astro-cid-xvrfupwn] h4[data-astro-cid-xvrfupwn]{font-size:.9rem;font-weight:600;text-transform:uppercase;letter-spacing:.05em;color:var(--text-muted);margin-bottom:.75rem}.toc[data-astro-cid-xvrfupwn] ul[data-astro-cid-xvrfupwn]{list-style:none;padding:0}.toc[data-astro-cid-xvrfupwn] li[data-astro-cid-xvrfupwn]{margin:.5rem 0}.toc[data-astro-cid-xvrfupwn] a[data-astro-cid-xvrfupwn]{font-size:.85rem;color:var(--text-muted);text-decoration:none;transition:color .2s}.toc[data-astro-cid-xvrfupwn] a[data-astro-cid-xvrfupwn]:hover{color:var(--accent)}.toc-level-2[data-astro-cid-xvrfupwn]{padding-left:0}.toc-level-3[data-astro-cid-xvrfupwn]{padding-left:1rem;font-size:.8rem}.chapter-navigation[data-astro-cid-pux6a34n]{display:flex;justify-content:space-between;gap:2rem;margin:4rem 0 2rem;padding-top:2rem;border-top:1px solid var(--border)}.nav-prev[data-astro-cid-pux6a34n],.nav-next[data-astro-cid-pux6a34n]{display:flex;flex-direction:column;gap:.5rem;padding:1rem;border:1px solid var(--border);border-radius:8px;text-decoration:none;transition:border-color .2s,background .2s;flex:1;max-width:45%}.nav-prev[data-astro-cid-pux6a34n]:hover,.nav-next[data-astro-cid-pux6a34n]:hover{border-color:var(--accent);background:var(--hover-bg)}.nav-prev[data-astro-cid-pux6a34n].placeholder{visibility:hidden}.nav-next[data-astro-cid-pux6a34n]{align-items:flex-end;text-align:right}.nav-label[data-astro-cid-pux6a34n]{font-size:.85rem;font-weight:600;text-transform:uppercase;letter-spacing:.05em;color:var(--accent)}.nav-title[data-astro-cid-pux6a34n]{font-size:1rem;color:var(--text)}
</style>
<link rel="stylesheet" href="/eng-ai/_astro/_chapter_.BUailOsj.css"><script type="module" src="/eng-ai/_astro/hoisted.0uyw1jl9.js"></script></head> <body>  <div class="book-layout"> <button id="mobile-menu-toggle" class="hamburger-button" aria-label="Toggle navigation menu" aria-expanded="false" data-astro-cid-odmlyywb> <span class="hamburger-line" data-astro-cid-odmlyywb></span> <span class="hamburger-line" data-astro-cid-odmlyywb></span> <span class="hamburger-line" data-astro-cid-odmlyywb></span> </button>  <div class="sidebar-overlay" id="sidebar-overlay" data-astro-cid-ssfzsv2f></div> <aside class="sidebar" id="sidebar" data-astro-cid-ssfzsv2f> <!-- Sidebar Controls --> <div class="sidebar-controls" data-astro-cid-ssfzsv2f> <button id="sidebar-close" class="sidebar-close-button" aria-label="Close menu" data-astro-cid-ssfzsv2f> <svg width="20" height="20" viewBox="0 0 20 20" fill="none" data-astro-cid-ssfzsv2f> <line x1="4" y1="4" x2="16" y2="16" stroke="currentColor" stroke-width="2" stroke-linecap="round" data-astro-cid-ssfzsv2f></line> <line x1="16" y1="4" x2="4" y2="16" stroke="currentColor" stroke-width="2" stroke-linecap="round" data-astro-cid-ssfzsv2f></line> </svg> </button> <button id="theme-toggle" class="theme-toggle-button" aria-label="Toggle dark mode" data-astro-cid-ssfzsv2f> <svg class="sun-icon" width="20" height="20" viewBox="0 0 20 20" data-astro-cid-ssfzsv2f> <circle cx="10" cy="10" r="4" fill="currentColor" data-astro-cid-ssfzsv2f></circle> <line x1="10" y1="1" x2="10" y2="3" stroke="currentColor" stroke-width="2" stroke-linecap="round" data-astro-cid-ssfzsv2f></line> <line x1="10" y1="17" x2="10" y2="19" stroke="currentColor" stroke-width="2" stroke-linecap="round" data-astro-cid-ssfzsv2f></line> <line x1="1" y1="10" x2="3" y2="10" stroke="currentColor" stroke-width="2" stroke-linecap="round" data-astro-cid-ssfzsv2f></line> <line x1="17" y1="10" x2="19" y2="10" stroke="currentColor" stroke-width="2" stroke-linecap="round" data-astro-cid-ssfzsv2f></line> <line x1="3.5" y1="3.5" x2="5" y2="5" stroke="currentColor" stroke-width="2" stroke-linecap="round" data-astro-cid-ssfzsv2f></line> <line x1="15" y1="15" x2="16.5" y2="16.5" stroke="currentColor" stroke-width="2" stroke-linecap="round" data-astro-cid-ssfzsv2f></line> <line x1="16.5" y1="3.5" x2="15" y2="5" stroke="currentColor" stroke-width="2" stroke-linecap="round" data-astro-cid-ssfzsv2f></line> <line x1="5" y1="15" x2="3.5" y2="16.5" stroke="currentColor" stroke-width="2" stroke-linecap="round" data-astro-cid-ssfzsv2f></line> </svg> <svg class="moon-icon" width="20" height="20" viewBox="0 0 20 20" data-astro-cid-ssfzsv2f> <path d="M10 2a8 8 0 108 8 6 6 0 01-8-8z" fill="currentColor" data-astro-cid-ssfzsv2f></path> </svg> </button> </div> <div class="sidebar-header" data-astro-cid-ssfzsv2f> <a href="/eng-ai/" data-astro-cid-ssfzsv2f> <h2 data-astro-cid-ssfzsv2f>Engineering Intelligence</h2> </a> </div> <nav class="sidebar-nav" data-astro-cid-ssfzsv2f> <section class="intro-section" data-astro-cid-ssfzsv2f> <ul data-astro-cid-ssfzsv2f> <li class="" data-astro-cid-ssfzsv2f> <a href="/eng-ai/introduction" <span class="intro-icon" data-astro-cid-ssfzsv2f>üìñ
              Introduction
</a> </li> </ul> </section> <section class="part-section" data-astro-cid-ssfzsv2f> <h3 class="" data-astro-cid-ssfzsv2f> <a href="/eng-ai/part1" data-astro-cid-ssfzsv2f>
Part I: Foundations </a> </h3> <ul data-astro-cid-ssfzsv2f> <li class="" data-astro-cid-ssfzsv2f> <a href="/eng-ai/part1/01-why-intelligence-is-not-magic" data-astro-cid-ssfzsv2f> <span class="chapter-num" data-astro-cid-ssfzsv2f>1.</span> Why Intelligence Is Not Magic </a> </li><li class="" data-astro-cid-ssfzsv2f> <a href="/eng-ai/part1/02-data-is-the-new-physics" data-astro-cid-ssfzsv2f> <span class="chapter-num" data-astro-cid-ssfzsv2f>2.</span> Data Is the New Physics </a> </li><li class="" data-astro-cid-ssfzsv2f> <a href="/eng-ai/part1/03-models-are-compression-machines" data-astro-cid-ssfzsv2f> <span class="chapter-num" data-astro-cid-ssfzsv2f>3.</span> Models Are Compression Machines </a> </li><li class="" data-astro-cid-ssfzsv2f> <a href="/eng-ai/part1/04-bias-variance-tradeoff" data-astro-cid-ssfzsv2f> <span class="chapter-num" data-astro-cid-ssfzsv2f>4.</span> The Bias-Variance Tradeoff </a> </li><li class="" data-astro-cid-ssfzsv2f> <a href="/eng-ai/part1/05-features-how-machines-see-the-world" data-astro-cid-ssfzsv2f> <span class="chapter-num" data-astro-cid-ssfzsv2f>5.</span> Features: How Machines See the World </a> </li> </ul> </section><section class="part-section" data-astro-cid-ssfzsv2f> <h3 class="" data-astro-cid-ssfzsv2f> <a href="/eng-ai/part2" data-astro-cid-ssfzsv2f>
Part II: Classical ML </a> </h3> <ul data-astro-cid-ssfzsv2f> <li class="" data-astro-cid-ssfzsv2f> <a href="/eng-ai/part2/06-linear-models" data-astro-cid-ssfzsv2f> <span class="chapter-num" data-astro-cid-ssfzsv2f>6.</span> Linear Models </a> </li><li class="" data-astro-cid-ssfzsv2f> <a href="/eng-ai/part2/07-logistic-regression" data-astro-cid-ssfzsv2f> <span class="chapter-num" data-astro-cid-ssfzsv2f>7.</span> Logistic Regression </a> </li><li class="" data-astro-cid-ssfzsv2f> <a href="/eng-ai/part2/08-decision-trees" data-astro-cid-ssfzsv2f> <span class="chapter-num" data-astro-cid-ssfzsv2f>8.</span> Decision Trees </a> </li><li class="" data-astro-cid-ssfzsv2f> <a href="/eng-ai/part2/09-ensembles" data-astro-cid-ssfzsv2f> <span class="chapter-num" data-astro-cid-ssfzsv2f>9.</span> Ensembles </a> </li><li class="" data-astro-cid-ssfzsv2f> <a href="/eng-ai/part2/10-loss-functions" data-astro-cid-ssfzsv2f> <span class="chapter-num" data-astro-cid-ssfzsv2f>10.</span> Loss Functions and Optimization </a> </li> </ul> </section><section class="part-section" data-astro-cid-ssfzsv2f> <h3 class="" data-astro-cid-ssfzsv2f> <a href="/eng-ai/part3" data-astro-cid-ssfzsv2f>
Part III: Neural Networks </a> </h3> <ul data-astro-cid-ssfzsv2f> <li class="" data-astro-cid-ssfzsv2f> <a href="/eng-ai/part3/11-neurons-as-math" data-astro-cid-ssfzsv2f> <span class="chapter-num" data-astro-cid-ssfzsv2f>11.</span> Neurons as Math </a> </li><li class="" data-astro-cid-ssfzsv2f> <a href="/eng-ai/part3/12-forward-pass" data-astro-cid-ssfzsv2f> <span class="chapter-num" data-astro-cid-ssfzsv2f>12.</span> The Forward Pass </a> </li><li class="" data-astro-cid-ssfzsv2f> <a href="/eng-ai/part3/13-backpropagation" data-astro-cid-ssfzsv2f> <span class="chapter-num" data-astro-cid-ssfzsv2f>13.</span> Backpropagation </a> </li><li class="" data-astro-cid-ssfzsv2f> <a href="/eng-ai/part3/14-optimization-deep-learning" data-astro-cid-ssfzsv2f> <span class="chapter-num" data-astro-cid-ssfzsv2f>14.</span> Optimization in Deep Learning </a> </li><li class="" data-astro-cid-ssfzsv2f> <a href="/eng-ai/part3/15-representation-learning" data-astro-cid-ssfzsv2f> <span class="chapter-num" data-astro-cid-ssfzsv2f>15.</span> Representation Learning </a> </li> </ul> </section><section class="part-section" data-astro-cid-ssfzsv2f> <h3 class="" data-astro-cid-ssfzsv2f> <a href="/eng-ai/part4" data-astro-cid-ssfzsv2f>
Part IV: Deep Architectures </a> </h3> <ul data-astro-cid-ssfzsv2f> <li class="" data-astro-cid-ssfzsv2f> <a href="/eng-ai/part4/16-convolutional-neural-networks" data-astro-cid-ssfzsv2f> <span class="chapter-num" data-astro-cid-ssfzsv2f>16.</span> Convolutional Neural Networks </a> </li><li class="" data-astro-cid-ssfzsv2f> <a href="/eng-ai/part4/17-recurrent-neural-networks" data-astro-cid-ssfzsv2f> <span class="chapter-num" data-astro-cid-ssfzsv2f>17.</span> Recurrent Neural Networks </a> </li><li class="" data-astro-cid-ssfzsv2f> <a href="/eng-ai/part4/18-embeddings" data-astro-cid-ssfzsv2f> <span class="chapter-num" data-astro-cid-ssfzsv2f>18.</span> Embeddings </a> </li><li class="" data-astro-cid-ssfzsv2f> <a href="/eng-ai/part4/19-attention" data-astro-cid-ssfzsv2f> <span class="chapter-num" data-astro-cid-ssfzsv2f>19.</span> Attention </a> </li><li class="" data-astro-cid-ssfzsv2f> <a href="/eng-ai/part4/20-transformers" data-astro-cid-ssfzsv2f> <span class="chapter-num" data-astro-cid-ssfzsv2f>20.</span> Transformers </a> </li> </ul> </section><section class="part-section" data-astro-cid-ssfzsv2f> <h3 class="" data-astro-cid-ssfzsv2f> <a href="/eng-ai/part5" data-astro-cid-ssfzsv2f>
Part V: Language Models </a> </h3> <ul data-astro-cid-ssfzsv2f> <li class="" data-astro-cid-ssfzsv2f> <a href="/eng-ai/part5/21-next-token-prediction" data-astro-cid-ssfzsv2f> <span class="chapter-num" data-astro-cid-ssfzsv2f>21.</span> Next-Token Prediction </a> </li><li class="" data-astro-cid-ssfzsv2f> <a href="/eng-ai/part5/22-pretraining" data-astro-cid-ssfzsv2f> <span class="chapter-num" data-astro-cid-ssfzsv2f>22.</span> Pretraining </a> </li><li class="" data-astro-cid-ssfzsv2f> <a href="/eng-ai/part5/23-fine-tuning" data-astro-cid-ssfzsv2f> <span class="chapter-num" data-astro-cid-ssfzsv2f>23.</span> Fine-Tuning </a> </li><li class="" data-astro-cid-ssfzsv2f> <a href="/eng-ai/part5/24-rlhf" data-astro-cid-ssfzsv2f> <span class="chapter-num" data-astro-cid-ssfzsv2f>24.</span> RLHF </a> </li><li class="" data-astro-cid-ssfzsv2f> <a href="/eng-ai/part5/25-emergent-abilities-and-scaling" data-astro-cid-ssfzsv2f> <span class="chapter-num" data-astro-cid-ssfzsv2f>25.</span> Emergent Abilities and Scaling </a> </li> </ul> </section><section class="part-section" data-astro-cid-ssfzsv2f> <h3 class="" data-astro-cid-ssfzsv2f> <a href="/eng-ai/part6" data-astro-cid-ssfzsv2f>
Part VI: Modern AI Systems </a> </h3> <ul data-astro-cid-ssfzsv2f> <li class="" data-astro-cid-ssfzsv2f> <a href="/eng-ai/part6/26-prompting-as-programming" data-astro-cid-ssfzsv2f> <span class="chapter-num" data-astro-cid-ssfzsv2f>26.</span> Prompting as Programming </a> </li><li class="" data-astro-cid-ssfzsv2f> <a href="/eng-ai/part6/27-retrieval-augmented-generation" data-astro-cid-ssfzsv2f> <span class="chapter-num" data-astro-cid-ssfzsv2f>27.</span> Retrieval-Augmented Generation </a> </li><li class="active" data-astro-cid-ssfzsv2f> <a href="/eng-ai/part6/28-tools-and-function-calling" data-astro-cid-ssfzsv2f> <span class="chapter-num" data-astro-cid-ssfzsv2f>28.</span> Tools and Function Calling </a> </li><li class="" data-astro-cid-ssfzsv2f> <a href="/eng-ai/part6/29-agents" data-astro-cid-ssfzsv2f> <span class="chapter-num" data-astro-cid-ssfzsv2f>29.</span> Agents - Models That Decide What to Do </a> </li><li class="" data-astro-cid-ssfzsv2f> <a href="/eng-ai/part6/30-memory-and-planning" data-astro-cid-ssfzsv2f> <span class="chapter-num" data-astro-cid-ssfzsv2f>30.</span> Memory, Planning, and Long-Term Behavior </a> </li> </ul> </section><section class="part-section" data-astro-cid-ssfzsv2f> <h3 class="" data-astro-cid-ssfzsv2f> <a href="/eng-ai/part7" data-astro-cid-ssfzsv2f>
Part VII: Engineering Reality </a> </h3> <ul data-astro-cid-ssfzsv2f> <li class="" data-astro-cid-ssfzsv2f> <a href="/eng-ai/part7/31-data-pipelines" data-astro-cid-ssfzsv2f> <span class="chapter-num" data-astro-cid-ssfzsv2f>31.</span> Data Pipelines - Where Models Are Born and Die </a> </li><li class="" data-astro-cid-ssfzsv2f> <a href="/eng-ai/part7/32-training-vs-inference" data-astro-cid-ssfzsv2f> <span class="chapter-num" data-astro-cid-ssfzsv2f>32.</span> Training vs Inference - Two Different Worlds </a> </li><li class="" data-astro-cid-ssfzsv2f> <a href="/eng-ai/part7/33-evaluation" data-astro-cid-ssfzsv2f> <span class="chapter-num" data-astro-cid-ssfzsv2f>33.</span> Evaluation - Why Accuracy Is Not Enough </a> </li><li class="" data-astro-cid-ssfzsv2f> <a href="/eng-ai/part7/34-hallucinations-bias-brittleness" data-astro-cid-ssfzsv2f> <span class="chapter-num" data-astro-cid-ssfzsv2f>34.</span> Hallucinations, Bias, and Brittleness </a> </li><li class="" data-astro-cid-ssfzsv2f> <a href="/eng-ai/part7/35-safety-alignment-control" data-astro-cid-ssfzsv2f> <span class="chapter-num" data-astro-cid-ssfzsv2f>35.</span> Safety, Alignment, and Control </a> </li> </ul> </section><section class="part-section" data-astro-cid-ssfzsv2f> <h3 class="" data-astro-cid-ssfzsv2f> <a href="/eng-ai/part8" data-astro-cid-ssfzsv2f>
Part VIII: The Frontier </a> </h3> <ul data-astro-cid-ssfzsv2f> <li class="" data-astro-cid-ssfzsv2f> <a href="/eng-ai/part8/36-scaling-laws" data-astro-cid-ssfzsv2f> <span class="chapter-num" data-astro-cid-ssfzsv2f>36.</span> Scaling Laws - Why Bigger Keeps Winning </a> </li><li class="" data-astro-cid-ssfzsv2f> <a href="/eng-ai/part8/37-multimodal-models" data-astro-cid-ssfzsv2f> <span class="chapter-num" data-astro-cid-ssfzsv2f>37.</span> Multimodal Models </a> </li><li class="" data-astro-cid-ssfzsv2f> <a href="/eng-ai/part8/38-self-improving-systems" data-astro-cid-ssfzsv2f> <span class="chapter-num" data-astro-cid-ssfzsv2f>38.</span> Self-Improving Systems </a> </li><li class="" data-astro-cid-ssfzsv2f> <a href="/eng-ai/part8/39-artificial-general-intelligence" data-astro-cid-ssfzsv2f> <span class="chapter-num" data-astro-cid-ssfzsv2f>39.</span> Artificial General Intelligence </a> </li><li class="" data-astro-cid-ssfzsv2f> <a href="/eng-ai/part8/40-the-engineers-role" data-astro-cid-ssfzsv2f> <span class="chapter-num" data-astro-cid-ssfzsv2f>40.</span> The Engineer&#39;s Role </a> </li> </ul> </section> </nav> </aside>   <main class="chapter-content"> <nav class="breadcrumbs" aria-label="Breadcrumb" data-astro-cid-ilhxcym7> <ol data-astro-cid-ilhxcym7> <li data-astro-cid-ilhxcym7><a href="/eng-ai/" data-astro-cid-ilhxcym7>Home</a></li> <li data-astro-cid-ilhxcym7><a href="/eng-ai/part6" data-astro-cid-ilhxcym7>Part VI: Modern AI Systems</a></li> <li aria-current="page" data-astro-cid-ilhxcym7>Tools and Function Calling</li> </ol> </nav>  <article class="chapter"> <h1 id="chapter-28-tools-and-function-calling">Chapter 28: Tools and Function Calling</h1>
<p>A language model can write poetry, summarize documents, and translate text. But it cannot tell you the current weather, calculate <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mn>2</mn><mn>64</mn></msup></mrow><annotation encoding="application/x-tex">2^{64}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8141em;"></span><span class="mord"><span class="mord">2</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">64</span></span></span></span></span></span></span></span></span></span></span></span> accurately, or book a flight. These limitations are not accidents. They are fundamental to what language models are: systems that predict text based on patterns in training data.</p>
<p>To become useful assistants rather than impressive text generators, language models need tools. Tools are external functions that extend a model‚Äôs capabilities beyond text generation. They provide access to computation, real-time data, and the ability to take actions in the world. The interface between language models and tools has become one of the most important engineering problems in modern AI systems.</p>
<p>This chapter explains how language models learn to use tools, how tool calling works in production systems, and why this capability transforms models from passive responders into active problem solvers.</p>
<hr>
<h2 id="why-llms-need-tools-ch28">Why LLMs Need Tools</h2>
<p>Language models face three fundamental limitations that tools address: <strong>computation</strong>, <strong>knowledge</strong>, and <strong>action</strong>.</p>
<p><strong>Computational limitations.</strong> Despite their sophistication, language models struggle with tasks that require precise arithmetic or symbolic reasoning. Asked to compute <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mn>2</mn><mn>64</mn></msup></mrow><annotation encoding="application/x-tex">2^{64}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8141em;"></span><span class="mord"><span class="mord">2</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">64</span></span></span></span></span></span></span></span></span></span></span></span>, a model might generate ‚Äú18,446,744,073,709,551,616‚Äù by memorizing the answer from training data, or it might hallucinate a plausible-looking but incorrect number. The model has no mechanism for reliably executing arithmetic operations‚Äîit can only predict what text would likely appear after the prompt.</p>
<p>Consider this example:</p>
<pre class="astro-code astro-code-themes github-light github-dark" style="background-color:#fff;--shiki-dark-bg:#24292e;color:#24292e;--shiki-dark:#e1e4e8; overflow-x: auto; white-space: pre-wrap; word-wrap: break-word;" tabindex="0" data-language="plaintext"><code><span class="line"><span>User: What is 8,237 √ó 6,549?</span></span>
<span class="line"><span>Model: 53,941,413</span></span>
<span class="line"><span></span></span>
<span class="line"><span>Correct answer: 53,939,613</span></span>
<span class="line"><span></span></span></code></pre>
<p>The model‚Äôs answer is close but wrong. It generated a number that looks plausible based on the structure of multiplication problems in its training data, but it did not perform the actual computation. For tasks requiring precision‚Äîfinancial calculations, scientific computations, logical operations‚Äîthis unreliability is unacceptable.</p>
<p><strong>Knowledge limitations.</strong> As discussed in Chapter 27, language models have a knowledge cutoff: they know only what was in their training data, frozen at a specific point in time. They cannot access current information, proprietary databases, or user-specific data. Asked ‚ÄúWhat‚Äôs the weather in Tokyo right now?‚Äù a model can only guess based on typical weather patterns, not retrieve the actual current conditions.</p>
<p>Even more limiting, models lack access to structured knowledge bases. A model might know general facts about medications but cannot reliably query a drug interaction database to check if two prescriptions are safe to combine. It cannot look up your calendar to see if you‚Äôre free next Tuesday. It cannot search your company‚Äôs internal documentation to find the deployment procedure for your application.</p>
<p><strong>Action limitations.</strong> Language models produce text. They cannot send emails, create calendar events, execute code, or interact with external systems. A user might ask ‚ÄúBook me a flight to London next week,‚Äù and a model can draft a response explaining how to book a flight, but it cannot actually complete the booking. It has no way to interact with the booking system.</p>
<p>These limitations prevent language models from being useful assistants. Users don‚Äôt just want advice‚Äîthey want tasks completed. Tools bridge this gap.</p>
<hr>
<h2 id="structured-outputs-and-function-calling-ch28">Structured Outputs and Function Calling</h2>
<p>For a language model to use tools, it needs a way to communicate what tool to call and what arguments to pass. This requires moving from freeform text generation to <strong>structured outputs</strong>.</p>
<p><strong>Function calling</strong> is the mechanism that enables this. Instead of only generating text for the user, the model generates structured data‚Äîtypically JSON‚Äîthat specifies:</p>
<ol>
<li>Which tool to call</li>
<li>What arguments to provide</li>
<li>Why this tool call is appropriate</li>
</ol>
<p>Here‚Äôs what a tool call looks like in practice:</p>
<pre class="astro-code astro-code-themes github-light github-dark" style="background-color:#fff;--shiki-dark-bg:#24292e;color:#24292e;--shiki-dark:#e1e4e8; overflow-x: auto; white-space: pre-wrap; word-wrap: break-word;" tabindex="0" data-language="plaintext"><code><span class="line"><span>User: What's 2^64?</span></span>
<span class="line"><span></span></span>
<span class="line"><span>Model generates (internal):</span></span>
<span class="line"><span>{</span></span>
<span class="line"><span>  "tool": "calculator",</span></span>
<span class="line"><span>  "arguments": {</span></span>
<span class="line"><span>    "expression": "2^64"</span></span>
<span class="line"><span>  },</span></span>
<span class="line"><span>  "reasoning": "User asked for precise computation"</span></span>
<span class="line"><span>}</span></span>
<span class="line"><span></span></span>
<span class="line"><span>Tool executes: calculator.evaluate("2^64")</span></span>
<span class="line"><span>Tool returns: 18446744073709551616</span></span>
<span class="line"><span></span></span>
<span class="line"><span>Model generates (to user):</span></span>
<span class="line"><span>2^64 equals 18,446,744,073,709,551,616.</span></span>
<span class="line"><span></span></span></code></pre>
<p>The model does not hallucinate the answer. Instead, it recognizes that this query requires precise computation, selects the appropriate tool, constructs a valid function call, and incorporates the result into its response.</p>
<p><strong>Tool schemas</strong> describe available tools to the model. A tool schema includes:</p>
<ul>
<li><strong>Name</strong>: An identifier for the tool</li>
<li><strong>Description</strong>: What the tool does (in natural language)</li>
<li><strong>Parameters</strong>: What inputs the tool expects (with types and descriptions)</li>
<li><strong>Return type</strong>: What the tool outputs</li>
</ul>
<p>Here‚Äôs an example schema for a calculator tool:</p>
<pre class="astro-code astro-code-themes github-light github-dark" style="background-color:#fff;--shiki-dark-bg:#24292e;color:#24292e;--shiki-dark:#e1e4e8; overflow-x: auto; white-space: pre-wrap; word-wrap: break-word;" tabindex="0" data-language="json"><code><span class="line"><span style="color:#24292E;--shiki-dark:#E1E4E8">{</span></span>
<span class="line"><span style="color:#005CC5;--shiki-dark:#79B8FF">  "name"</span><span style="color:#24292E;--shiki-dark:#E1E4E8">: </span><span style="color:#032F62;--shiki-dark:#9ECBFF">"calculator"</span><span style="color:#24292E;--shiki-dark:#E1E4E8">,</span></span>
<span class="line"><span style="color:#005CC5;--shiki-dark:#79B8FF">  "description"</span><span style="color:#24292E;--shiki-dark:#E1E4E8">: </span><span style="color:#032F62;--shiki-dark:#9ECBFF">"Evaluates mathematical expressions with arbitrary precision. Use this for any arithmetic, including exponentiation, logarithms, trigonometry, and complex calculations."</span><span style="color:#24292E;--shiki-dark:#E1E4E8">,</span></span>
<span class="line"><span style="color:#005CC5;--shiki-dark:#79B8FF">  "parameters"</span><span style="color:#24292E;--shiki-dark:#E1E4E8">: {</span></span>
<span class="line"><span style="color:#005CC5;--shiki-dark:#79B8FF">    "type"</span><span style="color:#24292E;--shiki-dark:#E1E4E8">: </span><span style="color:#032F62;--shiki-dark:#9ECBFF">"object"</span><span style="color:#24292E;--shiki-dark:#E1E4E8">,</span></span>
<span class="line"><span style="color:#005CC5;--shiki-dark:#79B8FF">    "properties"</span><span style="color:#24292E;--shiki-dark:#E1E4E8">: {</span></span>
<span class="line"><span style="color:#005CC5;--shiki-dark:#79B8FF">      "expression"</span><span style="color:#24292E;--shiki-dark:#E1E4E8">: {</span></span>
<span class="line"><span style="color:#005CC5;--shiki-dark:#79B8FF">        "type"</span><span style="color:#24292E;--shiki-dark:#E1E4E8">: </span><span style="color:#032F62;--shiki-dark:#9ECBFF">"string"</span><span style="color:#24292E;--shiki-dark:#E1E4E8">,</span></span>
<span class="line"><span style="color:#005CC5;--shiki-dark:#79B8FF">        "description"</span><span style="color:#24292E;--shiki-dark:#E1E4E8">: </span><span style="color:#032F62;--shiki-dark:#9ECBFF">"The mathematical expression to evaluate, e.g., '2^64' or 'sin(pi/4)'"</span></span>
<span class="line"><span style="color:#24292E;--shiki-dark:#E1E4E8">      }</span></span>
<span class="line"><span style="color:#24292E;--shiki-dark:#E1E4E8">    },</span></span>
<span class="line"><span style="color:#005CC5;--shiki-dark:#79B8FF">    "required"</span><span style="color:#24292E;--shiki-dark:#E1E4E8">: [</span><span style="color:#032F62;--shiki-dark:#9ECBFF">"expression"</span><span style="color:#24292E;--shiki-dark:#E1E4E8">]</span></span>
<span class="line"><span style="color:#24292E;--shiki-dark:#E1E4E8">  },</span></span>
<span class="line"><span style="color:#005CC5;--shiki-dark:#79B8FF">  "returns"</span><span style="color:#24292E;--shiki-dark:#E1E4E8">: {</span></span>
<span class="line"><span style="color:#005CC5;--shiki-dark:#79B8FF">    "type"</span><span style="color:#24292E;--shiki-dark:#E1E4E8">: </span><span style="color:#032F62;--shiki-dark:#9ECBFF">"number"</span><span style="color:#24292E;--shiki-dark:#E1E4E8">,</span></span>
<span class="line"><span style="color:#005CC5;--shiki-dark:#79B8FF">    "description"</span><span style="color:#24292E;--shiki-dark:#E1E4E8">: </span><span style="color:#032F62;--shiki-dark:#9ECBFF">"The numerical result of the calculation"</span></span>
<span class="line"><span style="color:#24292E;--shiki-dark:#E1E4E8">  }</span></span>
<span class="line"><span style="color:#24292E;--shiki-dark:#E1E4E8">}</span></span>
<span class="line"></span></code></pre>
<p>Notice that the description is written in natural language. The model learns from this description when to use the tool and how to construct arguments. <strong>Tool descriptions are prompts</strong>: they guide the model‚Äôs decision-making just as system prompts guide its overall behavior.</p>
<p>The parameters section uses JSON Schema to specify types and constraints. This enables automatic validation: the system can verify that the model generated a valid tool call before attempting execution.</p>
<p><strong>Structured output guarantees.</strong> Modern language models can be constrained to generate valid JSON matching a schema. This is done through <strong>constrained decoding</strong>: the model‚Äôs token generation is restricted to only produce tokens that could be part of a valid JSON object. This eliminates malformed outputs and ensures reliable parsing.</p>
<p>For example, if a tool requires a <code>date</code> field in ISO 8601 format, constrained decoding ensures the model generates <code>"2024-03-15"</code> rather than <code>"March 15, 2024"</code> or <code>"15/03/24"</code>. The schema acts as a hard constraint on generation.</p>
<p><strong>Tool calling flow.</strong> Here‚Äôs how the complete process works:</p>
<p><img  src="/eng-ai/_astro/28-diagram-1.BL6lYObG_Z1yMf4D.svg" alt="Structured Outputs and Function Calling diagram" width="800" height="400" loading="lazy" decoding="async"></p>
<p><strong>Figure 28.1</strong>: The complete tool calling flow. The model (1) receives a query, (2) generates structured JSON specifying which tool to call, (3) the system parses and validates the JSON, (4) executes the tool, (5) returns the result to the model, and (6) the model generates a final response incorporating the tool‚Äôs output.</p>
<hr>
<h2 id="tool-selection-how-models-decide-what-to-call-ch28">Tool Selection: How Models Decide What to Call</h2>
<p>When a model has access to multiple tools, it must decide which tool (if any) to call based on the user‚Äôs query. This decision happens through the same mechanism as all model behavior: next-token prediction guided by context.</p>
<p>Consider a model with access to three tools: <code>calculator</code>, <code>web_search</code>, and <code>get_weather</code>. Given the query ‚ÄúWhat‚Äôs the weather in Tokyo?‚Äù, the model must:</p>
<ol>
<li>Recognize that this query requires external information</li>
<li>Select the appropriate tool (<code>get_weather</code>, not <code>calculator</code> or <code>web_search</code>)</li>
<li>Construct the correct arguments (<code>{"location": "Tokyo"}</code>)</li>
</ol>
<p>This reasoning happens implicitly during generation. The model‚Äôs training included examples of tool use, so it has learned patterns like:</p>
<ul>
<li>Questions about current weather ‚Üí <code>get_weather</code> tool</li>
<li>Requests for arithmetic ‚Üí <code>calculator</code> tool</li>
<li>Questions about recent events ‚Üí <code>web_search</code> tool</li>
</ul>
<p>The tool descriptions in the context help the model make this decision. A well-written description makes tool selection more reliable:</p>
<p><strong>Bad description:</strong></p>
<pre class="astro-code astro-code-themes github-light github-dark" style="background-color:#fff;--shiki-dark-bg:#24292e;color:#24292e;--shiki-dark:#e1e4e8; overflow-x: auto; white-space: pre-wrap; word-wrap: break-word;" tabindex="0" data-language="json"><code><span class="line"><span style="color:#032F62;--shiki-dark:#9ECBFF">"description"</span><span style="color:#24292E;--shiki-dark:#E1E4E8">: </span><span style="color:#032F62;--shiki-dark:#9ECBFF">"Gets weather information"</span></span>
<span class="line"></span></code></pre>
<p><strong>Good description:</strong></p>
<pre class="astro-code astro-code-themes github-light github-dark" style="background-color:#fff;--shiki-dark-bg:#24292e;color:#24292e;--shiki-dark:#e1e4e8; overflow-x: auto; white-space: pre-wrap; word-wrap: break-word;" tabindex="0" data-language="json"><code><span class="line"><span style="color:#032F62;--shiki-dark:#9ECBFF">"description"</span><span style="color:#24292E;--shiki-dark:#E1E4E8">: </span><span style="color:#032F62;--shiki-dark:#9ECBFF">"Returns current weather conditions (temperature, precipitation, wind, humidity) for a specified location. Use this when users ask about current or real-time weather. For weather forecasts, use get_forecast instead."</span></span>
<span class="line"></span></code></pre>
<p>The good description clarifies when to use the tool, what it returns, and how it differs from similar tools. It helps the model make better decisions.</p>
<p><strong>Multi-step reasoning.</strong> Sometimes the model must chain multiple tools to answer a query. Consider:</p>
<pre class="astro-code astro-code-themes github-light github-dark" style="background-color:#fff;--shiki-dark-bg:#24292e;color:#24292e;--shiki-dark:#e1e4e8; overflow-x: auto; white-space: pre-wrap; word-wrap: break-word;" tabindex="0" data-language="plaintext"><code><span class="line"><span>User: How much would 150 euros be worth in dollars at the current exchange rate?</span></span>
<span class="line"><span></span></span></code></pre>
<p>This requires two steps:</p>
<ol>
<li>Call <code>get_exchange_rate</code> to fetch EUR‚ÜíUSD rate</li>
<li>Call <code>calculator</code> to compute <code>150 * rate</code></li>
</ol>
<p>The model must recognize this dependency and plan the sequence of tool calls. Modern systems handle this through <strong>execution loops</strong> that allow the model to observe results and decide on next actions.</p>
<p><strong>Tool call failures.</strong> Models sometimes make errors in tool selection:</p>
<ul>
<li><strong>Wrong tool</strong>: Calling <code>web_search</code> for a math problem</li>
<li><strong>Missing arguments</strong>: Calling <code>get_weather</code> without specifying a location</li>
<li><strong>Invalid arguments</strong>: Passing a date string where a number is expected</li>
</ul>
<p>Production systems handle these failures through error messages fed back to the model, allowing it to correct mistakes and retry.</p>
<hr>
<h2 id="execution-loops-acting-on-tool-results-ch28">Execution Loops: Acting on Tool Results</h2>
<p>A simple tool-using system might work like this:</p>
<ol>
<li>User sends query</li>
<li>Model generates tool call</li>
<li>System executes tool</li>
<li>Model generates final response</li>
</ol>
<p>But real tasks often require multiple rounds of tool use. The model needs to see the result of one tool call before deciding what to do next. This requires an <strong>execution loop</strong>.</p>
<p><strong>The ReAct pattern</strong> (Reasoning and Acting) is a common architecture for execution loops:</p>
<pre class="astro-code astro-code-themes github-light github-dark" style="background-color:#fff;--shiki-dark-bg:#24292e;color:#24292e;--shiki-dark:#e1e4e8; overflow-x: auto; white-space: pre-wrap; word-wrap: break-word;" tabindex="0" data-language="plaintext"><code><span class="line"><span>Observation: [Current state of the problem]</span></span>
<span class="line"><span>Thought: [Reasoning about what to do next]</span></span>
<span class="line"><span>Action: [Tool call to execute]</span></span>
<span class="line"><span>Observation: [Result of the tool call]</span></span>
<span class="line"><span>Thought: [Reasoning about the result]</span></span>
<span class="line"><span>Action: [Next tool call, or Final Answer]</span></span>
<span class="line"><span></span></span></code></pre>
<p>This loop continues until the model generates a ‚ÄúFinal Answer‚Äù action indicating it‚Äôs ready to respond to the user.</p>
<p>Here‚Äôs a concrete example:</p>
<pre class="astro-code astro-code-themes github-light github-dark" style="background-color:#fff;--shiki-dark-bg:#24292e;color:#24292e;--shiki-dark:#e1e4e8; overflow-x: auto; white-space: pre-wrap; word-wrap: break-word;" tabindex="0" data-language="plaintext"><code><span class="line"><span>User: What's the weather like in the capital of Japan?</span></span>
<span class="line"><span></span></span>
<span class="line"><span>Observation: User asked about weather in Japan's capital</span></span>
<span class="line"><span>Thought: I need to first determine Japan's capital, which is Tokyo</span></span>
<span class="line"><span>Action: get_weather({"location": "Tokyo"})</span></span>
<span class="line"><span></span></span>
<span class="line"><span>Observation: {"temperature": 18, "condition": "partly cloudy", "humidity": 65}</span></span>
<span class="line"><span>Thought: I now have the weather information for Tokyo</span></span>
<span class="line"><span>Action: Final Answer</span></span>
<span class="line"><span></span></span>
<span class="line"><span>Response: The weather in Tokyo (Japan's capital) is currently partly cloudy</span></span>
<span class="line"><span>with a temperature of 18¬∞C and 65% humidity.</span></span>
<span class="line"><span></span></span></code></pre>
<p>The model first identifies that it needs to know Japan‚Äôs capital (which it knows from training), then calls the weather tool, then synthesizes the information into a response.</p>
<p><strong>Execution loop structure.</strong> The system maintains a conversation where tool results are injected as assistant messages:</p>
<pre class="astro-code astro-code-themes github-light github-dark" style="background-color:#fff;--shiki-dark-bg:#24292e;color:#24292e;--shiki-dark:#e1e4e8; overflow-x: auto; white-space: pre-wrap; word-wrap: break-word;" tabindex="0" data-language="plaintext"><code><span class="line"><span>System: You have access to tools: get_weather, calculator, web_search...</span></span>
<span class="line"><span>User: What's 2^64?</span></span>
<span class="line"><span>Assistant: &#x3C;tool_call>calculator({"expression": "2^64"})&#x3C;/tool_call></span></span>
<span class="line"><span>Tool: &#x3C;tool_result>18446744073709551616&#x3C;/tool_result></span></span>
<span class="line"><span>Assistant: 2^64 equals 18,446,744,073,709,551,616.</span></span>
<span class="line"><span></span></span></code></pre>
<p>Each tool call and result becomes part of the conversation context, allowing the model to build on previous actions.</p>
<p><strong>Error handling in loops.</strong> When a tool call fails, the error message is fed back to the model:</p>
<pre class="astro-code astro-code-themes github-light github-dark" style="background-color:#fff;--shiki-dark-bg:#24292e;color:#24292e;--shiki-dark:#e1e4e8; overflow-x: auto; white-space: pre-wrap; word-wrap: break-word;" tabindex="0" data-language="plaintext"><code><span class="line"><span>Assistant: &#x3C;tool_call>get_weather({"location": "Toky"})&#x3C;/tool_call></span></span>
<span class="line"><span>Tool: &#x3C;error>Location "Toky" not found. Did you mean "Tokyo"?&#x3C;/error></span></span>
<span class="line"><span>Assistant: &#x3C;tool_call>get_weather({"location": "Tokyo"})&#x3C;/tool_call></span></span>
<span class="line"><span>Tool: &#x3C;tool_result>{"temperature": 18, "condition": "partly cloudy"}&#x3C;/tool_result></span></span>
<span class="line"><span></span></span></code></pre>
<p>The model corrects its typo based on the error feedback. This self-correction is a powerful property of execution loops.</p>
<p><strong>Loop termination.</strong> Execution loops need termination conditions to prevent infinite loops:</p>
<ul>
<li><strong>Max iterations</strong>: Stop after N tool calls (typically 5-10)</li>
<li><strong>Budget limits</strong>: Stop after exceeding token budget</li>
<li><strong>Final answer detection</strong>: Stop when model generates a final response</li>
</ul>
<p>These safeguards prevent runaway execution while allowing enough iterations for complex tasks.</p>
<hr>
<h2 id="tool-composition-and-complex-tasks-ch28">Tool Composition and Complex Tasks</h2>
<p>The real power of tool-using systems emerges when models chain multiple tools to complete complex tasks that require knowledge, computation, and action.</p>
<p><strong>Example: Planning a trip</strong></p>
<pre class="astro-code astro-code-themes github-light github-dark" style="background-color:#fff;--shiki-dark-bg:#24292e;color:#24292e;--shiki-dark:#e1e4e8; overflow-x: auto; white-space: pre-wrap; word-wrap: break-word;" tabindex="0" data-language="plaintext"><code><span class="line"><span>User: I'm traveling to London next week. What should I pack?</span></span>
<span class="line"><span></span></span>
<span class="line"><span>Tool calls:</span></span>
<span class="line"><span>1. get_weather_forecast({"location": "London", "days": 7})</span></span>
<span class="line"><span>   ‚Üí Returns: Rainy, 12-16¬∞C</span></span>
<span class="line"><span>2. web_search({"query": "London events next week"})</span></span>
<span class="line"><span>   ‚Üí Returns: Marathon on Saturday, museum exhibitions</span></span>
<span class="line"><span>3. Final response: "Pack layers for 12-16¬∞C weather, bring a rain jacket..."</span></span>
<span class="line"><span></span></span></code></pre>
<p>The model combined weather data with event information to give comprehensive packing advice.</p>
<p>This is an example of <strong>multi-tool composition</strong>, where the model chains different tools to gather complementary information:</p>
<p><img  src="/eng-ai/_astro/28-diagram-2.BcPyGivU_Z2btYrx.svg" alt="Tool Composition and Complex Tasks diagram" width="700" height="500" loading="lazy" decoding="async"></p>
<p><strong>Figure 28.2</strong>: Multi-tool composition for complex queries. The model orchestrates parallel calls to multiple tools (weather forecast, web search, currency conversion), gathers the results, and synthesizes them into a comprehensive response. This pattern enables answering questions that require information from diverse sources.</p>
<p><strong>Example: Code interpreter</strong></p>
<p>Some production systems (like OpenAI‚Äôs Code Interpreter) give models access to a Python execution environment:</p>
<pre class="astro-code astro-code-themes github-light github-dark" style="background-color:#fff;--shiki-dark-bg:#24292e;color:#24292e;--shiki-dark:#e1e4e8; overflow-x: auto; white-space: pre-wrap; word-wrap: break-word;" tabindex="0" data-language="plaintext"><code><span class="line"><span>User: Analyze this CSV file and plot monthly sales trends</span></span>
<span class="line"><span></span></span>
<span class="line"><span>Tool calls:</span></span>
<span class="line"><span>1. python_execute({"code": "import pandas as pd\ndf = pd.read_csv('sales.csv')\ndf.head()"})</span></span>
<span class="line"><span>   ‚Üí Returns: First 5 rows of data</span></span>
<span class="line"><span>2. python_execute({"code": "df.groupby('month')['sales'].sum().plot()"})</span></span>
<span class="line"><span>   ‚Üí Returns: [Plot image]</span></span>
<span class="line"><span>3. Final response: [Shows plot and analysis]</span></span>
<span class="line"><span></span></span></code></pre>
<p>The model writes code, sees the output, and iterates until the task is complete. This is a form of programming through natural language: the user describes what they want, and the model orchestrates computation to achieve it.</p>
<p><strong>Tool composition patterns.</strong> Common patterns emerge:</p>
<ul>
<li><strong>Sequential</strong>: One tool‚Äôs output is the next tool‚Äôs input</li>
<li><strong>Parallel</strong>: Multiple tools called simultaneously with independent inputs</li>
<li><strong>Conditional</strong>: Tool selection depends on previous results</li>
<li><strong>Iterative</strong>: Same tool called multiple times with refined inputs</li>
</ul>
<p>Production systems optimize these patterns. For instance, if the model calls <code>web_search</code> twice with independent queries, the system can execute both searches in parallel rather than sequentially.</p>
<p><strong>State management.</strong> Some tools maintain state across calls. A database tool might support:</p>
<pre class="astro-code astro-code-themes github-light github-dark" style="background-color:#fff;--shiki-dark-bg:#24292e;color:#24292e;--shiki-dark:#e1e4e8; overflow-x: auto; white-space: pre-wrap; word-wrap: break-word;" tabindex="0" data-language="plaintext"><code><span class="line"><span>1. database_query({"sql": "CREATE TEMP TABLE results ..."})</span></span>
<span class="line"><span>2. database_query({"sql": "SELECT * FROM results WHERE ..."})</span></span>
<span class="line"><span></span></span></code></pre>
<p>The second query depends on state created by the first. The execution environment must maintain this state throughout the loop.</p>
<hr>
<h2 id="engineering-takeaway-ch28">Engineering Takeaway</h2>
<p><strong>Tools transform language models from text predictors into system controllers.</strong> The model becomes the orchestration layer that decides what to compute, what to retrieve, and what actions to take. This architectural shift has several implications for building production AI systems:</p>
<p><strong>Tools extend capabilities without retraining.</strong> Adding a new tool requires only writing a schema and description‚Äîno model updates needed. This enables rapid iteration. Need the model to interact with your internal API? Write a tool definition. Need it to access a new database? Add a tool. The model learns to use new tools from their descriptions.</p>
<p><strong>Structured outputs require enforcement.</strong> Malformed JSON breaks tool execution. Production systems use constrained decoding to guarantee valid outputs, but this adds latency. The trade-off: reliability vs. speed. For critical tools (like financial transactions), guaranteed structure is essential. For optional tools (like search), looser constraints may be acceptable.</p>
<p><strong>Tool descriptions are the new API documentation.</strong> Clear, detailed descriptions improve tool selection. Vague descriptions cause the model to misuse tools. Writing good tool descriptions is now a skill: they must be precise enough to guide selection but concise enough to fit in context. This is prompt engineering applied to tool design.</p>
<p><strong>Execution loops need careful error handling.</strong> Tool failures happen: network errors, invalid inputs, timeouts. These failures must be surfaced to the model as error messages, allowing correction. But not all errors should be exposed‚Äîinternal system errors should be caught and logged, not fed to the model. Error messages themselves are prompts that affect model behavior.</p>
<p><strong>Security is paramount.</strong> Tools give models access to external systems. A compromised model or malicious input could call tools with harmful arguments. Production systems require:</p>
<ul>
<li><strong>Input sanitization</strong>: Validate tool arguments before execution</li>
<li><strong>Access control</strong>: Restrict which tools can be called in which contexts</li>
<li><strong>Human approval</strong>: Require confirmation for dangerous actions (sending emails, making purchases)</li>
<li><strong>Audit logging</strong>: Record all tool calls for security review</li>
</ul>
<p><strong>Models as orchestrators enable new architectures.</strong> Rather than building custom code for every task, you can provide tools and let the model figure out how to combine them. This is a shift from imperative programming (‚Äúfirst do X, then Y‚Äù) to declarative programming (‚Äúhere are available tools, achieve goal Z‚Äù). The model becomes an intelligent orchestration layer.</p>
<p><strong>Tool use is now standard in production assistants.</strong> ChatGPT‚Äôs plugins, Claude‚Äôs tool use, GitHub Copilot‚Äôs context fetching‚Äîall modern AI assistants use tools. A language model without tools is an impressive demo. A language model with tools is a useful system. The difference is the ability to ground responses in computation and data, not just prediction.</p>
<hr>
<h2 id="references-and-further-reading-ch28">References and Further Reading</h2>
<p><strong>Toolformer: Language Models Can Teach Themselves to Use Tools</strong>
Schick, T., Dwivedi-Yu, J., Dess√¨, R., Raileanu, R., Lomeli, M., Zettlemoyer, L., Cancedda, N., &#x26; Scialom, T. (2023). <em>arXiv:2302.04761</em></p>
<p><em>Why it matters:</em> This paper demonstrated that language models can learn when and how to use tools through self-supervised learning. The model generates its own training data by deciding when tool calls would be helpful, executing them, and training on examples where tools improved predictions. This showed that tool use can be learned, not just hardcoded‚Äîa key insight for making tool use reliable and generalizable.</p>
<p><strong>ReAct: Synergizing Reasoning and Acting in Language Models</strong>
Yao, S., Zhao, J., Yu, D., Du, N., Shafran, I., Narasimhan, K., &#x26; Cao, Y. (2023). <em>ICLR 2023</em></p>
<p><em>Why it matters:</em> ReAct introduced the execution loop pattern where models alternate between reasoning (thinking about what to do) and acting (calling tools). By making reasoning explicit, the model‚Äôs decision-making becomes interpretable: you can see why it chose each tool. This pattern has become standard in production agent systems because it enables debugging and improves reliability through structured thinking.</p>
<p><strong>Gorilla: Large Language Model Connected with Massive APIs</strong>
Patil, S. G., Zhang, T., Wang, X., &#x26; Gonzalez, J. E. (2023). <em>arXiv:2305.15334</em></p>
<p><em>Why it matters:</em> This work addressed the practical challenge of scaling to thousands of APIs. Models struggle to select the right tool when there are hundreds of options. Gorilla used retrieval to fetch relevant API documentation based on the query, then selected from that narrowed set. This hierarchical approach‚Äîretrieve then select‚Äîis now used in systems with many tools, showing that tool use systems require careful engineering as they scale.</p>
<hr>
<p>The next chapter examines how tool-using systems become <strong>agents</strong>: autonomous systems that pursue goals through planning, reflection, and self-correction over extended periods.</p> </article> <nav class="chapter-navigation" data-astro-cid-pux6a34n> <a href="/eng-ai/part6/27-retrieval-augmented-generation" class="nav-prev " data-astro-cid-pux6a34n> <span class="nav-label" data-astro-cid-pux6a34n>‚Üê Previous</span> <span class="nav-title" data-astro-cid-pux6a34n>Retrieval-Augmented Generation</span> </a> <a href="/eng-ai/part6/29-agents" class="nav-next" data-astro-cid-pux6a34n> <span class="nav-label" data-astro-cid-pux6a34n>Next ‚Üí</span> <span class="nav-title" data-astro-cid-pux6a34n>Agents - Models That Decide What to Do</span> </a> </nav>  </main> <aside class="chapter-toc"> <nav class="toc" data-astro-cid-xvrfupwn><h4 data-astro-cid-xvrfupwn>On This Page</h4><ul data-astro-cid-xvrfupwn><li class="toc-level-2" data-astro-cid-xvrfupwn><a href="#why-llms-need-tools-ch28" data-astro-cid-xvrfupwn>Why LLMs Need Tools</a></li><li class="toc-level-2" data-astro-cid-xvrfupwn><a href="#structured-outputs-and-function-calling-ch28" data-astro-cid-xvrfupwn>Structured Outputs and Function Calling</a></li><li class="toc-level-2" data-astro-cid-xvrfupwn><a href="#tool-selection-how-models-decide-what-to-call-ch28" data-astro-cid-xvrfupwn>Tool Selection: How Models Decide What to Call</a></li><li class="toc-level-2" data-astro-cid-xvrfupwn><a href="#execution-loops-acting-on-tool-results-ch28" data-astro-cid-xvrfupwn>Execution Loops: Acting on Tool Results</a></li><li class="toc-level-2" data-astro-cid-xvrfupwn><a href="#tool-composition-and-complex-tasks-ch28" data-astro-cid-xvrfupwn>Tool Composition and Complex Tasks</a></li><li class="toc-level-2" data-astro-cid-xvrfupwn><a href="#engineering-takeaway-ch28" data-astro-cid-xvrfupwn>Engineering Takeaway</a></li><li class="toc-level-2" data-astro-cid-xvrfupwn><a href="#references-and-further-reading-ch28" data-astro-cid-xvrfupwn>References and Further Reading</a></li></ul></nav> </aside> </div>   </body> </html>