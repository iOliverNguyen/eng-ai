<!DOCTYPE html><html lang="en"> <head><meta charset="UTF-8"><meta name="viewport" content="width=device-width, initial-scale=1.0"><title>Chapter 31: Data Pipelines - Where Models Are Born and Die | Engineering Intelligence</title><meta name="description" content="A book for engineers who want to understand Machine Learning and AI from first principles"><!-- Canonical URL --><link rel="canonical" href="https://olivernguyen.io/eng-ai/part7/31-data-pipelines/"><!-- Open Graph / Facebook --><meta property="og:type" content="website"><meta property="og:url" content="https://olivernguyen.io/eng-ai/part7/31-data-pipelines/"><meta property="og:title" content="Chapter 31: Data Pipelines - Where Models Are Born and Die | Engineering Intelligence"><meta property="og:description" content="A book for engineers who want to understand Machine Learning and AI from first principles"><meta property="og:image" content="https://olivernguyen.io/eng-ai/og-image.png"><meta property="og:site_name" content="Engineering Intelligence"><!-- Twitter --><meta name="twitter:card" content="summary_large_image"><meta name="twitter:url" content="https://olivernguyen.io/eng-ai/part7/31-data-pipelines/"><meta name="twitter:title" content="Chapter 31: Data Pipelines - Where Models Are Born and Die | Engineering Intelligence"><meta name="twitter:description" content="A book for engineers who want to understand Machine Learning and AI from first principles"><meta name="twitter:image" content="https://olivernguyen.io/eng-ai/og-image.png"><!-- Additional Meta --><meta name="author" content="Oliver Nguyen"><meta name="theme-color" content="#2563eb"><!-- Favicon (SVG preferred, PNG fallback) --><link rel="icon" type="image/svg+xml" href="/eng-ai/favicon.svg"><link rel="icon" type="image/png" sizes="32x32" href="/eng-ai/favicon-32x32.png"><link rel="icon" type="image/png" sizes="16x16" href="/eng-ai/favicon-16x16.png"><link rel="apple-touch-icon" sizes="180x180" href="/eng-ai/apple-touch-icon.png"><!-- KaTeX CSS for math rendering --><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css"><!-- Site styles --><link rel="stylesheet" href="/eng-ai/styles/global.css"><link rel="stylesheet" href="/eng-ai/styles/typography.css"><link rel="stylesheet" href="/eng-ai/styles/themes.css"><link rel="stylesheet" href="/eng-ai/styles/print.css"><style>.breadcrumbs[data-astro-cid-ilhxcym7]{margin-bottom:2rem}.breadcrumbs[data-astro-cid-ilhxcym7] ol[data-astro-cid-ilhxcym7]{display:flex;flex-wrap:wrap;gap:.5rem;list-style:none;padding:0;font-size:.9rem}.breadcrumbs[data-astro-cid-ilhxcym7] li[data-astro-cid-ilhxcym7]{display:flex;align-items:center;gap:.5rem}.breadcrumbs[data-astro-cid-ilhxcym7] li[data-astro-cid-ilhxcym7]:not(:last-child):after{content:"‚Ä∫";color:var(--text-muted)}.breadcrumbs[data-astro-cid-ilhxcym7] a[data-astro-cid-ilhxcym7]{color:var(--accent);text-decoration:none}.breadcrumbs[data-astro-cid-ilhxcym7] a[data-astro-cid-ilhxcym7]:hover{text-decoration:underline}.breadcrumbs[data-astro-cid-ilhxcym7] li[data-astro-cid-ilhxcym7][aria-current=page]{color:var(--text-muted)}.toc[data-astro-cid-xvrfupwn]{position:sticky;top:2rem;padding:1rem}.toc[data-astro-cid-xvrfupwn] h4[data-astro-cid-xvrfupwn]{font-size:.9rem;font-weight:600;text-transform:uppercase;letter-spacing:.05em;color:var(--text-muted);margin-bottom:.75rem}.toc[data-astro-cid-xvrfupwn] ul[data-astro-cid-xvrfupwn]{list-style:none;padding:0}.toc[data-astro-cid-xvrfupwn] li[data-astro-cid-xvrfupwn]{margin:.5rem 0}.toc[data-astro-cid-xvrfupwn] a[data-astro-cid-xvrfupwn]{font-size:.85rem;color:var(--text-muted);text-decoration:none;transition:color .2s}.toc[data-astro-cid-xvrfupwn] a[data-astro-cid-xvrfupwn]:hover{color:var(--accent)}.toc-level-2[data-astro-cid-xvrfupwn]{padding-left:0}.toc-level-3[data-astro-cid-xvrfupwn]{padding-left:1rem;font-size:.8rem}.chapter-navigation[data-astro-cid-pux6a34n]{display:flex;justify-content:space-between;gap:2rem;margin:4rem 0 2rem;padding-top:2rem;border-top:1px solid var(--border)}.nav-prev[data-astro-cid-pux6a34n],.nav-next[data-astro-cid-pux6a34n]{display:flex;flex-direction:column;gap:.5rem;padding:1rem;border:1px solid var(--border);border-radius:8px;text-decoration:none;transition:border-color .2s,background .2s;flex:1;max-width:45%}.nav-prev[data-astro-cid-pux6a34n]:hover,.nav-next[data-astro-cid-pux6a34n]:hover{border-color:var(--accent);background:var(--hover-bg)}.nav-prev[data-astro-cid-pux6a34n].placeholder{visibility:hidden}.nav-next[data-astro-cid-pux6a34n]{align-items:flex-end;text-align:right}.nav-label[data-astro-cid-pux6a34n]{font-size:.85rem;font-weight:600;text-transform:uppercase;letter-spacing:.05em;color:var(--accent)}.nav-title[data-astro-cid-pux6a34n]{font-size:1rem;color:var(--text)}
</style>
<link rel="stylesheet" href="/eng-ai/_astro/_chapter_.BUailOsj.css"><script type="module" src="/eng-ai/_astro/hoisted.0uyw1jl9.js"></script></head> <body>  <div class="book-layout"> <button id="mobile-menu-toggle" class="hamburger-button" aria-label="Toggle navigation menu" aria-expanded="false" data-astro-cid-odmlyywb> <span class="hamburger-line" data-astro-cid-odmlyywb></span> <span class="hamburger-line" data-astro-cid-odmlyywb></span> <span class="hamburger-line" data-astro-cid-odmlyywb></span> </button>  <div class="sidebar-overlay" id="sidebar-overlay" data-astro-cid-ssfzsv2f></div> <aside class="sidebar" id="sidebar" data-astro-cid-ssfzsv2f> <!-- Sidebar Controls --> <div class="sidebar-controls" data-astro-cid-ssfzsv2f> <button id="sidebar-close" class="sidebar-close-button" aria-label="Close menu" data-astro-cid-ssfzsv2f> <svg width="20" height="20" viewBox="0 0 20 20" fill="none" data-astro-cid-ssfzsv2f> <line x1="4" y1="4" x2="16" y2="16" stroke="currentColor" stroke-width="2" stroke-linecap="round" data-astro-cid-ssfzsv2f></line> <line x1="16" y1="4" x2="4" y2="16" stroke="currentColor" stroke-width="2" stroke-linecap="round" data-astro-cid-ssfzsv2f></line> </svg> </button> <button id="theme-toggle" class="theme-toggle-button" aria-label="Toggle dark mode" data-astro-cid-ssfzsv2f> <svg class="sun-icon" width="20" height="20" viewBox="0 0 20 20" data-astro-cid-ssfzsv2f> <circle cx="10" cy="10" r="4" fill="currentColor" data-astro-cid-ssfzsv2f></circle> <line x1="10" y1="1" x2="10" y2="3" stroke="currentColor" stroke-width="2" stroke-linecap="round" data-astro-cid-ssfzsv2f></line> <line x1="10" y1="17" x2="10" y2="19" stroke="currentColor" stroke-width="2" stroke-linecap="round" data-astro-cid-ssfzsv2f></line> <line x1="1" y1="10" x2="3" y2="10" stroke="currentColor" stroke-width="2" stroke-linecap="round" data-astro-cid-ssfzsv2f></line> <line x1="17" y1="10" x2="19" y2="10" stroke="currentColor" stroke-width="2" stroke-linecap="round" data-astro-cid-ssfzsv2f></line> <line x1="3.5" y1="3.5" x2="5" y2="5" stroke="currentColor" stroke-width="2" stroke-linecap="round" data-astro-cid-ssfzsv2f></line> <line x1="15" y1="15" x2="16.5" y2="16.5" stroke="currentColor" stroke-width="2" stroke-linecap="round" data-astro-cid-ssfzsv2f></line> <line x1="16.5" y1="3.5" x2="15" y2="5" stroke="currentColor" stroke-width="2" stroke-linecap="round" data-astro-cid-ssfzsv2f></line> <line x1="5" y1="15" x2="3.5" y2="16.5" stroke="currentColor" stroke-width="2" stroke-linecap="round" data-astro-cid-ssfzsv2f></line> </svg> <svg class="moon-icon" width="20" height="20" viewBox="0 0 20 20" data-astro-cid-ssfzsv2f> <path d="M10 2a8 8 0 108 8 6 6 0 01-8-8z" fill="currentColor" data-astro-cid-ssfzsv2f></path> </svg> </button> </div> <div class="sidebar-header" data-astro-cid-ssfzsv2f> <a href="/eng-ai/" data-astro-cid-ssfzsv2f> <h2 data-astro-cid-ssfzsv2f>Engineering Intelligence</h2> </a> </div> <nav class="sidebar-nav" data-astro-cid-ssfzsv2f> <section class="intro-section" data-astro-cid-ssfzsv2f> <ul data-astro-cid-ssfzsv2f> <li class="" data-astro-cid-ssfzsv2f> <a href="/eng-ai/introduction" <span class="intro-icon" data-astro-cid-ssfzsv2f>üìñ
              Introduction
</a> </li> </ul> </section> <section class="part-section" data-astro-cid-ssfzsv2f> <h3 class="" data-astro-cid-ssfzsv2f> <a href="/eng-ai/part1" data-astro-cid-ssfzsv2f>
Part I: Foundations </a> </h3> <ul data-astro-cid-ssfzsv2f> <li class="" data-astro-cid-ssfzsv2f> <a href="/eng-ai/part1/01-why-intelligence-is-not-magic" data-astro-cid-ssfzsv2f> <span class="chapter-num" data-astro-cid-ssfzsv2f>1.</span> Why Intelligence Is Not Magic </a> </li><li class="" data-astro-cid-ssfzsv2f> <a href="/eng-ai/part1/02-data-is-the-new-physics" data-astro-cid-ssfzsv2f> <span class="chapter-num" data-astro-cid-ssfzsv2f>2.</span> Data Is the New Physics </a> </li><li class="" data-astro-cid-ssfzsv2f> <a href="/eng-ai/part1/03-models-are-compression-machines" data-astro-cid-ssfzsv2f> <span class="chapter-num" data-astro-cid-ssfzsv2f>3.</span> Models Are Compression Machines </a> </li><li class="" data-astro-cid-ssfzsv2f> <a href="/eng-ai/part1/04-bias-variance-tradeoff" data-astro-cid-ssfzsv2f> <span class="chapter-num" data-astro-cid-ssfzsv2f>4.</span> The Bias-Variance Tradeoff </a> </li><li class="" data-astro-cid-ssfzsv2f> <a href="/eng-ai/part1/05-features-how-machines-see-the-world" data-astro-cid-ssfzsv2f> <span class="chapter-num" data-astro-cid-ssfzsv2f>5.</span> Features: How Machines See the World </a> </li> </ul> </section><section class="part-section" data-astro-cid-ssfzsv2f> <h3 class="" data-astro-cid-ssfzsv2f> <a href="/eng-ai/part2" data-astro-cid-ssfzsv2f>
Part II: Classical ML </a> </h3> <ul data-astro-cid-ssfzsv2f> <li class="" data-astro-cid-ssfzsv2f> <a href="/eng-ai/part2/06-linear-models" data-astro-cid-ssfzsv2f> <span class="chapter-num" data-astro-cid-ssfzsv2f>6.</span> Linear Models </a> </li><li class="" data-astro-cid-ssfzsv2f> <a href="/eng-ai/part2/07-logistic-regression" data-astro-cid-ssfzsv2f> <span class="chapter-num" data-astro-cid-ssfzsv2f>7.</span> Logistic Regression </a> </li><li class="" data-astro-cid-ssfzsv2f> <a href="/eng-ai/part2/08-decision-trees" data-astro-cid-ssfzsv2f> <span class="chapter-num" data-astro-cid-ssfzsv2f>8.</span> Decision Trees </a> </li><li class="" data-astro-cid-ssfzsv2f> <a href="/eng-ai/part2/09-ensembles" data-astro-cid-ssfzsv2f> <span class="chapter-num" data-astro-cid-ssfzsv2f>9.</span> Ensembles </a> </li><li class="" data-astro-cid-ssfzsv2f> <a href="/eng-ai/part2/10-loss-functions" data-astro-cid-ssfzsv2f> <span class="chapter-num" data-astro-cid-ssfzsv2f>10.</span> Loss Functions and Optimization </a> </li> </ul> </section><section class="part-section" data-astro-cid-ssfzsv2f> <h3 class="" data-astro-cid-ssfzsv2f> <a href="/eng-ai/part3" data-astro-cid-ssfzsv2f>
Part III: Neural Networks </a> </h3> <ul data-astro-cid-ssfzsv2f> <li class="" data-astro-cid-ssfzsv2f> <a href="/eng-ai/part3/11-neurons-as-math" data-astro-cid-ssfzsv2f> <span class="chapter-num" data-astro-cid-ssfzsv2f>11.</span> Neurons as Math </a> </li><li class="" data-astro-cid-ssfzsv2f> <a href="/eng-ai/part3/12-forward-pass" data-astro-cid-ssfzsv2f> <span class="chapter-num" data-astro-cid-ssfzsv2f>12.</span> The Forward Pass </a> </li><li class="" data-astro-cid-ssfzsv2f> <a href="/eng-ai/part3/13-backpropagation" data-astro-cid-ssfzsv2f> <span class="chapter-num" data-astro-cid-ssfzsv2f>13.</span> Backpropagation </a> </li><li class="" data-astro-cid-ssfzsv2f> <a href="/eng-ai/part3/14-optimization-deep-learning" data-astro-cid-ssfzsv2f> <span class="chapter-num" data-astro-cid-ssfzsv2f>14.</span> Optimization in Deep Learning </a> </li><li class="" data-astro-cid-ssfzsv2f> <a href="/eng-ai/part3/15-representation-learning" data-astro-cid-ssfzsv2f> <span class="chapter-num" data-astro-cid-ssfzsv2f>15.</span> Representation Learning </a> </li> </ul> </section><section class="part-section" data-astro-cid-ssfzsv2f> <h3 class="" data-astro-cid-ssfzsv2f> <a href="/eng-ai/part4" data-astro-cid-ssfzsv2f>
Part IV: Deep Architectures </a> </h3> <ul data-astro-cid-ssfzsv2f> <li class="" data-astro-cid-ssfzsv2f> <a href="/eng-ai/part4/16-convolutional-neural-networks" data-astro-cid-ssfzsv2f> <span class="chapter-num" data-astro-cid-ssfzsv2f>16.</span> Convolutional Neural Networks </a> </li><li class="" data-astro-cid-ssfzsv2f> <a href="/eng-ai/part4/17-recurrent-neural-networks" data-astro-cid-ssfzsv2f> <span class="chapter-num" data-astro-cid-ssfzsv2f>17.</span> Recurrent Neural Networks </a> </li><li class="" data-astro-cid-ssfzsv2f> <a href="/eng-ai/part4/18-embeddings" data-astro-cid-ssfzsv2f> <span class="chapter-num" data-astro-cid-ssfzsv2f>18.</span> Embeddings </a> </li><li class="" data-astro-cid-ssfzsv2f> <a href="/eng-ai/part4/19-attention" data-astro-cid-ssfzsv2f> <span class="chapter-num" data-astro-cid-ssfzsv2f>19.</span> Attention </a> </li><li class="" data-astro-cid-ssfzsv2f> <a href="/eng-ai/part4/20-transformers" data-astro-cid-ssfzsv2f> <span class="chapter-num" data-astro-cid-ssfzsv2f>20.</span> Transformers </a> </li> </ul> </section><section class="part-section" data-astro-cid-ssfzsv2f> <h3 class="" data-astro-cid-ssfzsv2f> <a href="/eng-ai/part5" data-astro-cid-ssfzsv2f>
Part V: Language Models </a> </h3> <ul data-astro-cid-ssfzsv2f> <li class="" data-astro-cid-ssfzsv2f> <a href="/eng-ai/part5/21-next-token-prediction" data-astro-cid-ssfzsv2f> <span class="chapter-num" data-astro-cid-ssfzsv2f>21.</span> Next-Token Prediction </a> </li><li class="" data-astro-cid-ssfzsv2f> <a href="/eng-ai/part5/22-pretraining" data-astro-cid-ssfzsv2f> <span class="chapter-num" data-astro-cid-ssfzsv2f>22.</span> Pretraining </a> </li><li class="" data-astro-cid-ssfzsv2f> <a href="/eng-ai/part5/23-fine-tuning" data-astro-cid-ssfzsv2f> <span class="chapter-num" data-astro-cid-ssfzsv2f>23.</span> Fine-Tuning </a> </li><li class="" data-astro-cid-ssfzsv2f> <a href="/eng-ai/part5/24-rlhf" data-astro-cid-ssfzsv2f> <span class="chapter-num" data-astro-cid-ssfzsv2f>24.</span> RLHF </a> </li><li class="" data-astro-cid-ssfzsv2f> <a href="/eng-ai/part5/25-emergent-abilities-and-scaling" data-astro-cid-ssfzsv2f> <span class="chapter-num" data-astro-cid-ssfzsv2f>25.</span> Emergent Abilities and Scaling </a> </li> </ul> </section><section class="part-section" data-astro-cid-ssfzsv2f> <h3 class="" data-astro-cid-ssfzsv2f> <a href="/eng-ai/part6" data-astro-cid-ssfzsv2f>
Part VI: Modern AI Systems </a> </h3> <ul data-astro-cid-ssfzsv2f> <li class="" data-astro-cid-ssfzsv2f> <a href="/eng-ai/part6/26-prompting-as-programming" data-astro-cid-ssfzsv2f> <span class="chapter-num" data-astro-cid-ssfzsv2f>26.</span> Prompting as Programming </a> </li><li class="" data-astro-cid-ssfzsv2f> <a href="/eng-ai/part6/27-retrieval-augmented-generation" data-astro-cid-ssfzsv2f> <span class="chapter-num" data-astro-cid-ssfzsv2f>27.</span> Retrieval-Augmented Generation </a> </li><li class="" data-astro-cid-ssfzsv2f> <a href="/eng-ai/part6/28-tools-and-function-calling" data-astro-cid-ssfzsv2f> <span class="chapter-num" data-astro-cid-ssfzsv2f>28.</span> Tools and Function Calling </a> </li><li class="" data-astro-cid-ssfzsv2f> <a href="/eng-ai/part6/29-agents" data-astro-cid-ssfzsv2f> <span class="chapter-num" data-astro-cid-ssfzsv2f>29.</span> Agents - Models That Decide What to Do </a> </li><li class="" data-astro-cid-ssfzsv2f> <a href="/eng-ai/part6/30-memory-and-planning" data-astro-cid-ssfzsv2f> <span class="chapter-num" data-astro-cid-ssfzsv2f>30.</span> Memory, Planning, and Long-Term Behavior </a> </li> </ul> </section><section class="part-section" data-astro-cid-ssfzsv2f> <h3 class="" data-astro-cid-ssfzsv2f> <a href="/eng-ai/part7" data-astro-cid-ssfzsv2f>
Part VII: Engineering Reality </a> </h3> <ul data-astro-cid-ssfzsv2f> <li class="active" data-astro-cid-ssfzsv2f> <a href="/eng-ai/part7/31-data-pipelines" data-astro-cid-ssfzsv2f> <span class="chapter-num" data-astro-cid-ssfzsv2f>31.</span> Data Pipelines - Where Models Are Born and Die </a> </li><li class="" data-astro-cid-ssfzsv2f> <a href="/eng-ai/part7/32-training-vs-inference" data-astro-cid-ssfzsv2f> <span class="chapter-num" data-astro-cid-ssfzsv2f>32.</span> Training vs Inference - Two Different Worlds </a> </li><li class="" data-astro-cid-ssfzsv2f> <a href="/eng-ai/part7/33-evaluation" data-astro-cid-ssfzsv2f> <span class="chapter-num" data-astro-cid-ssfzsv2f>33.</span> Evaluation - Why Accuracy Is Not Enough </a> </li><li class="" data-astro-cid-ssfzsv2f> <a href="/eng-ai/part7/34-hallucinations-bias-brittleness" data-astro-cid-ssfzsv2f> <span class="chapter-num" data-astro-cid-ssfzsv2f>34.</span> Hallucinations, Bias, and Brittleness </a> </li><li class="" data-astro-cid-ssfzsv2f> <a href="/eng-ai/part7/35-safety-alignment-control" data-astro-cid-ssfzsv2f> <span class="chapter-num" data-astro-cid-ssfzsv2f>35.</span> Safety, Alignment, and Control </a> </li> </ul> </section><section class="part-section" data-astro-cid-ssfzsv2f> <h3 class="" data-astro-cid-ssfzsv2f> <a href="/eng-ai/part8" data-astro-cid-ssfzsv2f>
Part VIII: The Frontier </a> </h3> <ul data-astro-cid-ssfzsv2f> <li class="" data-astro-cid-ssfzsv2f> <a href="/eng-ai/part8/36-scaling-laws" data-astro-cid-ssfzsv2f> <span class="chapter-num" data-astro-cid-ssfzsv2f>36.</span> Scaling Laws - Why Bigger Keeps Winning </a> </li><li class="" data-astro-cid-ssfzsv2f> <a href="/eng-ai/part8/37-multimodal-models" data-astro-cid-ssfzsv2f> <span class="chapter-num" data-astro-cid-ssfzsv2f>37.</span> Multimodal Models </a> </li><li class="" data-astro-cid-ssfzsv2f> <a href="/eng-ai/part8/38-self-improving-systems" data-astro-cid-ssfzsv2f> <span class="chapter-num" data-astro-cid-ssfzsv2f>38.</span> Self-Improving Systems </a> </li><li class="" data-astro-cid-ssfzsv2f> <a href="/eng-ai/part8/39-artificial-general-intelligence" data-astro-cid-ssfzsv2f> <span class="chapter-num" data-astro-cid-ssfzsv2f>39.</span> Artificial General Intelligence </a> </li><li class="" data-astro-cid-ssfzsv2f> <a href="/eng-ai/part8/40-the-engineers-role" data-astro-cid-ssfzsv2f> <span class="chapter-num" data-astro-cid-ssfzsv2f>40.</span> The Engineer&#39;s Role </a> </li> </ul> </section> </nav> </aside>   <main class="chapter-content"> <nav class="breadcrumbs" aria-label="Breadcrumb" data-astro-cid-ilhxcym7> <ol data-astro-cid-ilhxcym7> <li data-astro-cid-ilhxcym7><a href="/eng-ai/" data-astro-cid-ilhxcym7>Home</a></li> <li data-astro-cid-ilhxcym7><a href="/eng-ai/part7" data-astro-cid-ilhxcym7>Part VII: Engineering Reality</a></li> <li aria-current="page" data-astro-cid-ilhxcym7>Data Pipelines - Where Models Are Born and Die</li> </ol> </nav>  <article class="chapter"> <h1 id="chapter-31-data-pipelines---where-models-are-born-and-die">Chapter 31: Data Pipelines - Where Models Are Born and Die</h1>
<p>Every machine learning paper begins with a model architecture. The paper describes layers, attention mechanisms, and training procedures. It reports accuracy on benchmarks and compares to baselines. The data section is an afterthought: ‚ÄúWe trained on ImageNet‚Äù or ‚ÄúWe used Common Crawl.‚Äù</p>
<p>But in production, data is everything. Models are commodities‚Äîyou can download GPT-4, BERT, or ResNet in minutes. What you cannot download is your data. Your users, your products, your domain. The data pipeline‚Äîhow you collect, clean, label, and maintain data‚Äîdetermines whether your model succeeds or fails.</p>
<p>This chapter explains why data pipelines are where models are truly born, and where they die. Most ML failures are data failures. Understanding data pipelines is understanding the hardest part of production machine learning.</p>
<hr>
<h2 id="collection-where-data-comes-from-ch31">Collection: Where Data Comes From</h2>
<p>Before a model can learn anything, data must exist. Collection is the first stage of the pipeline, and it shapes everything that follows. What you collect determines what your model can learn. What you miss determines what your model cannot learn.</p>
<p><strong>Data sources vary by domain:</strong></p>
<p><strong>Web scraping and crawling</strong>: Search engines crawl billions of web pages. Language models are trained on internet text‚ÄîReddit, Wikipedia, GitHub, blogs, news sites. The quality and biases of these sources become the quality and biases of the model. Common Crawl contains misinformation, hate speech, and copyrighted content alongside valuable information.</p>
<p><strong>User interactions</strong>: Recommendation systems learn from clicks, watches, and purchases. Search engines learn from queries and click-through rates. Social media learns from likes, shares, and follows. This data is valuable because it reflects real user behavior, but it is inherently noisy‚Äîusers click by mistake, engagement is not always endorsement, and bots generate fake interactions.</p>
<p><strong>Sensor data</strong>: Self-driving cars collect camera, lidar, and radar data. Medical devices collect physiological signals. IoT devices collect environmental measurements. Sensor data is high-volume and high-dimensional, requiring significant storage and processing infrastructure.</p>
<p><strong>Manual curation</strong>: Some datasets are hand-built. ImageNet was created by humans labeling millions of images. Medical datasets require expert clinicians to annotate scans. Legal datasets require lawyers to label documents. Manual curation is expensive but produces higher-quality data.</p>
<p><strong>Collection biases</strong> are inevitable. What gets collected is not a neutral sample of reality‚Äîit is what is easy to collect, valuable to collect, or legal to collect:</p>
<ul>
<li><strong>Geographic bias</strong>: Most data comes from wealthy, English-speaking countries. Models trained on this data perform worse in other regions.</li>
<li><strong>Demographic bias</strong>: Medical data overrepresents certain demographics. Facial recognition datasets historically underrepresented darker skin tones.</li>
<li><strong>Platform bias</strong>: Social media data reflects the users of that platform, not the general population. Twitter users are younger and more politically engaged than average.</li>
<li><strong>Temporal bias</strong>: Data collected in one time period may not represent current reality. Fashion, language, and behavior change.</li>
</ul>
<p><strong>Example: Self-driving cars and corner cases</strong></p>
<p>Waymo‚Äôs self-driving cars have driven millions of miles, but most of those miles are on sunny California highways. The data does not include enough snow, heavy rain, or rural roads. When deployed in new environments, the models encounter situations underrepresented in training data: construction zones with unusual lane markers, pedestrians behaving unexpectedly, road hazards not seen before.</p>
<p>This is not a model architecture problem. Adding more layers does not help. The problem is data: the training set does not cover the full distribution of real-world driving scenarios. Collection must actively seek rare but important cases.</p>
<p><strong>Data quality issues</strong> appear at collection:</p>
<ul>
<li><strong>Missing values</strong>: Sensors fail, users skip form fields, APIs return incomplete records</li>
<li><strong>Duplicates</strong>: Same data point appears multiple times (web crawling, user re-submissions)</li>
<li><strong>Noise and outliers</strong>: Faulty sensors, data entry errors, adversarial manipulation</li>
<li><strong>Inconsistent formats</strong>: Dates in different formats, text encodings, schema changes over time</li>
</ul>
<p>Cleaning data is necessary, but cleaning cannot recover information that was never collected. If training data lacks diversity, no amount of cleaning produces a model that generalizes to diverse inputs.</p>
<hr>
<h2 id="labeling-the-human-bottleneck-ch31">Labeling: The Human Bottleneck</h2>
<p>Most supervised learning requires labeled data: inputs paired with ground truth outputs. For many tasks, labels cannot be collected automatically‚Äîthey require human judgment. Labeling is the bottleneck that determines how fast you can improve your model and how accurate your ground truth is.</p>
<p><strong>The labeling process:</strong></p>
<ol>
<li><strong>Task definition</strong>: Define what annotators should label and how. Ambiguous instructions lead to inconsistent labels.</li>
<li><strong>Annotator selection</strong>: Choose experts (doctors labeling medical scans) or crowdworkers (labeling objects in images). Experts are expensive and slow, crowdworkers are cheap and fast but less reliable.</li>
<li><strong>Annotation</strong>: Humans review data points and assign labels. This is tedious, time-consuming work.</li>
<li><strong>Quality control</strong>: Check inter-annotator agreement. If two annotators label the same image differently, the task is ambiguous or instructions are unclear.</li>
<li><strong>Review and iteration</strong>: Experts review crowdworker labels to catch errors.</li>
</ol>
<p><strong>Labeling is expensive.</strong> ImageNet cost $50,000+ in 2009 (leveraging Amazon Mechanical Turk at scale). Medical datasets require specialist physicians charging hundreds of dollars per hour. Legal document labeling requires lawyers. For most companies, labeling is the largest ML cost by far.</p>
<p><strong>Label quality varies.</strong></p>
<p><strong>Inter-annotator agreement</strong> measures consistency: if two annotators label the same data, do they agree? For clear tasks like ‚ÄúIs this a cat?‚Äù, agreement is high (~95%). For subjective tasks like ‚ÄúIs this comment toxic?‚Äù, agreement is much lower (60-70%). Low agreement means the ground truth is ambiguous‚Äîthe model cannot learn what ‚Äúcorrect‚Äù means if humans disagree.</p>
<p><strong>Example: Medical diagnosis labeling</strong></p>
<p>A chest X-ray is labeled by three radiologists:</p>
<ul>
<li>Radiologist A: ‚ÄúPneumonia, left lower lobe‚Äù</li>
<li>Radiologist B: ‚ÄúPossible infiltrate, unclear‚Äù</li>
<li>Radiologist C: ‚ÄúNo acute findings‚Äù</li>
</ul>
<p>Which label is correct? All three are board-certified experts. The ground truth is not a physical fact but an expert judgment call. Models trained on this data inherit this ambiguity. If labels disagree, the model learns to predict the average label, which may not be what any individual expert would say.</p>
<p><strong>Active learning</strong> reduces labeling costs by smartly selecting which data to label. Instead of labeling all data, the model identifies:</p>
<ul>
<li><strong>Uncertain examples</strong>: Data points where the model is least confident</li>
<li><strong>Diverse examples</strong>: Data points that cover different parts of the input space</li>
<li><strong>Disagreement</strong>: Data points where multiple models disagree</li>
</ul>
<p>By labeling these informative examples first, active learning achieves similar accuracy with 10x less labeled data. But it requires an initial model to decide what to label, creating a chicken-and-egg problem.</p>
<p><strong>Self-training and pseudo-labeling</strong> use the model to generate labels for unlabeled data, then retrain on this mixture. This works when the model is already good, but amplifies errors when the model is wrong. Pseudo-labels are cheaper than human labels but noisier.</p>
<p>The labeling bottleneck is fundamental: supervised learning cannot outpace the rate at which humans can provide ground truth. This is why unsupervised learning (Chapter 22) and self-supervised learning (next-token prediction, Chapter 21) are so valuable‚Äîthey learn without human labels.</p>
<hr>
<h2 id="drift-when-reality-changes-ch31">Drift: When Reality Changes</h2>
<p>Machine learning models assume that training data and deployment data come from the same distribution. This assumption is almost always false. The world changes. User behavior evolves. New products launch. Adversaries adapt. The model‚Äôs training data becomes stale.</p>
<p><strong>Data drift</strong> is the change in data distribution over time. There are two types:</p>
<p><strong>Covariate shift</strong>: The input distribution <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>P</mi><mo stretchy="false">(</mo><mi>X</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">P(X)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class="mclose">)</span></span></span></span> changes, but the relationship <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>P</mi><mo stretchy="false">(</mo><mi>Y</mi><mi mathvariant="normal">‚à£</mi><mi>X</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">P(Y | X)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.22222em;">Y</span><span class="mord">‚à£</span><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class="mclose">)</span></span></span></span> stays the same.</p>
<p>Example: A fraud detection model trained on credit card transactions from 2020 is deployed in 2024. In 2020, most transactions were in-person; by 2024, most are online. The input distribution changed (more online transactions), but the fraud patterns are similar (phishing, stolen cards, fake merchants). The model sees a different mix of transaction types than it was trained on.</p>
<p><strong>Concept drift</strong>: The relationship <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>P</mi><mo stretchy="false">(</mo><mi>Y</mi><mi mathvariant="normal">‚à£</mi><mi>X</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">P(Y | X)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.22222em;">Y</span><span class="mord">‚à£</span><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class="mclose">)</span></span></span></span> changes. The same input now has a different correct output.</p>
<p>Example: Fraudsters adapt. In 2020, they used technique A (carding). By 2024, they switched to technique B (account takeover). The model trained on technique A fails to detect technique B. The input might look similar (same transaction amounts, same purchase categories), but the fraud patterns are fundamentally different.</p>
<p><strong>Covariate shift is easier to handle</strong> than concept drift. If only <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>P</mi><mo stretchy="false">(</mo><mi>X</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">P(X)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class="mclose">)</span></span></span></span> changes, you can sometimes reweight training data to match deployment, or retrain on recent data. If <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>P</mi><mo stretchy="false">(</mo><mi>Y</mi><mi mathvariant="normal">‚à£</mi><mi>X</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">P(Y | X)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.22222em;">Y</span><span class="mord">‚à£</span><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class="mclose">)</span></span></span></span> changes, your ground truth is wrong‚Äîyou need new labels.</p>
<p><strong>Detecting drift</strong> requires monitoring:</p>
<p><strong>Statistical tests</strong>: Compare distributions of features in training vs production. KL divergence, Jensen-Shannon divergence, Kolmogorov-Smirnov test. If distributions diverge significantly, drift is occurring.</p>
<p><strong>Model performance monitoring</strong>: Track accuracy, precision, recall on production data (requires labels for a sample). If performance degrades, either drift occurred or your model was never good.</p>
<p><strong>Feature drift alerts</strong>: Monitor individual features for sudden changes. If ‚Äúaverage transaction amount‚Äù shifts from <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>50</mn><mi>t</mi><mi>o</mi></mrow><annotation encoding="application/x-tex">50 to </annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">50</span><span class="mord mathnormal">t</span><span class="mord mathnormal">o</span></span></span></span>500, something changed.</p>
<p><strong>Retraining strategies</strong> combat drift:</p>
<p><strong>Periodic retraining</strong>: Retrain every month, quarter, year on fresh data
<strong>Continuous learning</strong>: Update model online as new data arrives (risky‚Äîbad data poisons model)
<strong>Triggered retraining</strong>: Detect drift, then retrain
<strong>Ensemble over time</strong>: Maintain multiple models trained on different time periods, blend predictions</p>
<p>Retraining is expensive (compute, labeling, testing, deployment), so companies balance freshness vs cost. Google Search retrains ranking models continuously. A medical diagnosis model might retrain once a year.</p>
<p><strong>Example: COVID-19 and medical models</strong></p>
<p>Many medical prediction models failed during COVID-19. Models trained on pre-pandemic data assumed normal hospital patient distributions. When COVID patients flooded hospitals, the patient mix changed dramatically. Symptoms, demographics, co-morbidities‚Äîall shifted. Models predicting ICU admission or mortality gave unreliable results because <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>P</mi><mo stretchy="false">(</mo><mi>X</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">P(X)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class="mclose">)</span></span></span></span> and <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>P</mi><mo stretchy="false">(</mo><mi>Y</mi><mi mathvariant="normal">‚à£</mi><mi>X</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">P(Y|X)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.22222em;">Y</span><span class="mord">‚à£</span><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class="mclose">)</span></span></span></span> both changed. Models had to be retrained urgently on pandemic data.</p>
<p>This is concept drift at crisis speed. The models were not wrong‚Äîthey were trained on a world that no longer existed.</p>
<hr>
<h2 id="feedback-loops-when-models-poison-data-ch31">Feedback Loops: When Models Poison Data</h2>
<p>The most insidious data problem is the <strong>feedback loop</strong>: the model‚Äôs predictions influence what data is collected next, which influences the next model, which influences future data, creating a cycle that can amplify bias or degrade quality.</p>
<p><strong>How feedback loops form:</strong></p>
<ol>
<li>Model makes predictions in production</li>
<li>Users react to predictions (clicks, purchases, actions)</li>
<li>User reactions are logged as new training data</li>
<li>Model is retrained on data that includes its own influence</li>
<li>The cycle repeats</li>
</ol>
<p>Feedback loops can be positive (model improves over time) or negative (model degrades, bias amplifies).</p>
<p><strong>Example: YouTube recommendation feedback loop</strong></p>
<p>YouTube‚Äôs recommendation algorithm suggests videos. Users click suggested videos more than random videos (the algorithm works). Click data is logged as training data: ‚ÄúUser watched video after it was recommended.‚Äù</p>
<p>Next training iteration: Videos that were recommended get more clicks (because they were recommended), so they appear more engaging. The model learns ‚Äúrecommend videos that were previously recommended.‚Äù This creates a rich-get-richer dynamic: popular videos get recommended more, gaining more clicks, getting recommended even more.</p>
<p>The feedback loop can amplify bias: if the model initially recommends conspiracy theories to a small subset of users, those users click, the model learns ‚Äúthese users like conspiracy theories,‚Äù recommends more, users watch more, and the model doubles down. The data no longer reflects organic user preferences‚Äîit reflects algorithmically shaped preferences.</p>
<p><strong>Breaking the feedback loop:</strong></p>
<p><strong>Randomization</strong>: Occasionally show random content to collect unbiased interaction data
<strong>Holdout sets</strong>: Reserve some users for non-personalized experiences to measure organic behavior
<strong>Causal inference</strong>: Use techniques like inverse propensity weighting to estimate what would happen without the model
<strong>Logging policies</strong>: Record why the model made each prediction (recommendation reason), enabling analysis of bias</p>
<p><strong>Example: Search engine click data</strong></p>
<p>Search engines use click data to improve ranking. If users click result #3 more than #2, perhaps #3 should be ranked higher. But users click #1 most because it is ranked #1‚Äîposition bias. The model learns ‚Äúrank popular results higher,‚Äù which makes them more popular, which makes the model rank them higher.</p>
<p>Over time, the rich get richer: established websites dominate rankings because they have historical click data. New, high-quality sites struggle to break in. The data reflects not just relevance but past ranking decisions.</p>
<p><strong>Self-fulfilling prophecies</strong> occur when models change reality to match their predictions:</p>
<p><strong>Credit scoring</strong>: A model predicts someone is high-risk, they are denied credit, they cannot build credit history, confirming the model‚Äôs prediction.</p>
<p><strong>Recidivism prediction</strong>: A model predicts someone will re-offend, they receive harsher sentencing, longer imprisonment increases likelihood of re-offense, confirming the model‚Äôs prediction.</p>
<p><strong>Hiring tools</strong>: A model predicts someone will succeed, they are hired, they receive mentorship and opportunities, confirming the model‚Äôs prediction. Someone predicted to fail is not hired, never gets the chance, model never proven wrong.</p>
<p>In these cases, the model‚Äôs prediction changes the outcome it is predicting. The data is no longer ground truth‚Äîit is model-influenced reality.</p>
<p><img  src="/eng-ai/_astro/31-diagram.CYCPuvAV_ZflmJ5.svg" alt="Feedback Loops: When Models Poison Data diagram" width="800" height="500" loading="lazy" decoding="async"></p>
<p><strong>Figure 31.1</strong>: Data pipeline with feedback loop. The model makes predictions, users react to those predictions, reactions are logged as new data, and the model is retrained on model-influenced data. This cycle can amplify biases and create self-fulfilling prophecies. Drift monitoring and randomization help break the loop.</p>
<hr>
<h2 id="engineering-takeaway-ch31">Engineering Takeaway</h2>
<p><strong>Data quality determines model quality‚Äîgarbage in, garbage out.</strong> No amount of model tuning fixes bad data. The architecture that gains 2% accuracy on ImageNet is useless if your training data is missing 50% of the categories you care about. In production, data engineering matters far more than model engineering. The teams that win are the teams that build better data pipelines.</p>
<p><strong>Labeling is the bottleneck in supervised learning‚Äîactive learning helps, but cannot eliminate human judgment.</strong> Labels are expensive, slow, and inconsistent. For many tasks, ground truth is subjective (content moderation, aesthetic quality, medical diagnosis). Models inherit label ambiguity. Active learning reduces labeling costs by focusing on informative examples, but you still need humans to provide truth. The dream of unsupervised learning is a dream of escaping the labeling bottleneck.</p>
<p><strong>Data drift is inevitable‚Äîproduction models must be retrained or adapted.</strong> The world changes faster than models can keep up. Fraud patterns evolve, user preferences shift, new products launch. A model trained on last year‚Äôs data is out of date. Continuous monitoring detects drift before performance degrades. Retraining is not optional‚Äîit is the price of staying relevant. Companies that treat models as ‚Äúdeploy and forget‚Äù are companies whose models die slowly.</p>
<p><strong>Feedback loops can amplify bias‚Äîmonitor data carefully and break reinforcing cycles.</strong> When models influence the data they are trained on, self-reinforcing loops form. Bias amplifies, diversity decreases, and the data reflects algorithmic decisions rather than ground truth. Randomization, causal inference, and holdout sets help break loops. The most dangerous feedback loops are invisible‚Äîyou do not see the counterfactual of what would have happened without the model.</p>
<p><strong>Data versioning is essential‚Äîreproducibility requires knowing what data was used to train each model.</strong> When a model fails in production, you need to know: What data was it trained on? Has that data changed? Can you reproduce the training run? Without data versioning (like DVC, Git LFS, or custom solutions), debugging is impossible. Every model should have a lineage: this model was trained on dataset v3.2, using hyperparameters X, on date Y. Treating data like code is treating machine learning like engineering.</p>
<p><strong>Pipeline monitoring catches problems before models fail‚Äîmonitor data quality, distribution shifts, and labeling consistency.</strong> Models fail because data fails. Monitoring model accuracy is reactive‚Äîyou see the problem after users do. Monitoring data quality is proactive‚Äîyou see the problem before it reaches the model. Check for: sudden spikes in missing values, distribution shifts in key features, changes in label distribution, annotation agreement rates. If the pipeline breaks, the model will fail. Fix the pipeline, not the model.</p>
<p><strong>Why most ML teams spend 80% of time on data, not models‚Äîthe data pipeline is the product.</strong> Researchers spend 80% of time on models. Practitioners spend 80% of time on data. Collecting, cleaning, labeling, versioning, monitoring‚Äîthis is where the work is. The model is the easy part. The data pipeline is the hard part. If someone says ‚ÄúI built an ML system,‚Äù they mean ‚ÄúI built a data pipeline and attached a model to it.‚Äù The model is the cherry on top. The data is the ice cream.</p>
<hr>
<h2 id="references-and-further-reading-ch31">References and Further Reading</h2>
<p><strong>‚ÄúEveryone Wants to Do the Model Work, Not the Data Work‚Äù: Data Cascades in High-Stakes AI</strong>
Sambasivan, N., Kapania, S., Highfill, H., Akrong, D., Paritosh, P., &#x26; Aroyo, L. M. (2021). <em>CHI 2021</em></p>
<p><em>Why it matters:</em> This paper documented ‚Äúdata cascades‚Äù‚Äîcompounding events where problems in data create downstream failures that multiply over time. Based on interviews with ML practitioners across the world, it revealed that data problems (poor labeling, collection bias, documentation gaps) cause most production failures, not model architecture. The paper emphasizes that data work is undervalued and under-resourced compared to model work, despite being the primary determinant of success. It is a wake-up call that data engineering is the real challenge in ML.</p>
<p><strong>Hidden Technical Debt in Machine Learning Systems</strong>
Sculley, D., Holt, G., Golovin, D., Davydov, E., Phillips, T., Ebner, D., Chaudhary, V., Young, M., Crespo, J.-F., &#x26; Dennison, D. (2015). <em>NIPS 2015</em></p>
<p><em>Why it matters:</em> This Google paper introduced the concept of ‚Äútechnical debt‚Äù in ML systems, showing that the model is a tiny part of the system‚Äîsurrounded by configuration, data collection, feature extraction, monitoring, and serving infrastructure. Data dependencies are highlighted as particularly insidious: unstable data sources, legacy features, and undeclared consumers create hidden coupling. Changing data breaks models in non-obvious ways. The paper argues that managing data pipelines is harder than managing code, and that most ML system complexity is in data, not models.</p>
<p><strong>How to Avoid Machine Learning Pitfalls: A Guide for Academic Researchers</strong>
Lones, M. A. (2021). <em>arXiv:2108.02497</em></p>
<p><em>Why it matters:</em> This guide, aimed at researchers, covers common ML pitfalls‚Äîmany of which are data problems. Leakage (test data contaminating training), selection bias (non-random splits), overfitting to test sets, and ignoring distribution shift. It emphasizes that many ‚ÄúSOTA results‚Äù in papers are artifacts of data problems, not genuine model improvements. The guide is a checklist for avoiding subtle data issues that invalidate results, making it essential reading for anyone working with ML in research or production.</p>
<hr>
<p>The next chapter examines the fundamental divide between training and inference: why models trained offline must perform online, why latency matters more than accuracy in production, and how deployment transforms constraints.</p> </article> <nav class="chapter-navigation" data-astro-cid-pux6a34n> <a href="/eng-ai/part7" class="nav-prev " data-astro-cid-pux6a34n> <span class="nav-label" data-astro-cid-pux6a34n>‚Üê Previous</span> <span class="nav-title" data-astro-cid-pux6a34n>Part VII: Engineering Reality</span> </a> <a href="/eng-ai/part7/32-training-vs-inference" class="nav-next" data-astro-cid-pux6a34n> <span class="nav-label" data-astro-cid-pux6a34n>Next ‚Üí</span> <span class="nav-title" data-astro-cid-pux6a34n>Training vs Inference - Two Different Worlds</span> </a> </nav>  </main> <aside class="chapter-toc"> <nav class="toc" data-astro-cid-xvrfupwn><h4 data-astro-cid-xvrfupwn>On This Page</h4><ul data-astro-cid-xvrfupwn><li class="toc-level-2" data-astro-cid-xvrfupwn><a href="#collection-where-data-comes-from-ch31" data-astro-cid-xvrfupwn>Collection: Where Data Comes From</a></li><li class="toc-level-2" data-astro-cid-xvrfupwn><a href="#labeling-the-human-bottleneck-ch31" data-astro-cid-xvrfupwn>Labeling: The Human Bottleneck</a></li><li class="toc-level-2" data-astro-cid-xvrfupwn><a href="#drift-when-reality-changes-ch31" data-astro-cid-xvrfupwn>Drift: When Reality Changes</a></li><li class="toc-level-2" data-astro-cid-xvrfupwn><a href="#feedback-loops-when-models-poison-data-ch31" data-astro-cid-xvrfupwn>Feedback Loops: When Models Poison Data</a></li><li class="toc-level-2" data-astro-cid-xvrfupwn><a href="#engineering-takeaway-ch31" data-astro-cid-xvrfupwn>Engineering Takeaway</a></li><li class="toc-level-2" data-astro-cid-xvrfupwn><a href="#references-and-further-reading-ch31" data-astro-cid-xvrfupwn>References and Further Reading</a></li></ul></nav> </aside> </div>   </body> </html>