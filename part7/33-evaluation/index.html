<!DOCTYPE html><html lang="en"> <head><meta charset="UTF-8"><meta name="viewport" content="width=device-width, initial-scale=1.0"><title>Chapter 33: Evaluation - Why Accuracy Is Not Enough | Engineering Intelligence</title><meta name="description" content="A book for engineers who want to understand Machine Learning and AI from first principles"><!-- Canonical URL --><link rel="canonical" href="https://olivernguyen.io/eng-ai/part7/33-evaluation/"><!-- Open Graph / Facebook --><meta property="og:type" content="website"><meta property="og:url" content="https://olivernguyen.io/eng-ai/part7/33-evaluation/"><meta property="og:title" content="Chapter 33: Evaluation - Why Accuracy Is Not Enough | Engineering Intelligence"><meta property="og:description" content="A book for engineers who want to understand Machine Learning and AI from first principles"><meta property="og:image" content="https://olivernguyen.io/eng-ai/og-image.png"><meta property="og:site_name" content="Engineering Intelligence"><!-- Twitter --><meta name="twitter:card" content="summary_large_image"><meta name="twitter:url" content="https://olivernguyen.io/eng-ai/part7/33-evaluation/"><meta name="twitter:title" content="Chapter 33: Evaluation - Why Accuracy Is Not Enough | Engineering Intelligence"><meta name="twitter:description" content="A book for engineers who want to understand Machine Learning and AI from first principles"><meta name="twitter:image" content="https://olivernguyen.io/eng-ai/og-image.png"><!-- Additional Meta --><meta name="author" content="Oliver Nguyen"><meta name="theme-color" content="#2563eb"><!-- Favicon (SVG preferred, PNG fallback) --><link rel="icon" type="image/svg+xml" href="/eng-ai/favicon.svg"><link rel="icon" type="image/png" sizes="32x32" href="/eng-ai/favicon-32x32.png"><link rel="icon" type="image/png" sizes="16x16" href="/eng-ai/favicon-16x16.png"><link rel="apple-touch-icon" sizes="180x180" href="/eng-ai/apple-touch-icon.png"><!-- KaTeX CSS for math rendering --><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css"><!-- Site styles --><link rel="stylesheet" href="/eng-ai/styles/global.css"><link rel="stylesheet" href="/eng-ai/styles/typography.css"><link rel="stylesheet" href="/eng-ai/styles/themes.css"><link rel="stylesheet" href="/eng-ai/styles/print.css"><style>.breadcrumbs[data-astro-cid-ilhxcym7]{margin-bottom:2rem}.breadcrumbs[data-astro-cid-ilhxcym7] ol[data-astro-cid-ilhxcym7]{display:flex;flex-wrap:wrap;gap:.5rem;list-style:none;padding:0;font-size:.9rem}.breadcrumbs[data-astro-cid-ilhxcym7] li[data-astro-cid-ilhxcym7]{display:flex;align-items:center;gap:.5rem}.breadcrumbs[data-astro-cid-ilhxcym7] li[data-astro-cid-ilhxcym7]:not(:last-child):after{content:"‚Ä∫";color:var(--text-muted)}.breadcrumbs[data-astro-cid-ilhxcym7] a[data-astro-cid-ilhxcym7]{color:var(--accent);text-decoration:none}.breadcrumbs[data-astro-cid-ilhxcym7] a[data-astro-cid-ilhxcym7]:hover{text-decoration:underline}.breadcrumbs[data-astro-cid-ilhxcym7] li[data-astro-cid-ilhxcym7][aria-current=page]{color:var(--text-muted)}.toc[data-astro-cid-xvrfupwn]{position:sticky;top:2rem;padding:1rem}.toc[data-astro-cid-xvrfupwn] h4[data-astro-cid-xvrfupwn]{font-size:.9rem;font-weight:600;text-transform:uppercase;letter-spacing:.05em;color:var(--text-muted);margin-bottom:.75rem}.toc[data-astro-cid-xvrfupwn] ul[data-astro-cid-xvrfupwn]{list-style:none;padding:0}.toc[data-astro-cid-xvrfupwn] li[data-astro-cid-xvrfupwn]{margin:.5rem 0}.toc[data-astro-cid-xvrfupwn] a[data-astro-cid-xvrfupwn]{font-size:.85rem;color:var(--text-muted);text-decoration:none;transition:color .2s}.toc[data-astro-cid-xvrfupwn] a[data-astro-cid-xvrfupwn]:hover{color:var(--accent)}.toc-level-2[data-astro-cid-xvrfupwn]{padding-left:0}.toc-level-3[data-astro-cid-xvrfupwn]{padding-left:1rem;font-size:.8rem}.chapter-navigation[data-astro-cid-pux6a34n]{display:flex;justify-content:space-between;gap:2rem;margin:4rem 0 2rem;padding-top:2rem;border-top:1px solid var(--border)}.nav-prev[data-astro-cid-pux6a34n],.nav-next[data-astro-cid-pux6a34n]{display:flex;flex-direction:column;gap:.5rem;padding:1rem;border:1px solid var(--border);border-radius:8px;text-decoration:none;transition:border-color .2s,background .2s;flex:1;max-width:45%}.nav-prev[data-astro-cid-pux6a34n]:hover,.nav-next[data-astro-cid-pux6a34n]:hover{border-color:var(--accent);background:var(--hover-bg)}.nav-prev[data-astro-cid-pux6a34n].placeholder{visibility:hidden}.nav-next[data-astro-cid-pux6a34n]{align-items:flex-end;text-align:right}.nav-label[data-astro-cid-pux6a34n]{font-size:.85rem;font-weight:600;text-transform:uppercase;letter-spacing:.05em;color:var(--accent)}.nav-title[data-astro-cid-pux6a34n]{font-size:1rem;color:var(--text)}
</style>
<link rel="stylesheet" href="/eng-ai/_astro/_chapter_.BUailOsj.css"><script type="module" src="/eng-ai/_astro/hoisted.0uyw1jl9.js"></script></head> <body>  <div class="book-layout"> <button id="mobile-menu-toggle" class="hamburger-button" aria-label="Toggle navigation menu" aria-expanded="false" data-astro-cid-odmlyywb> <span class="hamburger-line" data-astro-cid-odmlyywb></span> <span class="hamburger-line" data-astro-cid-odmlyywb></span> <span class="hamburger-line" data-astro-cid-odmlyywb></span> </button>  <div class="sidebar-overlay" id="sidebar-overlay" data-astro-cid-ssfzsv2f></div> <aside class="sidebar" id="sidebar" data-astro-cid-ssfzsv2f> <!-- Sidebar Controls --> <div class="sidebar-controls" data-astro-cid-ssfzsv2f> <button id="sidebar-close" class="sidebar-close-button" aria-label="Close menu" data-astro-cid-ssfzsv2f> <svg width="20" height="20" viewBox="0 0 20 20" fill="none" data-astro-cid-ssfzsv2f> <line x1="4" y1="4" x2="16" y2="16" stroke="currentColor" stroke-width="2" stroke-linecap="round" data-astro-cid-ssfzsv2f></line> <line x1="16" y1="4" x2="4" y2="16" stroke="currentColor" stroke-width="2" stroke-linecap="round" data-astro-cid-ssfzsv2f></line> </svg> </button> <button id="theme-toggle" class="theme-toggle-button" aria-label="Toggle dark mode" data-astro-cid-ssfzsv2f> <svg class="sun-icon" width="20" height="20" viewBox="0 0 20 20" data-astro-cid-ssfzsv2f> <circle cx="10" cy="10" r="4" fill="currentColor" data-astro-cid-ssfzsv2f></circle> <line x1="10" y1="1" x2="10" y2="3" stroke="currentColor" stroke-width="2" stroke-linecap="round" data-astro-cid-ssfzsv2f></line> <line x1="10" y1="17" x2="10" y2="19" stroke="currentColor" stroke-width="2" stroke-linecap="round" data-astro-cid-ssfzsv2f></line> <line x1="1" y1="10" x2="3" y2="10" stroke="currentColor" stroke-width="2" stroke-linecap="round" data-astro-cid-ssfzsv2f></line> <line x1="17" y1="10" x2="19" y2="10" stroke="currentColor" stroke-width="2" stroke-linecap="round" data-astro-cid-ssfzsv2f></line> <line x1="3.5" y1="3.5" x2="5" y2="5" stroke="currentColor" stroke-width="2" stroke-linecap="round" data-astro-cid-ssfzsv2f></line> <line x1="15" y1="15" x2="16.5" y2="16.5" stroke="currentColor" stroke-width="2" stroke-linecap="round" data-astro-cid-ssfzsv2f></line> <line x1="16.5" y1="3.5" x2="15" y2="5" stroke="currentColor" stroke-width="2" stroke-linecap="round" data-astro-cid-ssfzsv2f></line> <line x1="5" y1="15" x2="3.5" y2="16.5" stroke="currentColor" stroke-width="2" stroke-linecap="round" data-astro-cid-ssfzsv2f></line> </svg> <svg class="moon-icon" width="20" height="20" viewBox="0 0 20 20" data-astro-cid-ssfzsv2f> <path d="M10 2a8 8 0 108 8 6 6 0 01-8-8z" fill="currentColor" data-astro-cid-ssfzsv2f></path> </svg> </button> </div> <div class="sidebar-header" data-astro-cid-ssfzsv2f> <a href="/eng-ai/" data-astro-cid-ssfzsv2f> <h2 data-astro-cid-ssfzsv2f>Engineering Intelligence</h2> </a> </div> <nav class="sidebar-nav" data-astro-cid-ssfzsv2f> <section class="intro-section" data-astro-cid-ssfzsv2f> <ul data-astro-cid-ssfzsv2f> <li class="" data-astro-cid-ssfzsv2f> <a href="/eng-ai/introduction" <span class="intro-icon" data-astro-cid-ssfzsv2f>üìñ
              Introduction
</a> </li> </ul> </section> <section class="part-section" data-astro-cid-ssfzsv2f> <h3 class="" data-astro-cid-ssfzsv2f> <a href="/eng-ai/part1" data-astro-cid-ssfzsv2f>
Part I: Foundations </a> </h3> <ul data-astro-cid-ssfzsv2f> <li class="" data-astro-cid-ssfzsv2f> <a href="/eng-ai/part1/01-why-intelligence-is-not-magic" data-astro-cid-ssfzsv2f> <span class="chapter-num" data-astro-cid-ssfzsv2f>1.</span> Why Intelligence Is Not Magic </a> </li><li class="" data-astro-cid-ssfzsv2f> <a href="/eng-ai/part1/02-data-is-the-new-physics" data-astro-cid-ssfzsv2f> <span class="chapter-num" data-astro-cid-ssfzsv2f>2.</span> Data Is the New Physics </a> </li><li class="" data-astro-cid-ssfzsv2f> <a href="/eng-ai/part1/03-models-are-compression-machines" data-astro-cid-ssfzsv2f> <span class="chapter-num" data-astro-cid-ssfzsv2f>3.</span> Models Are Compression Machines </a> </li><li class="" data-astro-cid-ssfzsv2f> <a href="/eng-ai/part1/04-bias-variance-tradeoff" data-astro-cid-ssfzsv2f> <span class="chapter-num" data-astro-cid-ssfzsv2f>4.</span> The Bias-Variance Tradeoff </a> </li><li class="" data-astro-cid-ssfzsv2f> <a href="/eng-ai/part1/05-features-how-machines-see-the-world" data-astro-cid-ssfzsv2f> <span class="chapter-num" data-astro-cid-ssfzsv2f>5.</span> Features: How Machines See the World </a> </li> </ul> </section><section class="part-section" data-astro-cid-ssfzsv2f> <h3 class="" data-astro-cid-ssfzsv2f> <a href="/eng-ai/part2" data-astro-cid-ssfzsv2f>
Part II: Classical ML </a> </h3> <ul data-astro-cid-ssfzsv2f> <li class="" data-astro-cid-ssfzsv2f> <a href="/eng-ai/part2/06-linear-models" data-astro-cid-ssfzsv2f> <span class="chapter-num" data-astro-cid-ssfzsv2f>6.</span> Linear Models </a> </li><li class="" data-astro-cid-ssfzsv2f> <a href="/eng-ai/part2/07-logistic-regression" data-astro-cid-ssfzsv2f> <span class="chapter-num" data-astro-cid-ssfzsv2f>7.</span> Logistic Regression </a> </li><li class="" data-astro-cid-ssfzsv2f> <a href="/eng-ai/part2/08-decision-trees" data-astro-cid-ssfzsv2f> <span class="chapter-num" data-astro-cid-ssfzsv2f>8.</span> Decision Trees </a> </li><li class="" data-astro-cid-ssfzsv2f> <a href="/eng-ai/part2/09-ensembles" data-astro-cid-ssfzsv2f> <span class="chapter-num" data-astro-cid-ssfzsv2f>9.</span> Ensembles </a> </li><li class="" data-astro-cid-ssfzsv2f> <a href="/eng-ai/part2/10-loss-functions" data-astro-cid-ssfzsv2f> <span class="chapter-num" data-astro-cid-ssfzsv2f>10.</span> Loss Functions and Optimization </a> </li> </ul> </section><section class="part-section" data-astro-cid-ssfzsv2f> <h3 class="" data-astro-cid-ssfzsv2f> <a href="/eng-ai/part3" data-astro-cid-ssfzsv2f>
Part III: Neural Networks </a> </h3> <ul data-astro-cid-ssfzsv2f> <li class="" data-astro-cid-ssfzsv2f> <a href="/eng-ai/part3/11-neurons-as-math" data-astro-cid-ssfzsv2f> <span class="chapter-num" data-astro-cid-ssfzsv2f>11.</span> Neurons as Math </a> </li><li class="" data-astro-cid-ssfzsv2f> <a href="/eng-ai/part3/12-forward-pass" data-astro-cid-ssfzsv2f> <span class="chapter-num" data-astro-cid-ssfzsv2f>12.</span> The Forward Pass </a> </li><li class="" data-astro-cid-ssfzsv2f> <a href="/eng-ai/part3/13-backpropagation" data-astro-cid-ssfzsv2f> <span class="chapter-num" data-astro-cid-ssfzsv2f>13.</span> Backpropagation </a> </li><li class="" data-astro-cid-ssfzsv2f> <a href="/eng-ai/part3/14-optimization-deep-learning" data-astro-cid-ssfzsv2f> <span class="chapter-num" data-astro-cid-ssfzsv2f>14.</span> Optimization in Deep Learning </a> </li><li class="" data-astro-cid-ssfzsv2f> <a href="/eng-ai/part3/15-representation-learning" data-astro-cid-ssfzsv2f> <span class="chapter-num" data-astro-cid-ssfzsv2f>15.</span> Representation Learning </a> </li> </ul> </section><section class="part-section" data-astro-cid-ssfzsv2f> <h3 class="" data-astro-cid-ssfzsv2f> <a href="/eng-ai/part4" data-astro-cid-ssfzsv2f>
Part IV: Deep Architectures </a> </h3> <ul data-astro-cid-ssfzsv2f> <li class="" data-astro-cid-ssfzsv2f> <a href="/eng-ai/part4/16-convolutional-neural-networks" data-astro-cid-ssfzsv2f> <span class="chapter-num" data-astro-cid-ssfzsv2f>16.</span> Convolutional Neural Networks </a> </li><li class="" data-astro-cid-ssfzsv2f> <a href="/eng-ai/part4/17-recurrent-neural-networks" data-astro-cid-ssfzsv2f> <span class="chapter-num" data-astro-cid-ssfzsv2f>17.</span> Recurrent Neural Networks </a> </li><li class="" data-astro-cid-ssfzsv2f> <a href="/eng-ai/part4/18-embeddings" data-astro-cid-ssfzsv2f> <span class="chapter-num" data-astro-cid-ssfzsv2f>18.</span> Embeddings </a> </li><li class="" data-astro-cid-ssfzsv2f> <a href="/eng-ai/part4/19-attention" data-astro-cid-ssfzsv2f> <span class="chapter-num" data-astro-cid-ssfzsv2f>19.</span> Attention </a> </li><li class="" data-astro-cid-ssfzsv2f> <a href="/eng-ai/part4/20-transformers" data-astro-cid-ssfzsv2f> <span class="chapter-num" data-astro-cid-ssfzsv2f>20.</span> Transformers </a> </li> </ul> </section><section class="part-section" data-astro-cid-ssfzsv2f> <h3 class="" data-astro-cid-ssfzsv2f> <a href="/eng-ai/part5" data-astro-cid-ssfzsv2f>
Part V: Language Models </a> </h3> <ul data-astro-cid-ssfzsv2f> <li class="" data-astro-cid-ssfzsv2f> <a href="/eng-ai/part5/21-next-token-prediction" data-astro-cid-ssfzsv2f> <span class="chapter-num" data-astro-cid-ssfzsv2f>21.</span> Next-Token Prediction </a> </li><li class="" data-astro-cid-ssfzsv2f> <a href="/eng-ai/part5/22-pretraining" data-astro-cid-ssfzsv2f> <span class="chapter-num" data-astro-cid-ssfzsv2f>22.</span> Pretraining </a> </li><li class="" data-astro-cid-ssfzsv2f> <a href="/eng-ai/part5/23-fine-tuning" data-astro-cid-ssfzsv2f> <span class="chapter-num" data-astro-cid-ssfzsv2f>23.</span> Fine-Tuning </a> </li><li class="" data-astro-cid-ssfzsv2f> <a href="/eng-ai/part5/24-rlhf" data-astro-cid-ssfzsv2f> <span class="chapter-num" data-astro-cid-ssfzsv2f>24.</span> RLHF </a> </li><li class="" data-astro-cid-ssfzsv2f> <a href="/eng-ai/part5/25-emergent-abilities-and-scaling" data-astro-cid-ssfzsv2f> <span class="chapter-num" data-astro-cid-ssfzsv2f>25.</span> Emergent Abilities and Scaling </a> </li> </ul> </section><section class="part-section" data-astro-cid-ssfzsv2f> <h3 class="" data-astro-cid-ssfzsv2f> <a href="/eng-ai/part6" data-astro-cid-ssfzsv2f>
Part VI: Modern AI Systems </a> </h3> <ul data-astro-cid-ssfzsv2f> <li class="" data-astro-cid-ssfzsv2f> <a href="/eng-ai/part6/26-prompting-as-programming" data-astro-cid-ssfzsv2f> <span class="chapter-num" data-astro-cid-ssfzsv2f>26.</span> Prompting as Programming </a> </li><li class="" data-astro-cid-ssfzsv2f> <a href="/eng-ai/part6/27-retrieval-augmented-generation" data-astro-cid-ssfzsv2f> <span class="chapter-num" data-astro-cid-ssfzsv2f>27.</span> Retrieval-Augmented Generation </a> </li><li class="" data-astro-cid-ssfzsv2f> <a href="/eng-ai/part6/28-tools-and-function-calling" data-astro-cid-ssfzsv2f> <span class="chapter-num" data-astro-cid-ssfzsv2f>28.</span> Tools and Function Calling </a> </li><li class="" data-astro-cid-ssfzsv2f> <a href="/eng-ai/part6/29-agents" data-astro-cid-ssfzsv2f> <span class="chapter-num" data-astro-cid-ssfzsv2f>29.</span> Agents - Models That Decide What to Do </a> </li><li class="" data-astro-cid-ssfzsv2f> <a href="/eng-ai/part6/30-memory-and-planning" data-astro-cid-ssfzsv2f> <span class="chapter-num" data-astro-cid-ssfzsv2f>30.</span> Memory, Planning, and Long-Term Behavior </a> </li> </ul> </section><section class="part-section" data-astro-cid-ssfzsv2f> <h3 class="" data-astro-cid-ssfzsv2f> <a href="/eng-ai/part7" data-astro-cid-ssfzsv2f>
Part VII: Engineering Reality </a> </h3> <ul data-astro-cid-ssfzsv2f> <li class="" data-astro-cid-ssfzsv2f> <a href="/eng-ai/part7/31-data-pipelines" data-astro-cid-ssfzsv2f> <span class="chapter-num" data-astro-cid-ssfzsv2f>31.</span> Data Pipelines - Where Models Are Born and Die </a> </li><li class="" data-astro-cid-ssfzsv2f> <a href="/eng-ai/part7/32-training-vs-inference" data-astro-cid-ssfzsv2f> <span class="chapter-num" data-astro-cid-ssfzsv2f>32.</span> Training vs Inference - Two Different Worlds </a> </li><li class="active" data-astro-cid-ssfzsv2f> <a href="/eng-ai/part7/33-evaluation" data-astro-cid-ssfzsv2f> <span class="chapter-num" data-astro-cid-ssfzsv2f>33.</span> Evaluation - Why Accuracy Is Not Enough </a> </li><li class="" data-astro-cid-ssfzsv2f> <a href="/eng-ai/part7/34-hallucinations-bias-brittleness" data-astro-cid-ssfzsv2f> <span class="chapter-num" data-astro-cid-ssfzsv2f>34.</span> Hallucinations, Bias, and Brittleness </a> </li><li class="" data-astro-cid-ssfzsv2f> <a href="/eng-ai/part7/35-safety-alignment-control" data-astro-cid-ssfzsv2f> <span class="chapter-num" data-astro-cid-ssfzsv2f>35.</span> Safety, Alignment, and Control </a> </li> </ul> </section><section class="part-section" data-astro-cid-ssfzsv2f> <h3 class="" data-astro-cid-ssfzsv2f> <a href="/eng-ai/part8" data-astro-cid-ssfzsv2f>
Part VIII: The Frontier </a> </h3> <ul data-astro-cid-ssfzsv2f> <li class="" data-astro-cid-ssfzsv2f> <a href="/eng-ai/part8/36-scaling-laws" data-astro-cid-ssfzsv2f> <span class="chapter-num" data-astro-cid-ssfzsv2f>36.</span> Scaling Laws - Why Bigger Keeps Winning </a> </li><li class="" data-astro-cid-ssfzsv2f> <a href="/eng-ai/part8/37-multimodal-models" data-astro-cid-ssfzsv2f> <span class="chapter-num" data-astro-cid-ssfzsv2f>37.</span> Multimodal Models </a> </li><li class="" data-astro-cid-ssfzsv2f> <a href="/eng-ai/part8/38-self-improving-systems" data-astro-cid-ssfzsv2f> <span class="chapter-num" data-astro-cid-ssfzsv2f>38.</span> Self-Improving Systems </a> </li><li class="" data-astro-cid-ssfzsv2f> <a href="/eng-ai/part8/39-artificial-general-intelligence" data-astro-cid-ssfzsv2f> <span class="chapter-num" data-astro-cid-ssfzsv2f>39.</span> Artificial General Intelligence </a> </li><li class="" data-astro-cid-ssfzsv2f> <a href="/eng-ai/part8/40-the-engineers-role" data-astro-cid-ssfzsv2f> <span class="chapter-num" data-astro-cid-ssfzsv2f>40.</span> The Engineer&#39;s Role </a> </li> </ul> </section> </nav> </aside>   <main class="chapter-content"> <nav class="breadcrumbs" aria-label="Breadcrumb" data-astro-cid-ilhxcym7> <ol data-astro-cid-ilhxcym7> <li data-astro-cid-ilhxcym7><a href="/eng-ai/" data-astro-cid-ilhxcym7>Home</a></li> <li data-astro-cid-ilhxcym7><a href="/eng-ai/part7" data-astro-cid-ilhxcym7>Part VII: Engineering Reality</a></li> <li aria-current="page" data-astro-cid-ilhxcym7>Evaluation - Why Accuracy Is Not Enough</li> </ol> </nav>  <article class="chapter"> <h1 id="chapter-33-evaluation---why-accuracy-is-not-enough">Chapter 33: Evaluation - Why Accuracy Is Not Enough</h1>
<p>A model achieves 95% accuracy on the test set. Is it good? It depends. If the task is classifying cats vs dogs, 95% is excellent. If the task is diagnosing cancer, 95% might be catastrophic‚Äîmissing 5% of cases could mean thousands of deaths.</p>
<p>Accuracy is the most common metric in machine learning papers, and it is one of the least informative. It collapses all failure modes into a single number, hiding what matters: which errors the model makes, how often, and at what cost. Production systems require richer evaluation that captures real-world constraints.</p>
<p>This chapter explains why accuracy misleads, why benchmarks are poor proxies for deployment performance, and how to evaluate models in ways that matter.</p>
<hr>
<h2 id="train-vs-test-why-validation-matters-ch33">Train vs Test: Why Validation Matters</h2>
<p>The purpose of evaluation is to measure how a model generalizes to unseen data. If you evaluate on training data, the model gets 100% accuracy by memorizing. To measure generalization, you must evaluate on held-out test data.</p>
<p><strong>Train/validation/test split:</strong></p>
<p><strong>Training set</strong> (70-80%): Used to train the model. The model sees these examples and adjusts weights to minimize loss.</p>
<p><strong>Validation set</strong> (10-15%): Used to tune hyperparameters (learning rate, regularization). The model does not train on validation data, but you use validation performance to make decisions (which hyperparameters to use, when to stop training).</p>
<p><strong>Test set</strong> (10-20%): Used only once, at the end, to report final performance. The model never sees test data during training or tuning. Test accuracy is your estimate of real-world performance.</p>
<p><strong>Why three sets?</strong> If you tune hyperparameters using test data, you are implicitly fitting the test set‚Äîinformation leaks from test to training. The model appears to generalize, but you have overfit to the test distribution. A separate validation set lets you tune without contaminating the test set.</p>
<p><strong>Overfitting to the test set</strong> happens when you evaluate repeatedly. Imagine you train 100 models, test them all, and report the best. You are selecting for test performance, which means you are fitting the test set. The reported accuracy is optimistic‚Äîit does not reflect performance on truly unseen data.</p>
<p>Academic benchmarks suffer from this. ImageNet has been used for a decade. Thousands of papers report results. Researchers tune architectures, hyperparameters, and data augmentation until ImageNet accuracy is maximized. The test set is no longer held-out‚Äîit has been implicitly fit through repeated evaluation. Reported ‚ÄúSOTA‚Äù results are partially artifacts of overfitting.</p>
<p><strong>Cross-validation</strong> reduces overfitting to a single test split. K-fold cross-validation divides data into K folds (e.g., 5). Train on K-1 folds, test on the remaining fold. Repeat K times, rotating which fold is the test set. Average the results.</p>
<p>Cross-validation gives a more robust estimate of performance, but it is K times more expensive (train K models instead of 1). For large datasets or large models, this is prohibitive. For small datasets, cross-validation is essential.</p>
<p><strong>Temporal splits</strong> are critical for time-series data. If you randomly split time-series data, the model sees future data points in training and past data points in testing. This is leakage‚Äîthe model learns from the future. Correct splits respect time: train on data before time T, test on data after time T.</p>
<p>Example: A stock price prediction model must be trained on 2020-2022 data and tested on 2023 data. Randomly mixing 2020-2023 data across train/test is cheating. The model will learn patterns from 2023 and appear to generalize when it does not.</p>
<hr>
<h2 id="accuracy-is-not-enough-cost-sensitive-errors-ch33">Accuracy Is Not Enough: Cost-Sensitive Errors</h2>
<p><strong>Accuracy</strong> measures the fraction of predictions that are correct:</p>
<span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mtext>Accuracy</mtext><mo>=</mo><mfrac><mtext>Correct¬†predictions</mtext><mtext>Total¬†predictions</mtext></mfrac></mrow><annotation encoding="application/x-tex">\text{Accuracy} = \frac{\text{Correct predictions}}{\text{Total predictions}}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8778em;vertical-align:-0.1944em;"></span><span class="mord text"><span class="mord">Accuracy</span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:2.2519em;vertical-align:-0.8804em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.3714em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord text"><span class="mord">Total¬†predictions</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord text"><span class="mord">Correct¬†predictions</span></span></span></span></span><span class="vlist-s">‚Äã</span></span><span class="vlist-r"><span class="vlist" style="height:0.8804em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></span>
<p>Accuracy treats all errors equally. But not all errors have equal cost.</p>
<p><strong>Example: Medical diagnosis</strong></p>
<p>A cancer detection model classifies scans as ‚Äúcancer‚Äù or ‚Äúno cancer.‚Äù The test set has 1,000 scans: 950 healthy, 50 cancerous (5% prevalence).</p>
<p><strong>Model A</strong> predicts ‚Äúno cancer‚Äù for all scans. Accuracy: 950/1000 = 95%. The model is 95% accurate but useless‚Äîit missed every cancer case.</p>
<p><strong>Model B</strong> predicts ‚Äúcancer‚Äù for 100 scans: 45 true positives, 55 false positives (healthy patients flagged as cancer), 5 false negatives (cancers missed). Accuracy: (45 + 895) / 1000 = 94%.</p>
<p>Model B has lower accuracy than Model A, but it is far better. It catches 45/50 cancers (90% sensitivity). Model A catches 0/50 (0% sensitivity).</p>
<p>Accuracy is misleading because the classes are imbalanced (5% positive, 95% negative). A model that always predicts the majority class achieves high accuracy while being worthless.</p>
<p><strong>Precision and recall</strong> capture different error modes:</p>
<p><strong>Precision</strong>: Of the examples the model predicted positive, how many are actually positive?</p>
<span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mtext>Precision</mtext><mo>=</mo><mfrac><mtext>True¬†Positives</mtext><mtext>True¬†Positives¬†+¬†False¬†Positives</mtext></mfrac></mrow><annotation encoding="application/x-tex">\text{Precision} = \frac{\text{True Positives}}{\text{True Positives + False Positives}}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord text"><span class="mord">Precision</span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:2.1297em;vertical-align:-0.7693em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.3603em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord text"><span class="mord">True¬†Positives¬†+¬†False¬†Positives</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord text"><span class="mord">True¬†Positives</span></span></span></span></span><span class="vlist-s">‚Äã</span></span><span class="vlist-r"><span class="vlist" style="height:0.7693em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></span>
<p>For Model B: <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mn>45</mn><mrow><mn>45</mn><mo>+</mo><mn>55</mn></mrow></mfrac><mo>=</mo><mn>0.45</mn></mrow><annotation encoding="application/x-tex">\frac{45}{45 + 55} = 0.45</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.2484em;vertical-align:-0.4033em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8451em;"><span style="top:-2.655em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">45</span><span class="mbin mtight">+</span><span class="mord mtight">55</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">45</span></span></span></span></span><span class="vlist-s">‚Äã</span></span><span class="vlist-r"><span class="vlist" style="height:0.4033em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">0.45</span></span></span></span> (45% of flagged scans are actual cancers).</p>
<p><strong>Recall</strong> (Sensitivity): Of the actual positive examples, how many did the model catch?</p>
<span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mtext>Recall</mtext><mo>=</mo><mfrac><mtext>True¬†Positives</mtext><mtext>True¬†Positives¬†+¬†False¬†Negatives</mtext></mfrac></mrow><annotation encoding="application/x-tex">\text{Recall} = \frac{\text{True Positives}}{\text{True Positives + False Negatives}}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em;"></span><span class="mord text"><span class="mord">Recall</span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:2.2408em;vertical-align:-0.8804em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.3603em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord text"><span class="mord">True¬†Positives¬†+¬†False¬†Negatives</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord text"><span class="mord">True¬†Positives</span></span></span></span></span><span class="vlist-s">‚Äã</span></span><span class="vlist-r"><span class="vlist" style="height:0.8804em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></span>
<p>For Model B: <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mn>45</mn><mrow><mn>45</mn><mo>+</mo><mn>5</mn></mrow></mfrac><mo>=</mo><mn>0.90</mn></mrow><annotation encoding="application/x-tex">\frac{45}{45 + 5} = 0.90</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.2484em;vertical-align:-0.4033em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8451em;"><span style="top:-2.655em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">45</span><span class="mbin mtight">+</span><span class="mord mtight">5</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">45</span></span></span></span></span><span class="vlist-s">‚Äã</span></span><span class="vlist-r"><span class="vlist" style="height:0.4033em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">0.90</span></span></span></span> (90% of cancers detected).</p>
<p><strong>Precision-recall trade-off:</strong> You can increase recall by predicting ‚Äúcancer‚Äù more often, but this reduces precision (more false positives). You can increase precision by predicting ‚Äúcancer‚Äù only when very confident, but this reduces recall (more false negatives).</p>
<p>In medical diagnosis, false negatives (missing cancer) are catastrophic. False positives (flagging healthy patients) are costly but not deadly. You prioritize high recall, accepting lower precision. The model should err on the side of caution‚Äîflag more, miss less.</p>
<p>In spam filtering, false positives (marking legitimate email as spam) are more costly than false negatives (letting spam through). You prioritize precision over recall. Better to let some spam through than to lose important emails.</p>
<p><strong>F1 score</strong> is the harmonic mean of precision and recall:</p>
<span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msub><mi>F</mi><mn>1</mn></msub><mo>=</mo><mn>2</mn><mo>‚ãÖ</mo><mfrac><mrow><mtext>Precision</mtext><mo>‚ãÖ</mo><mtext>Recall</mtext></mrow><mrow><mtext>Precision</mtext><mo>+</mo><mtext>Recall</mtext></mrow></mfrac></mrow><annotation encoding="application/x-tex">F_1 = 2 \cdot \frac{\text{Precision} \cdot \text{Recall}}{\text{Precision} + \text{Recall}}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">F</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.1389em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">‚Äã</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">2</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">‚ãÖ</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:2.1408em;vertical-align:-0.7693em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.3714em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord text"><span class="mord">Precision</span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mord text"><span class="mord">Recall</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord text"><span class="mord">Precision</span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">‚ãÖ</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mord text"><span class="mord">Recall</span></span></span></span></span><span class="vlist-s">‚Äã</span></span><span class="vlist-r"><span class="vlist" style="height:0.7693em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></span>
<p>F1 balances precision and recall, but it assumes equal importance. For imbalanced classes or cost-sensitive errors, precision and recall individually are more informative than a single score.</p>
<hr>
<h2 id="distribution-shift-when-metrics-become-meaningless-ch33">Distribution Shift: When Metrics Become Meaningless</h2>
<p>Models are trained on one dataset and deployed on another. If the deployment distribution differs from the training distribution, test accuracy does not predict deployment performance.</p>
<p><strong>Domain shift</strong> occurs when training and deployment come from different domains:</p>
<p><strong>Example: Face recognition</strong></p>
<p>A face recognition model trained on Flickr images (mostly well-lit, frontal faces, high resolution) achieves 99% accuracy on a Flickr test set. Deployed in surveillance cameras (varied lighting, angles, low resolution), accuracy drops to 85%. The test set does not match deployment.</p>
<p><strong>Covariate shift</strong> (Chapter 31): The input distribution changes but the relationship between input and output stays the same. Test metrics become unreliable because the test set does not represent the deployment input distribution.</p>
<p><strong>Concept drift</strong> (Chapter 31): The relationship between input and output changes. Test metrics are meaningless because the ground truth has changed.</p>
<p><strong>Adversarial distribution shift</strong> occurs when adversaries actively manipulate inputs to fool the model:</p>
<p><strong>Example: Fraud detection</strong></p>
<p>A fraud detection model trained on 2022 fraud patterns achieves 98% accuracy on 2022 test data. Deployed in 2023, fraudsters have adapted. They use new tactics (account takeover instead of carding, synthetic identities instead of stolen cards). The model, trained on old patterns, misses new fraud. Test accuracy: 98%. Deployment accuracy: 70%.</p>
<p>The test set does not account for adversarial adaptation. Fraudsters are not random‚Äîthey optimize to evade detection. Test sets cannot capture this without adversarial red teaming.</p>
<p><strong>Detecting distribution shift</strong> requires monitoring production data (Chapter 31): compare feature distributions, track model confidence, measure performance on labeled samples. If distributions drift, retrain. Test accuracy is a snapshot, not a guarantee.</p>
<hr>
<h2 id="human-evaluation-why-humans-stay-in-the-loop-ch33">Human Evaluation: Why Humans Stay in the Loop</h2>
<p>For many tasks, automated metrics are insufficient. The metric is not well-defined, ground truth is subjective, or what matters cannot be captured by a formula. Human evaluation is the only way to measure quality.</p>
<p><strong>When human evaluation is necessary:</strong></p>
<p><strong>Open-ended generation</strong>: Text generation (stories, summaries, dialogue), image generation (DALL-E, Midjourney). Metrics like BLEU (translation), ROUGE (summarization), or perceptual similarity (images) correlate poorly with human judgment. Only humans can judge fluency, coherence, and quality.</p>
<p><strong>Subjective tasks</strong>: Content moderation (is this toxic?), sentiment analysis (is this positive?), humor detection (is this funny?). Ground truth is subjective. Inter-human agreement is low. Metrics are noisy proxies.</p>
<p><strong>Safety and alignment</strong>: Does the model refuse harmful requests? Does it follow instructions? Does it exhibit bias? These are qualitative judgments requiring human review.</p>
<p><strong>Human evaluation methods:</strong></p>
<p><strong>Pairwise comparison</strong>: Show humans two model outputs (Model A and Model B) and ask: ‚ÄúWhich is better?‚Äù Humans are better at relative judgments than absolute ratings.</p>
<p><strong>Likert scale ratings</strong>: ‚ÄúRate this response from 1 (very bad) to 5 (very good).‚Äù Easier to collect than pairwise comparisons but noisier (rating scales are subjective).</p>
<p><strong>Red teaming</strong>: Hire experts to adversarially test the model‚Äîtry to make it fail, generate harmful content, expose biases. Red teamers find edge cases automated metrics miss.</p>
<p><strong>RLHF (Reinforcement Learning from Human Feedback)</strong> (Chapter 24): Humans rate model outputs, and these ratings train a reward model that guides further training. Human evaluation is not just measurement‚Äîit is the training signal.</p>
<p><strong>Challenges of human evaluation:</strong></p>
<p><strong>Cost</strong>: Humans are expensive. Evaluating 10,000 model outputs at <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>0.10</mn><mi>p</mi><mi>e</mi><mi>r</mi><mi>r</mi><mi>a</mi><mi>t</mi><mi>i</mi><mi>n</mi><mi>g</mi><mo>=</mo></mrow><annotation encoding="application/x-tex">0.10 per rating = </annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.854em;vertical-align:-0.1944em;"></span><span class="mord">0.10</span><span class="mord mathnormal">p</span><span class="mord mathnormal" style="margin-right:0.02778em;">err</span><span class="mord mathnormal">a</span><span class="mord mathnormal">t</span><span class="mord mathnormal">in</span><span class="mord mathnormal" style="margin-right:0.03588em;">g</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span></span></span></span>1,000. For large-scale evaluation, this adds up.</p>
<p><strong>Noise</strong>: Inter-rater agreement is low for subjective tasks. Different humans give different ratings. Aggregate ratings over multiple raters to reduce noise.</p>
<p><strong>Bias</strong>: Human raters have biases (linguistic, cultural, demographic). Ratings reflect rater preferences, not objective quality.</p>
<p><strong>Scale</strong>: Automated metrics scale to millions of examples. Human evaluation scales to thousands. You cannot human-evaluate every query in production.</p>
<p>Despite these challenges, human evaluation is necessary for tasks where automated metrics fail. The best approach combines both: automated metrics for fast iteration, human evaluation for final quality checks.</p>
<hr>
<h2 id="hidden-failure-modes-rare-but-deadly-errors-ch33">Hidden Failure Modes: Rare but Deadly Errors</h2>
<p><strong>Aggregate metrics</strong> (accuracy, F1, AUC) hide rare failures. A model can have 99% accuracy overall but fail catastrophically on specific subgroups or edge cases.</p>
<p><strong>Long-tail failures</strong> are rare cases that matter:</p>
<p><strong>Example: Self-driving cars</strong></p>
<p>A self-driving perception model achieves 99.99% accuracy on pedestrian detection. Sounds excellent. But 0.01% failure on 1 million frames = 100 failures. If even one failure causes a crash, the model is unsafe.</p>
<p>Long-tail events‚Äîunusual clothing, occlusions, rare weather, edge-case scenarios‚Äîare underrepresented in test sets but critical in deployment. Aggregate accuracy does not capture tail risk.</p>
<p><strong>Subgroup disparities</strong>: A model can have high overall accuracy but low accuracy on specific demographic subgroups:</p>
<p><strong>Example: Face recognition</strong></p>
<p>A face recognition model achieves 95% accuracy overall. Broken down by demographics:</p>
<ul>
<li>Light-skinned males: 99% accuracy</li>
<li>Dark-skinned females: 65% accuracy</li>
</ul>
<p>The aggregate metric hides that the model fails on underrepresented subgroups. Deployment causes harm to specific populations while appearing successful on average.</p>
<p><strong>Adversarial examples</strong> (Chapter 34): Tiny perturbations that humans do not notice fool the model into wildly wrong predictions. Adversarial accuracy is near 0% for most models, even if standard accuracy is 99%. Test sets do not include adversarial examples unless explicitly constructed.</p>
<p><strong>Stress testing</strong> probes for hidden failures:</p>
<p><strong>Checklist-style evaluation</strong> (Ribeiro et al., 2020): Manually design test cases covering capabilities (negation, coreference, robustness to typos). Example: Sentiment analysis should correctly handle ‚Äúnot bad‚Äù (positive), ‚Äúnot good‚Äù (negative), ‚Äúpretty bad‚Äù (negative). Simple accuracy does not catch these.</p>
<p><strong>Counterfactual evaluation</strong>: Change one word in the input and measure if the prediction changes correctly. Example: ‚ÄúHe is a doctor‚Äù ‚Üí ‚ÄúShe is a doctor‚Äù should not change predictions in gender-neutral tasks. If it does, the model has learned spurious gender correlations.</p>
<p><strong>Worst-group performance</strong>: Report accuracy not just overall but on the worst-performing subgroup. A model with 95% average accuracy and 60% worst-group accuracy is biased. Deploy with caution.</p>
<p><img  src="/eng-ai/_astro/33-diagram.DgpwAfK-_Z2mCW6m.svg" alt="Hidden Failure Modes: Rare but Deadly Errors diagram" width="800" height="450" loading="lazy" decoding="async"></p>
<p><strong>Figure 33.1</strong>: Precision-recall trade-off curve. As recall increases (catching more positives), precision decreases (more false positives). The operating point depends on the cost of errors: spam filtering prioritizes precision (avoid flagging legitimate email), cancer detection prioritizes recall (catch all cases, accept false alarms).</p>
<hr>
<h2 id="benchmarks-are-proxies-not-goals-ch33">Benchmarks Are Proxies, Not Goals</h2>
<p><strong>Benchmarks</strong> (ImageNet, GLUE, SuperGLUE, SQuAD) are standard datasets used to compare models. They enable fair comparison: same data, same splits, same metrics. But they are proxies for real-world performance, and proxies can mislead.</p>
<p><strong>Benchmark saturation:</strong> When many researchers optimize for the same benchmark, performance plateaus. ImageNet top-1 accuracy reached 99%, exceeding estimated human performance. Does this mean computer vision is solved? No. Models fail on:</p>
<ul>
<li><strong>Domain shift</strong>: Natural images (ImageNet) vs medical scans, satellite imagery</li>
<li><strong>Robustness</strong>: Small perturbations, occlusions, adversarial attacks</li>
<li><strong>Generalization</strong>: Long-tail categories, rare objects, unusual viewpoints</li>
</ul>
<p><strong>SOTA (State-of-the-Art) does not mean deployment-ready.</strong> Achieving SOTA on SuperGLUE does not mean the model understands language‚Äîit means the model is good at SuperGLUE tasks. The benchmark is a proxy for understanding, but a noisy one.</p>
<p><strong>Gaming benchmarks:</strong> Researchers tune models specifically for benchmark performance, sometimes learning shortcuts that do not generalize. Example: SQuAD (question answering) models learned to exploit biases in question phrasing rather than understanding context. When evaluated on adversarial versions of SQuAD, performance dropped 40%.</p>
<p><strong>Benchmark artifacts</strong>: Datasets have biases and shortcuts. Models exploit these rather than learning the intended skill. The benchmark appears solved, but the model has not learned the underlying capability.</p>
<p><strong>Production metrics differ from benchmark metrics:</strong></p>
<ul>
<li><strong>Latency</strong>: Benchmarks ignore latency. Production requires &#x3C;100ms.</li>
<li><strong>Robustness</strong>: Benchmarks use clean test sets. Production faces noisy, adversarial, out-of-distribution inputs.</li>
<li><strong>User satisfaction</strong>: Benchmarks measure accuracy. Production cares about engagement, retention, revenue.</li>
</ul>
<p><strong>Real-world evaluation</strong> requires business metrics, not just ML metrics. A model with 95% accuracy that increases revenue by 10% is more valuable than a model with 99% accuracy that increases revenue by 1%. Accuracy is a proxy. Revenue is the goal.</p>
<hr>
<h2 id="engineering-takeaway-ch33">Engineering Takeaway</h2>
<p><strong>Accuracy alone is meaningless without context‚Äîclass imbalance and cost-sensitive errors require precision, recall, and domain-specific metrics.</strong> A model can have 95% accuracy and be useless (predicting majority class) or catastrophic (missing critical cases). Precision and recall capture different failure modes. F1 balances them but assumes equal cost. For imbalanced or cost-sensitive problems, report precision, recall, and confusion matrices‚Äînot just accuracy.</p>
<p><strong>Validation strategy must match deployment‚Äîuse temporal splits for time-series, stratified splits for imbalanced data.</strong> Randomly splitting time-series data leaks future information into training. Randomly splitting imbalanced data may leave rare classes out of the test set. The test set must resemble deployment. If deployment is time-ordered (fraud detection, stock prediction), test sets must be time-ordered. If deployment has rare but critical cases (medical diagnosis, safety systems), test sets must include them.</p>
<p><strong>Distribution shift invalidates test metrics‚Äîmonitor production performance continuously, retrain when drift is detected.</strong> Test accuracy measures generalization to the test distribution, not the deployment distribution. When deployment distribution shifts (covariate shift, concept drift, adversarial adaptation), test metrics become stale. Production monitoring is the real test. Log predictions, sample labels, measure accuracy on recent data. When accuracy degrades, retrain or adapt. Test metrics are predictions, production metrics are ground truth.</p>
<p><strong>Rare cases matter most in high-stakes domains‚Äîmeasure worst-group performance, not just average performance.</strong> A model with 95% average accuracy and 60% accuracy on a minority group is biased. Aggregate metrics hide disparities. Report accuracy broken down by subgroups (demographics, geographies, edge cases). For safety-critical systems, worst-case performance matters more than average. One catastrophic failure outweighs 1,000 successes.</p>
<p><strong>Human evaluation is essential for open-ended tasks‚Äîautomated metrics correlate poorly with quality for generation and subjective tasks.</strong> BLEU score does not capture fluency. Perceptual similarity does not capture artistic quality. Sentiment scores do not capture nuance. For generation (text, images, music), content moderation, and alignment, humans must judge quality. Human evaluation is expensive and noisy, but it is the ground truth automated metrics approximate. Combine automated metrics (cheap, scalable) with human evaluation (expensive, accurate) for robust assessment.</p>
<p><strong>Benchmarks are proxies, not goals‚ÄîSOTA on ImageNet does not mean vision is solved.</strong> Benchmarks enable comparison but do not capture deployment constraints. A model that achieves SOTA on GLUE but fails on out-of-domain text is not useful. A model that achieves 99% accuracy on ImageNet but takes 10 seconds to run is not deployable. Benchmark performance is a starting point, not an end goal. Production evaluation requires latency, robustness, fairness, and business metrics‚Äînot just benchmark scores.</p>
<p><strong>Real-world evaluation requires business metrics‚Äîaccuracy is a proxy for what actually matters (engagement, revenue, safety).</strong> ML models are not ends in themselves‚Äîthey serve business goals. A search ranking model is valuable if it increases clicks and revenue, not if it improves NDCG. A recommendation model is valuable if it increases watch time and retention, not if it improves AUC. Business metrics are noisy and hard to measure, but they are what matter. Optimize ML metrics as proxies, but validate with business metrics.</p>
<hr>
<h2 id="references-and-further-reading-ch33">References and Further Reading</h2>
<p><strong>Documenting Large Webtext Corpora: A Case Study on the Colossal Clean Crawled Corpus</strong>
Dodge, J., Sap, M., Marasoviƒá, A., Agnew, W., Ilharco, G., Groeneveld, D., Mitchell, M., &#x26; Gardner, M. (2021). <em>EMNLP 2021</em></p>
<p><em>Why it matters:</em> This paper examines the C4 dataset (used to train T5 and many other models) and documents biases, quality issues, and artifacts. It shows that even ‚Äúclean‚Äù datasets contain offensive content, misinformation, and spam. The paper argues that dataset documentation is essential for understanding model behavior‚Äîwithout knowing what data the model trained on, you cannot explain its failures. It introduced a framework for dataset documentation that has influenced how researchers report data provenance.</p>
<p><strong>Beyond Accuracy: Behavioral Testing of NLP Models with CheckList</strong>
Ribeiro, M. T., Wu, T., Guestrin, C., &#x26; Singh, S. (2020). <em>ACL 2020</em></p>
<p><em>Why it matters:</em> CheckList is a methodology for testing NLP models through capability-focused test cases (negation, coreference, robustness to typos). Rather than relying on aggregate accuracy, CheckList measures performance on specific linguistic phenomena. The paper shows that models with high accuracy on standard benchmarks fail simple CheckList tests, revealing hidden weaknesses. CheckList has been widely adopted for systematic testing of language models, showing that accuracy is insufficient for measuring model quality.</p>
<p><strong>A Closer Look at Accuracy vs. Robustness</strong>
Taori, R., Katariya, V., Yaghmaie, A., Recht, B., &#x26; Schmidt, L. (2020). <em>arXiv:2004.06524</em></p>
<p><em>Why it matters:</em> This paper investigates the trade-off between standard accuracy and robustness to distribution shift. It shows that models with high ImageNet accuracy often have low accuracy on shifted distributions (ImageNet-C, ImageNet-A). The paper challenges the assumption that higher benchmark accuracy means better models‚Äîrobustness matters as much as accuracy, but benchmarks do not measure it. This work motivated research into robustness as a first-class evaluation criterion, not an afterthought.</p>
<hr>
<p>The next chapter examines why models fail in scary ways: hallucinations that confidently generate false information, biases that amplify discrimination, adversarial examples that break perception, and brittleness that causes catastrophic failures on edge cases.</p> </article> <nav class="chapter-navigation" data-astro-cid-pux6a34n> <a href="/eng-ai/part7/32-training-vs-inference" class="nav-prev " data-astro-cid-pux6a34n> <span class="nav-label" data-astro-cid-pux6a34n>‚Üê Previous</span> <span class="nav-title" data-astro-cid-pux6a34n>Training vs Inference - Two Different Worlds</span> </a> <a href="/eng-ai/part7/34-hallucinations-bias-brittleness" class="nav-next" data-astro-cid-pux6a34n> <span class="nav-label" data-astro-cid-pux6a34n>Next ‚Üí</span> <span class="nav-title" data-astro-cid-pux6a34n>Hallucinations, Bias, and Brittleness</span> </a> </nav>  </main> <aside class="chapter-toc"> <nav class="toc" data-astro-cid-xvrfupwn><h4 data-astro-cid-xvrfupwn>On This Page</h4><ul data-astro-cid-xvrfupwn><li class="toc-level-2" data-astro-cid-xvrfupwn><a href="#train-vs-test-why-validation-matters-ch33" data-astro-cid-xvrfupwn>Train vs Test: Why Validation Matters</a></li><li class="toc-level-2" data-astro-cid-xvrfupwn><a href="#accuracy-is-not-enough-cost-sensitive-errors-ch33" data-astro-cid-xvrfupwn>Accuracy Is Not Enough: Cost-Sensitive Errors</a></li><li class="toc-level-2" data-astro-cid-xvrfupwn><a href="#distribution-shift-when-metrics-become-meaningless-ch33" data-astro-cid-xvrfupwn>Distribution Shift: When Metrics Become Meaningless</a></li><li class="toc-level-2" data-astro-cid-xvrfupwn><a href="#human-evaluation-why-humans-stay-in-the-loop-ch33" data-astro-cid-xvrfupwn>Human Evaluation: Why Humans Stay in the Loop</a></li><li class="toc-level-2" data-astro-cid-xvrfupwn><a href="#hidden-failure-modes-rare-but-deadly-errors-ch33" data-astro-cid-xvrfupwn>Hidden Failure Modes: Rare but Deadly Errors</a></li><li class="toc-level-2" data-astro-cid-xvrfupwn><a href="#benchmarks-are-proxies-not-goals-ch33" data-astro-cid-xvrfupwn>Benchmarks Are Proxies, Not Goals</a></li><li class="toc-level-2" data-astro-cid-xvrfupwn><a href="#engineering-takeaway-ch33" data-astro-cid-xvrfupwn>Engineering Takeaway</a></li><li class="toc-level-2" data-astro-cid-xvrfupwn><a href="#references-and-further-reading-ch33" data-astro-cid-xvrfupwn>References and Further Reading</a></li></ul></nav> </aside> </div>   </body> </html>