<!DOCTYPE html><html lang="en"> <head><meta charset="UTF-8"><meta name="viewport" content="width=device-width, initial-scale=1.0"><title>Chapter 15: Representation Learning | Engineering Intelligence</title><meta name="description" content="A book for engineers who want to understand Machine Learning and AI from first principles"><!-- Canonical URL --><link rel="canonical" href="https://olivernguyen.io/eng-ai/part3/15-representation-learning/"><!-- Open Graph / Facebook --><meta property="og:type" content="website"><meta property="og:url" content="https://olivernguyen.io/eng-ai/part3/15-representation-learning/"><meta property="og:title" content="Chapter 15: Representation Learning | Engineering Intelligence"><meta property="og:description" content="A book for engineers who want to understand Machine Learning and AI from first principles"><meta property="og:image" content="https://olivernguyen.io/eng-ai/og-image.png"><meta property="og:site_name" content="Engineering Intelligence"><!-- Twitter --><meta name="twitter:card" content="summary_large_image"><meta name="twitter:url" content="https://olivernguyen.io/eng-ai/part3/15-representation-learning/"><meta name="twitter:title" content="Chapter 15: Representation Learning | Engineering Intelligence"><meta name="twitter:description" content="A book for engineers who want to understand Machine Learning and AI from first principles"><meta name="twitter:image" content="https://olivernguyen.io/eng-ai/og-image.png"><!-- Additional Meta --><meta name="author" content="Oliver Nguyen"><meta name="theme-color" content="#2563eb"><!-- Favicon (SVG preferred, PNG fallback) --><link rel="icon" type="image/svg+xml" href="/eng-ai/favicon.svg"><link rel="icon" type="image/png" sizes="32x32" href="/eng-ai/favicon-32x32.png"><link rel="icon" type="image/png" sizes="16x16" href="/eng-ai/favicon-16x16.png"><link rel="apple-touch-icon" sizes="180x180" href="/eng-ai/apple-touch-icon.png"><!-- KaTeX CSS for math rendering --><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css"><!-- Site styles --><link rel="stylesheet" href="/eng-ai/styles/global.css"><link rel="stylesheet" href="/eng-ai/styles/typography.css"><link rel="stylesheet" href="/eng-ai/styles/themes.css"><link rel="stylesheet" href="/eng-ai/styles/print.css"><style>.breadcrumbs[data-astro-cid-ilhxcym7]{margin-bottom:2rem}.breadcrumbs[data-astro-cid-ilhxcym7] ol[data-astro-cid-ilhxcym7]{display:flex;flex-wrap:wrap;gap:.5rem;list-style:none;padding:0;font-size:.9rem}.breadcrumbs[data-astro-cid-ilhxcym7] li[data-astro-cid-ilhxcym7]{display:flex;align-items:center;gap:.5rem}.breadcrumbs[data-astro-cid-ilhxcym7] li[data-astro-cid-ilhxcym7]:not(:last-child):after{content:"‚Ä∫";color:var(--text-muted)}.breadcrumbs[data-astro-cid-ilhxcym7] a[data-astro-cid-ilhxcym7]{color:var(--accent);text-decoration:none}.breadcrumbs[data-astro-cid-ilhxcym7] a[data-astro-cid-ilhxcym7]:hover{text-decoration:underline}.breadcrumbs[data-astro-cid-ilhxcym7] li[data-astro-cid-ilhxcym7][aria-current=page]{color:var(--text-muted)}.toc[data-astro-cid-xvrfupwn]{position:sticky;top:2rem;padding:1rem}.toc[data-astro-cid-xvrfupwn] h4[data-astro-cid-xvrfupwn]{font-size:.9rem;font-weight:600;text-transform:uppercase;letter-spacing:.05em;color:var(--text-muted);margin-bottom:.75rem}.toc[data-astro-cid-xvrfupwn] ul[data-astro-cid-xvrfupwn]{list-style:none;padding:0}.toc[data-astro-cid-xvrfupwn] li[data-astro-cid-xvrfupwn]{margin:.5rem 0}.toc[data-astro-cid-xvrfupwn] a[data-astro-cid-xvrfupwn]{font-size:.85rem;color:var(--text-muted);text-decoration:none;transition:color .2s}.toc[data-astro-cid-xvrfupwn] a[data-astro-cid-xvrfupwn]:hover{color:var(--accent)}.toc-level-2[data-astro-cid-xvrfupwn]{padding-left:0}.toc-level-3[data-astro-cid-xvrfupwn]{padding-left:1rem;font-size:.8rem}.chapter-navigation[data-astro-cid-pux6a34n]{display:flex;justify-content:space-between;gap:2rem;margin:4rem 0 2rem;padding-top:2rem;border-top:1px solid var(--border)}.nav-prev[data-astro-cid-pux6a34n],.nav-next[data-astro-cid-pux6a34n]{display:flex;flex-direction:column;gap:.5rem;padding:1rem;border:1px solid var(--border);border-radius:8px;text-decoration:none;transition:border-color .2s,background .2s;flex:1;max-width:45%}.nav-prev[data-astro-cid-pux6a34n]:hover,.nav-next[data-astro-cid-pux6a34n]:hover{border-color:var(--accent);background:var(--hover-bg)}.nav-prev[data-astro-cid-pux6a34n].placeholder{visibility:hidden}.nav-next[data-astro-cid-pux6a34n]{align-items:flex-end;text-align:right}.nav-label[data-astro-cid-pux6a34n]{font-size:.85rem;font-weight:600;text-transform:uppercase;letter-spacing:.05em;color:var(--accent)}.nav-title[data-astro-cid-pux6a34n]{font-size:1rem;color:var(--text)}
</style>
<link rel="stylesheet" href="/eng-ai/_astro/_chapter_.BUailOsj.css"><script type="module" src="/eng-ai/_astro/hoisted.0uyw1jl9.js"></script></head> <body>  <div class="book-layout"> <button id="mobile-menu-toggle" class="hamburger-button" aria-label="Toggle navigation menu" aria-expanded="false" data-astro-cid-odmlyywb> <span class="hamburger-line" data-astro-cid-odmlyywb></span> <span class="hamburger-line" data-astro-cid-odmlyywb></span> <span class="hamburger-line" data-astro-cid-odmlyywb></span> </button>  <div class="sidebar-overlay" id="sidebar-overlay" data-astro-cid-ssfzsv2f></div> <aside class="sidebar" id="sidebar" data-astro-cid-ssfzsv2f> <!-- Sidebar Controls --> <div class="sidebar-controls" data-astro-cid-ssfzsv2f> <button id="sidebar-close" class="sidebar-close-button" aria-label="Close menu" data-astro-cid-ssfzsv2f> <svg width="20" height="20" viewBox="0 0 20 20" fill="none" data-astro-cid-ssfzsv2f> <line x1="4" y1="4" x2="16" y2="16" stroke="currentColor" stroke-width="2" stroke-linecap="round" data-astro-cid-ssfzsv2f></line> <line x1="16" y1="4" x2="4" y2="16" stroke="currentColor" stroke-width="2" stroke-linecap="round" data-astro-cid-ssfzsv2f></line> </svg> </button> <button id="theme-toggle" class="theme-toggle-button" aria-label="Toggle dark mode" data-astro-cid-ssfzsv2f> <svg class="sun-icon" width="20" height="20" viewBox="0 0 20 20" data-astro-cid-ssfzsv2f> <circle cx="10" cy="10" r="4" fill="currentColor" data-astro-cid-ssfzsv2f></circle> <line x1="10" y1="1" x2="10" y2="3" stroke="currentColor" stroke-width="2" stroke-linecap="round" data-astro-cid-ssfzsv2f></line> <line x1="10" y1="17" x2="10" y2="19" stroke="currentColor" stroke-width="2" stroke-linecap="round" data-astro-cid-ssfzsv2f></line> <line x1="1" y1="10" x2="3" y2="10" stroke="currentColor" stroke-width="2" stroke-linecap="round" data-astro-cid-ssfzsv2f></line> <line x1="17" y1="10" x2="19" y2="10" stroke="currentColor" stroke-width="2" stroke-linecap="round" data-astro-cid-ssfzsv2f></line> <line x1="3.5" y1="3.5" x2="5" y2="5" stroke="currentColor" stroke-width="2" stroke-linecap="round" data-astro-cid-ssfzsv2f></line> <line x1="15" y1="15" x2="16.5" y2="16.5" stroke="currentColor" stroke-width="2" stroke-linecap="round" data-astro-cid-ssfzsv2f></line> <line x1="16.5" y1="3.5" x2="15" y2="5" stroke="currentColor" stroke-width="2" stroke-linecap="round" data-astro-cid-ssfzsv2f></line> <line x1="5" y1="15" x2="3.5" y2="16.5" stroke="currentColor" stroke-width="2" stroke-linecap="round" data-astro-cid-ssfzsv2f></line> </svg> <svg class="moon-icon" width="20" height="20" viewBox="0 0 20 20" data-astro-cid-ssfzsv2f> <path d="M10 2a8 8 0 108 8 6 6 0 01-8-8z" fill="currentColor" data-astro-cid-ssfzsv2f></path> </svg> </button> </div> <div class="sidebar-header" data-astro-cid-ssfzsv2f> <a href="/eng-ai/" data-astro-cid-ssfzsv2f> <h2 data-astro-cid-ssfzsv2f>Engineering Intelligence</h2> </a> </div> <nav class="sidebar-nav" data-astro-cid-ssfzsv2f> <section class="intro-section" data-astro-cid-ssfzsv2f> <ul data-astro-cid-ssfzsv2f> <li class="" data-astro-cid-ssfzsv2f> <a href="/eng-ai/introduction" <span class="intro-icon" data-astro-cid-ssfzsv2f>üìñ
              Introduction
</a> </li> </ul> </section> <section class="part-section" data-astro-cid-ssfzsv2f> <h3 class="" data-astro-cid-ssfzsv2f> <a href="/eng-ai/part1" data-astro-cid-ssfzsv2f>
Part I: Foundations </a> </h3> <ul data-astro-cid-ssfzsv2f> <li class="" data-astro-cid-ssfzsv2f> <a href="/eng-ai/part1/01-why-intelligence-is-not-magic" data-astro-cid-ssfzsv2f> <span class="chapter-num" data-astro-cid-ssfzsv2f>1.</span> Why Intelligence Is Not Magic </a> </li><li class="" data-astro-cid-ssfzsv2f> <a href="/eng-ai/part1/02-data-is-the-new-physics" data-astro-cid-ssfzsv2f> <span class="chapter-num" data-astro-cid-ssfzsv2f>2.</span> Data Is the New Physics </a> </li><li class="" data-astro-cid-ssfzsv2f> <a href="/eng-ai/part1/03-models-are-compression-machines" data-astro-cid-ssfzsv2f> <span class="chapter-num" data-astro-cid-ssfzsv2f>3.</span> Models Are Compression Machines </a> </li><li class="" data-astro-cid-ssfzsv2f> <a href="/eng-ai/part1/04-bias-variance-tradeoff" data-astro-cid-ssfzsv2f> <span class="chapter-num" data-astro-cid-ssfzsv2f>4.</span> The Bias-Variance Tradeoff </a> </li><li class="" data-astro-cid-ssfzsv2f> <a href="/eng-ai/part1/05-features-how-machines-see-the-world" data-astro-cid-ssfzsv2f> <span class="chapter-num" data-astro-cid-ssfzsv2f>5.</span> Features: How Machines See the World </a> </li> </ul> </section><section class="part-section" data-astro-cid-ssfzsv2f> <h3 class="" data-astro-cid-ssfzsv2f> <a href="/eng-ai/part2" data-astro-cid-ssfzsv2f>
Part II: Classical ML </a> </h3> <ul data-astro-cid-ssfzsv2f> <li class="" data-astro-cid-ssfzsv2f> <a href="/eng-ai/part2/06-linear-models" data-astro-cid-ssfzsv2f> <span class="chapter-num" data-astro-cid-ssfzsv2f>6.</span> Linear Models </a> </li><li class="" data-astro-cid-ssfzsv2f> <a href="/eng-ai/part2/07-logistic-regression" data-astro-cid-ssfzsv2f> <span class="chapter-num" data-astro-cid-ssfzsv2f>7.</span> Logistic Regression </a> </li><li class="" data-astro-cid-ssfzsv2f> <a href="/eng-ai/part2/08-decision-trees" data-astro-cid-ssfzsv2f> <span class="chapter-num" data-astro-cid-ssfzsv2f>8.</span> Decision Trees </a> </li><li class="" data-astro-cid-ssfzsv2f> <a href="/eng-ai/part2/09-ensembles" data-astro-cid-ssfzsv2f> <span class="chapter-num" data-astro-cid-ssfzsv2f>9.</span> Ensembles </a> </li><li class="" data-astro-cid-ssfzsv2f> <a href="/eng-ai/part2/10-loss-functions" data-astro-cid-ssfzsv2f> <span class="chapter-num" data-astro-cid-ssfzsv2f>10.</span> Loss Functions and Optimization </a> </li> </ul> </section><section class="part-section" data-astro-cid-ssfzsv2f> <h3 class="" data-astro-cid-ssfzsv2f> <a href="/eng-ai/part3" data-astro-cid-ssfzsv2f>
Part III: Neural Networks </a> </h3> <ul data-astro-cid-ssfzsv2f> <li class="" data-astro-cid-ssfzsv2f> <a href="/eng-ai/part3/11-neurons-as-math" data-astro-cid-ssfzsv2f> <span class="chapter-num" data-astro-cid-ssfzsv2f>11.</span> Neurons as Math </a> </li><li class="" data-astro-cid-ssfzsv2f> <a href="/eng-ai/part3/12-forward-pass" data-astro-cid-ssfzsv2f> <span class="chapter-num" data-astro-cid-ssfzsv2f>12.</span> The Forward Pass </a> </li><li class="" data-astro-cid-ssfzsv2f> <a href="/eng-ai/part3/13-backpropagation" data-astro-cid-ssfzsv2f> <span class="chapter-num" data-astro-cid-ssfzsv2f>13.</span> Backpropagation </a> </li><li class="" data-astro-cid-ssfzsv2f> <a href="/eng-ai/part3/14-optimization-deep-learning" data-astro-cid-ssfzsv2f> <span class="chapter-num" data-astro-cid-ssfzsv2f>14.</span> Optimization in Deep Learning </a> </li><li class="active" data-astro-cid-ssfzsv2f> <a href="/eng-ai/part3/15-representation-learning" data-astro-cid-ssfzsv2f> <span class="chapter-num" data-astro-cid-ssfzsv2f>15.</span> Representation Learning </a> </li> </ul> </section><section class="part-section" data-astro-cid-ssfzsv2f> <h3 class="" data-astro-cid-ssfzsv2f> <a href="/eng-ai/part4" data-astro-cid-ssfzsv2f>
Part IV: Deep Architectures </a> </h3> <ul data-astro-cid-ssfzsv2f> <li class="" data-astro-cid-ssfzsv2f> <a href="/eng-ai/part4/16-convolutional-neural-networks" data-astro-cid-ssfzsv2f> <span class="chapter-num" data-astro-cid-ssfzsv2f>16.</span> Convolutional Neural Networks </a> </li><li class="" data-astro-cid-ssfzsv2f> <a href="/eng-ai/part4/17-recurrent-neural-networks" data-astro-cid-ssfzsv2f> <span class="chapter-num" data-astro-cid-ssfzsv2f>17.</span> Recurrent Neural Networks </a> </li><li class="" data-astro-cid-ssfzsv2f> <a href="/eng-ai/part4/18-embeddings" data-astro-cid-ssfzsv2f> <span class="chapter-num" data-astro-cid-ssfzsv2f>18.</span> Embeddings </a> </li><li class="" data-astro-cid-ssfzsv2f> <a href="/eng-ai/part4/19-attention" data-astro-cid-ssfzsv2f> <span class="chapter-num" data-astro-cid-ssfzsv2f>19.</span> Attention </a> </li><li class="" data-astro-cid-ssfzsv2f> <a href="/eng-ai/part4/20-transformers" data-astro-cid-ssfzsv2f> <span class="chapter-num" data-astro-cid-ssfzsv2f>20.</span> Transformers </a> </li> </ul> </section><section class="part-section" data-astro-cid-ssfzsv2f> <h3 class="" data-astro-cid-ssfzsv2f> <a href="/eng-ai/part5" data-astro-cid-ssfzsv2f>
Part V: Language Models </a> </h3> <ul data-astro-cid-ssfzsv2f> <li class="" data-astro-cid-ssfzsv2f> <a href="/eng-ai/part5/21-next-token-prediction" data-astro-cid-ssfzsv2f> <span class="chapter-num" data-astro-cid-ssfzsv2f>21.</span> Next-Token Prediction </a> </li><li class="" data-astro-cid-ssfzsv2f> <a href="/eng-ai/part5/22-pretraining" data-astro-cid-ssfzsv2f> <span class="chapter-num" data-astro-cid-ssfzsv2f>22.</span> Pretraining </a> </li><li class="" data-astro-cid-ssfzsv2f> <a href="/eng-ai/part5/23-fine-tuning" data-astro-cid-ssfzsv2f> <span class="chapter-num" data-astro-cid-ssfzsv2f>23.</span> Fine-Tuning </a> </li><li class="" data-astro-cid-ssfzsv2f> <a href="/eng-ai/part5/24-rlhf" data-astro-cid-ssfzsv2f> <span class="chapter-num" data-astro-cid-ssfzsv2f>24.</span> RLHF </a> </li><li class="" data-astro-cid-ssfzsv2f> <a href="/eng-ai/part5/25-emergent-abilities-and-scaling" data-astro-cid-ssfzsv2f> <span class="chapter-num" data-astro-cid-ssfzsv2f>25.</span> Emergent Abilities and Scaling </a> </li> </ul> </section><section class="part-section" data-astro-cid-ssfzsv2f> <h3 class="" data-astro-cid-ssfzsv2f> <a href="/eng-ai/part6" data-astro-cid-ssfzsv2f>
Part VI: Modern AI Systems </a> </h3> <ul data-astro-cid-ssfzsv2f> <li class="" data-astro-cid-ssfzsv2f> <a href="/eng-ai/part6/26-prompting-as-programming" data-astro-cid-ssfzsv2f> <span class="chapter-num" data-astro-cid-ssfzsv2f>26.</span> Prompting as Programming </a> </li><li class="" data-astro-cid-ssfzsv2f> <a href="/eng-ai/part6/27-retrieval-augmented-generation" data-astro-cid-ssfzsv2f> <span class="chapter-num" data-astro-cid-ssfzsv2f>27.</span> Retrieval-Augmented Generation </a> </li><li class="" data-astro-cid-ssfzsv2f> <a href="/eng-ai/part6/28-tools-and-function-calling" data-astro-cid-ssfzsv2f> <span class="chapter-num" data-astro-cid-ssfzsv2f>28.</span> Tools and Function Calling </a> </li><li class="" data-astro-cid-ssfzsv2f> <a href="/eng-ai/part6/29-agents" data-astro-cid-ssfzsv2f> <span class="chapter-num" data-astro-cid-ssfzsv2f>29.</span> Agents - Models That Decide What to Do </a> </li><li class="" data-astro-cid-ssfzsv2f> <a href="/eng-ai/part6/30-memory-and-planning" data-astro-cid-ssfzsv2f> <span class="chapter-num" data-astro-cid-ssfzsv2f>30.</span> Memory, Planning, and Long-Term Behavior </a> </li> </ul> </section><section class="part-section" data-astro-cid-ssfzsv2f> <h3 class="" data-astro-cid-ssfzsv2f> <a href="/eng-ai/part7" data-astro-cid-ssfzsv2f>
Part VII: Engineering Reality </a> </h3> <ul data-astro-cid-ssfzsv2f> <li class="" data-astro-cid-ssfzsv2f> <a href="/eng-ai/part7/31-data-pipelines" data-astro-cid-ssfzsv2f> <span class="chapter-num" data-astro-cid-ssfzsv2f>31.</span> Data Pipelines - Where Models Are Born and Die </a> </li><li class="" data-astro-cid-ssfzsv2f> <a href="/eng-ai/part7/32-training-vs-inference" data-astro-cid-ssfzsv2f> <span class="chapter-num" data-astro-cid-ssfzsv2f>32.</span> Training vs Inference - Two Different Worlds </a> </li><li class="" data-astro-cid-ssfzsv2f> <a href="/eng-ai/part7/33-evaluation" data-astro-cid-ssfzsv2f> <span class="chapter-num" data-astro-cid-ssfzsv2f>33.</span> Evaluation - Why Accuracy Is Not Enough </a> </li><li class="" data-astro-cid-ssfzsv2f> <a href="/eng-ai/part7/34-hallucinations-bias-brittleness" data-astro-cid-ssfzsv2f> <span class="chapter-num" data-astro-cid-ssfzsv2f>34.</span> Hallucinations, Bias, and Brittleness </a> </li><li class="" data-astro-cid-ssfzsv2f> <a href="/eng-ai/part7/35-safety-alignment-control" data-astro-cid-ssfzsv2f> <span class="chapter-num" data-astro-cid-ssfzsv2f>35.</span> Safety, Alignment, and Control </a> </li> </ul> </section><section class="part-section" data-astro-cid-ssfzsv2f> <h3 class="" data-astro-cid-ssfzsv2f> <a href="/eng-ai/part8" data-astro-cid-ssfzsv2f>
Part VIII: The Frontier </a> </h3> <ul data-astro-cid-ssfzsv2f> <li class="" data-astro-cid-ssfzsv2f> <a href="/eng-ai/part8/36-scaling-laws" data-astro-cid-ssfzsv2f> <span class="chapter-num" data-astro-cid-ssfzsv2f>36.</span> Scaling Laws - Why Bigger Keeps Winning </a> </li><li class="" data-astro-cid-ssfzsv2f> <a href="/eng-ai/part8/37-multimodal-models" data-astro-cid-ssfzsv2f> <span class="chapter-num" data-astro-cid-ssfzsv2f>37.</span> Multimodal Models </a> </li><li class="" data-astro-cid-ssfzsv2f> <a href="/eng-ai/part8/38-self-improving-systems" data-astro-cid-ssfzsv2f> <span class="chapter-num" data-astro-cid-ssfzsv2f>38.</span> Self-Improving Systems </a> </li><li class="" data-astro-cid-ssfzsv2f> <a href="/eng-ai/part8/39-artificial-general-intelligence" data-astro-cid-ssfzsv2f> <span class="chapter-num" data-astro-cid-ssfzsv2f>39.</span> Artificial General Intelligence </a> </li><li class="" data-astro-cid-ssfzsv2f> <a href="/eng-ai/part8/40-the-engineers-role" data-astro-cid-ssfzsv2f> <span class="chapter-num" data-astro-cid-ssfzsv2f>40.</span> The Engineer&#39;s Role </a> </li> </ul> </section> </nav> </aside>   <main class="chapter-content"> <nav class="breadcrumbs" aria-label="Breadcrumb" data-astro-cid-ilhxcym7> <ol data-astro-cid-ilhxcym7> <li data-astro-cid-ilhxcym7><a href="/eng-ai/" data-astro-cid-ilhxcym7>Home</a></li> <li data-astro-cid-ilhxcym7><a href="/eng-ai/part3" data-astro-cid-ilhxcym7>Part III: Neural Networks</a></li> <li aria-current="page" data-astro-cid-ilhxcym7>Representation Learning</li> </ol> </nav>  <article class="chapter"> <h1 id="chapter-15-representation-learning">Chapter 15: Representation Learning</h1>
<h2 id="from-pixels-to-meaning-ch15">From Pixels to Meaning</h2>
<p>A raw image is a grid of numbers representing pixel intensities. These numbers, taken literally, contain no semantic meaning. Pixel (142, 87) being red tells you nothing about whether the image contains a dog, a cat, or a car. Yet humans instantly recognize objects. How?</p>
<p>The human visual system doesn‚Äôt process pixels. It extracts features hierarchically: edges, then shapes, then parts, then objects. By the time visual information reaches higher brain areas, it‚Äôs represented as concepts (‚Äúdog,‚Äù ‚Äúrunning,‚Äù ‚Äúoutdoors‚Äù) rather than photoreceptor activations. The brain learned these representations through experience.</p>
<p>Neural networks do the same thing automatically. Early layers learn low-level features (edges, colors, textures). Middle layers combine these into mid-level features (corners, patterns, parts). Late layers combine those into high-level features (objects, scenes, categories). By the final layer, the network has transformed pixels into a representation where the task‚Äîclassification, detection, segmentation‚Äîis easy.</p>
<p>This is representation learning: automatically discovering features that make subsequent prediction simple. It‚Äôs why deep learning succeeded where classical machine learning struggled on perceptual tasks. Hand-engineering features for images, speech, or text is extraordinarily hard. Learning them automatically is what neural networks do best.</p>
<h2 id="distributed-representations-why-neurons-dont-map-1-to-1-ch15">Distributed Representations: Why Neurons Don‚Äôt Map 1-to-1</h2>
<p>In classical feature engineering, each feature represents a specific, interpretable property: ‚Äúcontains the word ‚Äòdog‚Äô,‚Äù ‚Äúhas vertical edges,‚Äù ‚Äúred color histogram peak.‚Äù Each feature is independent and interpretable.</p>
<p>Neural networks don‚Äôt work this way. Features in deep networks are distributed: each neuron participates in representing many concepts, and each concept is represented by many neurons. A single neuron in a late layer doesn‚Äôt encode ‚Äúdog‚Äù‚Äîit responds to some combination of shapes, textures, and patterns that happen to correlate with dogs (and other things).</p>
<p>This distributed encoding is more efficient. Suppose you want to represent 1,000 concepts. With one-hot encoding (one neuron per concept), you need 1,000 neurons. With distributed representations, you might only need 100 neurons, where each concept is encoded as a pattern of activations across those neurons. A binary pattern of length 100 can represent <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mn>2</mn><mn>100</mn></msup><mo>‚âà</mo><msup><mn>10</mn><mn>30</mn></msup></mrow><annotation encoding="application/x-tex">2^{100} \approx 10^{30}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8141em;"></span><span class="mord"><span class="mord">2</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">100</span></span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">‚âà</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.8141em;"></span><span class="mord">1</span><span class="mord"><span class="mord">0</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">30</span></span></span></span></span></span></span></span></span></span></span></span> distinct concepts‚Äîexponentially more than one-hot encoding.</p>
<p>This exponential efficiency comes from composition. Features are reusable. A ‚Äúpointy ear‚Äù feature is useful for cats, dogs, foxes, and rabbits. A ‚Äúvertical line‚Äù feature is useful for buildings, trees, and text. By combining reusable features, the network can represent a vast number of concepts without needing a neuron for each one.</p>
<p>The cost is interpretability. You cannot point to a single neuron and say ‚Äúthis detects dogs.‚Äù Instead, ‚Äúdog‚Äù is encoded as a distributed pattern across many neurons. This makes neural networks harder to understand but far more powerful.</p>
<h2 id="emergence-how-concepts-appear-ch15">Emergence: How Concepts Appear</h2>
<p>Deep networks don‚Äôt start with meaningful representations. Initially, weights are random, and activations are noise. But through training‚Äîadjusting weights to minimize loss‚Äîthe network organizes its internal representations to support the task.</p>
<p>As training progresses, structure emerges:</p>
<ul>
<li><strong>Early layers</strong> develop general low-level features (edges, blobs) useful across many tasks</li>
<li><strong>Middle layers</strong> develop task-specific mid-level features (textures, patterns, parts)</li>
<li><strong>Late layers</strong> develop task-specific high-level features (objects, categories, concepts)</li>
</ul>
<p>This emergence is not programmed. The network is only told to minimize classification loss. The intermediate representations‚Äîwhat features to learn at each layer‚Äîare discovered automatically. The hierarchy emerges because it‚Äôs an efficient way to compress the mapping from inputs to outputs.</p>
<p>Why does hierarchy emerge? Because deep networks can represent hierarchical functions more efficiently than shallow ones. A function that combines low-level patterns into high-level concepts can be represented with <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>O</mi><mo stretchy="false">(</mo><mi>n</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">O(n)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">O</span><span class="mopen">(</span><span class="mord mathnormal">n</span><span class="mclose">)</span></span></span></span> parameters in a deep network but might require <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>O</mi><mo stretchy="false">(</mo><msup><mn>2</mn><mi>n</mi></msup><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">O(2^n)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">O</span><span class="mopen">(</span><span class="mord"><span class="mord">2</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.6644em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">n</span></span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span> parameters in a shallow network. The exponential efficiency of depth encourages hierarchical organization.</p>
<p>This is why deep learning works: not because we told the network to learn hierarchical features, but because the optimization process discovers that hierarchical representations are efficient. The structure of the solution is shaped by the architecture, the data, and the task.</p>
<p><img  src="/eng-ai/_astro/15-diagram.DSobxtrS_2gwOoN.svg" alt="Emergence: How Concepts Appear diagram" width="500" height="320" loading="lazy" decoding="async"></p>
<p>The diagram shows how structure emerges during training. Before training, activations are random. After training, the network has organized into meaningful features at each layer, discovered automatically by gradient descent.</p>
<h2 id="why-emergence-happens-the-implicit-bias-of-sgd-ch15">Why Emergence Happens: The Implicit Bias of SGD</h2>
<p>Emergence isn‚Äôt magic. It happens because stochastic gradient descent has an implicit bias toward simple solutions‚Äîa form of Occam‚Äôs razor built into the optimization algorithm.</p>
<p>When there are multiple functions that fit the training data equally well (and in overparameterized networks, there are many such functions), SGD preferentially finds the ‚Äúsimplest‚Äù one. Simple here means something precise: the function with the smallest norm in parameter space, or equivalently, the function that compresses the data most efficiently.</p>
<p>Why does SGD prefer simple solutions? Because gradient descent follows the shortest path in weight space from the initialization to a solution. Starting from small random weights (near zero), gradient descent takes small steps, and the first solution it finds is the one that requires the smallest weight changes. This naturally favors low-complexity solutions‚Äîfunctions that can be expressed with small weights.</p>
<p>This is regularization through optimization. Even without explicit regularization (weight decay, dropout), SGD implicitly regularizes by preferring simple functions. This implicit bias prevents overfitting: among all the functions that perfectly fit training data, the network learns the one that generalizes.</p>
<p>The hierarchical structure that emerges is the simplest way to compress the mapping from inputs to outputs. Instead of memorizing every input-output pair, the network discovers reusable patterns. ‚ÄúFur‚Äù is learned once and reused for cats, dogs, foxes. ‚ÄúVertical edge‚Äù is learned once and reused for buildings, trees, letters. This compositional reuse is the compressed representation.</p>
<p>This connects back to the compression view of learning (Chapter 3). Networks that generalize well are those that compress training data into simple, reusable representations. The features that emerge during training are the compression: they‚Äôre the minimal description length of the patterns in the data. SGD‚Äôs implicit bias toward simplicity is why neural networks discover hierarchical features rather than memorizing examples.</p>
<p><strong>Mathematical intuition:</strong> Gradient noise from mini-batch sampling acts as a regularizer. When gradients are noisy, optimization can only follow the strong, consistent signals‚Äîthe generalizable patterns‚Äîbecause noise washes out the weak, idiosyncratic patterns. This is why very large batch sizes (low noise) sometimes hurt generalization: the noise has a beneficial effect by preventing memorization.</p>
<h2 id="what-do-layers-learn-concrete-examples-ch15">What Do Layers Learn? Concrete Examples</h2>
<p>The hierarchy isn‚Äôt abstract‚Äîyou can visualize it. Examining what neurons respond to at different depths reveals the progression from pixels to meaning.</p>
<p><strong>Vision Networks (ResNet, VGG, AlexNet):</strong></p>
<ul>
<li><strong>Layer 1</strong>: Simple features‚Äîedges at various orientations, color blobs, frequency gradients. These are universal: every image has edges, and every vision network learns similar Layer 1 features regardless of the task.</li>
<li><strong>Layers 2-3</strong>: Intermediate features‚Äîcorners, curves, simple patterns, texture repetitions (stripes, grids, dots). These combine edges into slightly more complex structures.</li>
<li><strong>Layers 4-5</strong>: Object parts‚Äîwheels, eyes, fur, windows, faces, legs. These are recognizable components that appear in multiple object categories.</li>
<li><strong>Final layers</strong>: Full objects and scenes‚Äîdogs, cars, buildings, outdoor scenes. By the final layer, the network has transformed pixels into semantic categories.</li>
</ul>
<p><strong>Language Models (BERT, GPT, Transformers):</strong></p>
<ul>
<li><strong>Early layers</strong>: Syntax and grammar‚Äîpart-of-speech tagging, syntactic dependencies, phrase structure. Early layers parse the structure of language.</li>
<li><strong>Middle layers</strong>: Semantics‚Äîword meanings, coreference resolution (what ‚Äúit‚Äù refers to), entity relationships. Middle layers understand what the text is about.</li>
<li><strong>Late layers</strong>: Task-specific features‚Äîsentiment (positive/negative), named entities (person, organization, location), question-answering patterns. Late layers adapt to the specific prediction task.</li>
</ul>
<p><strong>How We Know This:</strong></p>
<ul>
<li><strong>Activation maximization</strong>: Find inputs that maximize a neuron‚Äôs activation. For a Layer 1 neuron, you get simple edges. For a Layer 5 neuron, you get complex object parts.</li>
<li><strong>Saliency maps</strong>: Compute gradient of output with respect to input. Shows which pixels most influence the prediction. Early layers have diffuse saliency; late layers focus on semantically meaningful regions.</li>
<li><strong>GradCAM</strong>: Weighted combination of activations at a layer, visualized as a heatmap. Shows where the network is ‚Äúlooking‚Äù at different depths. Early layers attend everywhere; late layers attend to objects.</li>
<li><strong>Linear probing</strong>: Freeze all layers except the final layer, train a linear classifier on the frozen representations. If linear probe accuracy is high, the representation is linearly separable‚Äîa sign of good features.</li>
</ul>
<p>These techniques aren‚Äôt just research tools. In production, you can use them to debug why a network makes certain predictions and whether it has learned the right features.</p>
<h2 id="representation-quality-how-to-measure-whats-learned-ch15">Representation Quality: How to Measure What‚Äôs Learned</h2>
<p>Not all representations are equally good. How do you measure whether your network has learned useful features?</p>
<p><strong>Linear Probing:</strong></p>
<p>Freeze the network‚Äôs weights, remove the final classification layer, and train a simple linear classifier on the frozen representations (activations from the second-to-last layer). If the linear classifier achieves high accuracy, the representation is linearly separable‚Äîthe network has done the hard work of transforming data into a space where a linear boundary works.</p>
<p>Linear probing is a diagnostic. If probe accuracy is low despite good end-to-end accuracy, the representation is poor and the final layer is doing too much work. If probe accuracy is high, the representation is good, and you can use it for transfer learning.</p>
<p><strong>Representation Similarity:</strong></p>
<p>Compare representations across different models or layers. Centered Kernel Alignment (CKA) measures how similar two sets of representations are, even if they live in different dimensional spaces. High CKA means the networks have learned similar features; low CKA means they‚Äôve learned different features.</p>
<p>This is useful for understanding when two architectures are fundamentally similar (ResNet vs VGG) vs when they‚Äôre genuinely different (CNN vs Transformer). It also helps track training dynamics: you can see when representations stabilize during training.</p>
<p><strong>Transfer Learning Performance:</strong></p>
<p>The ultimate test: fine-tune the representation on a downstream task. If the pretrained representation generalizes well to new tasks with minimal fine-tuning, it‚Äôs a good representation. If it requires extensive retraining, the representation is overfitted to the original task.</p>
<p>In production, evaluate representations on multiple downstream tasks simultaneously. A representation that works across many tasks (object detection, segmentation, classification) is more valuable than one tuned for a single task.</p>
<p><strong>Practical Tip:</strong> When training a new model, log linear probe accuracy on a validation set every few epochs. If probe accuracy plateaus while training accuracy keeps increasing, you‚Äôre overfitting. The representation has stopped improving, and the network is just memorizing through the final layer.</p>
<h2 id="domain-specific-representations-ch15">Domain-Specific Representations</h2>
<p>The structure of learned representations depends on the domain. Different modalities have different inductive biases built into their architectures.</p>
<p><strong>Vision (Images, Video):</strong> Spatial hierarchy. Nearby pixels are related, and objects have spatial coherence. Convolutional networks (CNNs) encode this bias: they detect local patterns (edges, textures) and build up to global patterns (objects, scenes). The hierarchy mirrors the spatial structure: low-level features are local, high-level features are global.</p>
<p><strong>Language (Text, Code):</strong> Sequential dependencies. Words depend on previous words, and meaning emerges from context. Recurrent networks (RNNs, LSTMs) and Transformers encode this bias: they process sequences left-to-right or attend to relevant context. The hierarchy mirrors linguistic structure: tokens ‚Üí phrases ‚Üí sentences ‚Üí documents.</p>
<p><strong>Audio (Speech, Music):</strong> Time-frequency patterns. Audio is both temporal (events over time) and spectral (frequencies present at each moment). Networks for audio (WaveNet, Conformer) combine convolutional layers (for frequency patterns) with recurrent or attention layers (for temporal dependencies). The learned features are spectrograms, phonemes, words, prosody.</p>
<p><strong>Graphs (Social Networks, Molecules):</strong> Node and edge relationships. Information flows along edges, and structure determines function. Graph neural networks (GNNs) encode this bias: they aggregate information from neighbors and propagate messages. The learned features are node embeddings that capture both local structure (immediate neighbors) and global topology (community structure, paths).</p>
<p>The key insight: architecture choice encodes assumptions about the data structure. When the architecture‚Äôs inductive bias matches the domain structure, learning is efficient and representations generalize. When they mismatch, the network must work harder to learn basic patterns, and generalization suffers.</p>
<h2 id="why-deep-beats-shallow-ch15">Why Deep Beats Shallow</h2>
<p>A shallow network (one or two hidden layers) can approximate any continuous function‚Äîthis is the universal approximation theorem. So why use deep networks?</p>
<p>Because deep networks are exponentially more efficient. A shallow network might require exponentially many neurons to approximate a function that a deep network represents with linearly many neurons. Depth enables compositional efficiency.</p>
<p>Consider a function that checks if an image contains specific combinations of patterns: ‚Äúfur AND pointy ears‚Äù or ‚Äúwheels AND windows.‚Äù A shallow network must have separate neurons for every possible combination. If there are <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi></mrow><annotation encoding="application/x-tex">n</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal">n</span></span></span></span> binary patterns, this requires <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mn>2</mn><mi>n</mi></msup></mrow><annotation encoding="application/x-tex">2^n</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6644em;"></span><span class="mord"><span class="mord">2</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.6644em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">n</span></span></span></span></span></span></span></span></span></span></span> neurons.</p>
<p>A deep network can compute the same function hierarchically:</p>
<ul>
<li>Layer 1: Detect <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi></mrow><annotation encoding="application/x-tex">n</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal">n</span></span></span></span> individual patterns (edges, textures)</li>
<li>Layer 2: Detect <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi></mrow><annotation encoding="application/x-tex">n</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal">n</span></span></span></span> combinations of layer 1 patterns (fur, ears, wheels, windows)</li>
<li>Layer 3: Detect combinations of layer 2 patterns (cat, car)</li>
</ul>
<p>This requires <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>O</mi><mo stretchy="false">(</mo><mi>n</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">O(n)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">O</span><span class="mopen">(</span><span class="mord mathnormal">n</span><span class="mclose">)</span></span></span></span> neurons per layer and a few layers‚Äîlinear in <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi></mrow><annotation encoding="application/x-tex">n</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal">n</span></span></span></span>, not exponential. The depth allows the network to reuse computations: ‚Äúfur‚Äù is computed once and used in multiple higher-level concepts.</p>
<p>This exponential advantage is why deep learning succeeded. Shallow networks need prohibitively many neurons for complex tasks. Deep networks achieve the same expressiveness with far fewer parameters, enabling better generalization and faster training.</p>
<h2 id="engineering-takeaway-ch15">Engineering Takeaway</h2>
<p>Representation learning is the core insight of deep learning. Networks automatically discover hierarchical features that make prediction easy. Understanding what representations are learned, how to measure their quality, and how to leverage pretrained representations is essential for building effective systems.</p>
<p><strong>Representations are the key to generalization.</strong> If the learned features are good, the final task is easy‚Äîeven a linear classifier achieves high accuracy. If the features are poor, no amount of tuning the final layer helps. When performance plateaus, improving representations (more data, better architecture, better pretraining) often matters more than hyperparameter tuning. Use linear probing (freeze the network, train a linear classifier on frozen features) to diagnose whether the representation is the bottleneck. If linear probe accuracy is low, improve the representation; if it‚Äôs high, tune the final layer.</p>
<p><strong>Transfer learning is standard practice, not a research trick.</strong> A network pretrained on ImageNet learns general visual features: edges, textures, object parts. You can reuse these features for different tasks (medical imaging, satellite analysis, industrial inspection) by fine-tuning the final layers or using the pretrained network as a fixed feature extractor. This works because early layers learn general features and late layers learn task-specific features. Transfer learning reduces data requirements by 10-100√ó and training time by similar factors. In production, almost no one trains vision or language models from scratch‚Äîthey start with pretrained models (ResNet, BERT, GPT, CLIP) and adapt them.</p>
<p><strong>Embeddings are the interface between models and systems.</strong> The intermediate representations‚Äîespecially from the second-to-last layer‚Äîare useful features for downstream tasks. Word embeddings (Word2Vec, GloVe, BERT) capture semantic meaning and power search, recommendation, clustering. Image embeddings (ResNet, CLIP) capture visual concepts and enable similarity search, zero-shot classification, multimodal retrieval. Embeddings are how you integrate neural networks into larger systems: extract embeddings, store them in a vector database, use them for retrieval or ranking. This is the foundation of modern search and recommendation.</p>
<p><strong>Visualization reveals what the network learned.</strong> Use activation maximization (find inputs that maximize neuron activations) to see what patterns neurons detect. Use t-SNE or UMAP on final-layer embeddings to see if the network has separated classes. Use GradCAM to see where the network is ‚Äúlooking‚Äù when making predictions. If visualizations look random or nonsensical, the network hasn‚Äôt learned meaningful features‚Äîyou have a training problem (bad data, bad architecture, bad optimization). Visualization is essential for debugging and building trust in production systems.</p>
<p><strong>Depth has diminishing returns beyond a point.</strong> Deeper networks are more expressive but harder to train, slower to run, and eventually plateau in performance. ResNet-50 is usually better than ResNet-18 but only marginally better than ResNet-34. Very deep networks (ResNet-152, ResNet-1000) show small gains and require careful engineering (skip connections, normalization, initialization) to train at all. The practical sweet spot for most vision tasks: 18-50 layers. For language: 6-24 transformer layers. Beyond that, gains are small unless you‚Äôre training on massive datasets (billions of examples).</p>
<p><strong>Architecture choice encodes inductive biases.</strong> CNNs assume spatial locality (nearby pixels are related). Transformers assume flexible attention (any token can attend to any other). RNNs assume sequential dependencies (current state depends on previous state). Graph neural networks assume relational structure (nodes connected by edges). When the architecture‚Äôs bias matches the data structure, learning is efficient and generalizes. When they mismatch, the network must work harder and generalization suffers. Choose architectures that match your domain: CNNs for images, Transformers for language, GNNs for graphs.</p>
<p><strong>Monitor representation quality during training.</strong> Log linear probe accuracy on a validation set every few epochs. If probe accuracy plateaus while training accuracy increases, you‚Äôre overfitting‚Äîthe representation has stopped improving, and the network is memorizing through the final layer. If probe accuracy and training accuracy both increase, the representation is still learning. Use representation similarity metrics (CKA) to track when different layers stabilize. In production, continuously evaluate whether representations remain useful on downstream tasks‚Äîdistribution shift can degrade representation quality even if training metrics look fine.</p>
<p>The lesson: Deep learning works because networks learn hierarchical representations automatically. Early layers learn general features, late layers learn task-specific features. This eliminates the bottleneck of feature engineering and enables end-to-end learning from raw data. Understanding representation learning‚Äîwhat features emerge at each layer, how to measure representation quality, how to leverage pretrained representations‚Äîis the key to using deep learning effectively in production.</p>
<hr>
<h2 id="references-and-further-reading-ch15">References and Further Reading</h2>
<p><strong>Representation Learning: A Review and New Perspectives</strong> ‚Äì Yoshua Bengio, Aaron Courville, Pascal Vincent (2013)
<a href="https://arxiv.org/abs/1206.5538">https://arxiv.org/abs/1206.5538</a></p>
<p>This paper surveys representation learning and explains why it‚Äôs the key to deep learning‚Äôs success. Bengio explains distributed representations, hierarchical features, and why deep networks learn better representations than shallow ones. Reading this gives you the theoretical foundation for understanding what makes deep learning powerful.</p>
<p><strong>Visualizing and Understanding Convolutional Networks</strong> ‚Äì Matthew Zeiler and Rob Fergus (2013)
<a href="https://arxiv.org/abs/1311.2901">https://arxiv.org/abs/1311.2901</a></p>
<p>Zeiler and Fergus visualize what CNNs learn at each layer, showing that early layers detect edges, middle layers detect textures and patterns, and late layers detect object parts. The visualizations make abstract concepts concrete: you can see the hierarchical features emerge. Reading this (and examining the figures) will give you intuition for what ‚Äúrepresentation learning‚Äù actually looks like.</p>
<p><strong>How Transferable Are Features in Deep Neural Networks?</strong> ‚Äì Jason Yosinski et al. (2014)
<a href="https://arxiv.org/abs/1411.1792">https://arxiv.org/abs/1411.1792</a></p>
<p>This paper shows that features learned on one task transfer to others. Yosinski demonstrates that early layers learn general features and late layers learn task-specific features, and quantifies how much performance degrades when transferring between tasks. Reading this explains why transfer learning works and when it‚Äôs most effective.</p> </article> <nav class="chapter-navigation" data-astro-cid-pux6a34n> <a href="/eng-ai/part3/14-optimization-deep-learning" class="nav-prev " data-astro-cid-pux6a34n> <span class="nav-label" data-astro-cid-pux6a34n>‚Üê Previous</span> <span class="nav-title" data-astro-cid-pux6a34n>Optimization in Deep Learning</span> </a> <a href="/eng-ai/part4" class="nav-next" data-astro-cid-pux6a34n> <span class="nav-label" data-astro-cid-pux6a34n>Next ‚Üí</span> <span class="nav-title" data-astro-cid-pux6a34n>Part IV: Deep Architectures</span> </a> </nav>  </main> <aside class="chapter-toc"> <nav class="toc" data-astro-cid-xvrfupwn><h4 data-astro-cid-xvrfupwn>On This Page</h4><ul data-astro-cid-xvrfupwn><li class="toc-level-2" data-astro-cid-xvrfupwn><a href="#from-pixels-to-meaning-ch15" data-astro-cid-xvrfupwn>From Pixels to Meaning</a></li><li class="toc-level-2" data-astro-cid-xvrfupwn><a href="#distributed-representations-why-neurons-dont-map-1-to-1-ch15" data-astro-cid-xvrfupwn>Distributed Representations: Why Neurons Don‚Äôt Map 1-to-1</a></li><li class="toc-level-2" data-astro-cid-xvrfupwn><a href="#emergence-how-concepts-appear-ch15" data-astro-cid-xvrfupwn>Emergence: How Concepts Appear</a></li><li class="toc-level-2" data-astro-cid-xvrfupwn><a href="#why-emergence-happens-the-implicit-bias-of-sgd-ch15" data-astro-cid-xvrfupwn>Why Emergence Happens: The Implicit Bias of SGD</a></li><li class="toc-level-2" data-astro-cid-xvrfupwn><a href="#what-do-layers-learn-concrete-examples-ch15" data-astro-cid-xvrfupwn>What Do Layers Learn? Concrete Examples</a></li><li class="toc-level-2" data-astro-cid-xvrfupwn><a href="#representation-quality-how-to-measure-whats-learned-ch15" data-astro-cid-xvrfupwn>Representation Quality: How to Measure What‚Äôs Learned</a></li><li class="toc-level-2" data-astro-cid-xvrfupwn><a href="#domain-specific-representations-ch15" data-astro-cid-xvrfupwn>Domain-Specific Representations</a></li><li class="toc-level-2" data-astro-cid-xvrfupwn><a href="#why-deep-beats-shallow-ch15" data-astro-cid-xvrfupwn>Why Deep Beats Shallow</a></li><li class="toc-level-2" data-astro-cid-xvrfupwn><a href="#engineering-takeaway-ch15" data-astro-cid-xvrfupwn>Engineering Takeaway</a></li><li class="toc-level-2" data-astro-cid-xvrfupwn><a href="#references-and-further-reading-ch15" data-astro-cid-xvrfupwn>References and Further Reading</a></li></ul></nav> </aside> </div>   </body> </html>